{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b105abe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.93.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.conda/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.conda/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.conda/lib/python3.11/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in ./.conda/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.conda/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.conda/lib/python3.11/site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Using cached openai-1.93.0-py3-none-any.whl (755 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.10.0-cp311-cp311-macosx_11_0_arm64.whl (321 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [openai]2m2/3\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distro-1.9.0 jiter-0.10.0 openai-1.93.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9553102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m2025-07-07 15:59:56 - pipmaster.package_manager - INFO - Targeting pip associated with Python: /Users/giacomo/Documents/kg+llm_task2_nlp/.conda/bin/python | Command base: /Users/giacomo/Documents/kg+llm_task2_nlp/.conda/bin/python -m pip\u001b[0m\n",
      "\u001b[94m2025-07-07 15:59:56 - pipmaster.package_manager - INFO - Targeting pip associated with Python: /Users/giacomo/Documents/kg+llm_task2_nlp/.conda/bin/python | Command base: /Users/giacomo/Documents/kg+llm_task2_nlp/.conda/bin/python -m pip\u001b[0m\n",
      "\u001b[94m2025-07-07 15:59:56 - pipmaster.async_package_manager - INFO - [Async] Initialized for Python: /Users/giacomo/Documents/kg+llm_task2_nlp/.conda/bin/python\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration and corrected imports are set.\n",
      "Logging configured. You will now see detailed progress from the LightRAG library.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from neo4j import GraphDatabase\n",
    "import xml.etree.ElementTree as ET\n",
    "import logging \n",
    "import sys\n",
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm.ollama import ollama_model_complete, ollama_embed\n",
    "from lightrag.kg.shared_storage import initialize_pipeline_status\n",
    "from lightrag.utils import EmbeddingFunc, logger, set_verbose_debug\n",
    "from openai import AsyncOpenAI\n",
    "from prompt_it import PROMPTS_IT\n",
    "PDF_FOLDER = \"docs\"\n",
    "WORKING_DIR = \"./pa_rag_storage\" \n",
    "\n",
    "# --- Ollama Model Configuration ---\n",
    "OLLAMA_GENERATION_MODEL = \"gemma3:1b\"\n",
    "OLLAMA_EMBEDDING_MODEL = \"nomic-embed-text\"\n",
    "OLLAMA_EMBEDDING_DIM = 768 \n",
    "\n",
    "LM_STUDIO_API_BASE = \"http://localhost:1234/v1\"\n",
    "LM_STUDIO_MODEL_NAME = \"google/gemma-3-1b\" \n",
    "\n",
    "EMBEDDING_MODEL = \"multilingual-e5-large-instruct-GGUF/multilingual-e5-large-instruct-q8_0.gguf\"\n",
    "EMBEDDING_DIM = 768\n",
    "# --- Neo4j Database Configuration ---\n",
    "os.environ[\"NEO4J_URI\"] = \"neo4j://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"giacomo3234\" \n",
    "\n",
    "lm_studio_client = AsyncOpenAI(base_url=LM_STUDIO_API_BASE, api_key=\"not-needed\")\n",
    "\n",
    "os.makedirs(WORKING_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Configuration and corrected imports are set.\")\n",
    "\n",
    "# Get the root logger for the 'lightrag' library\n",
    "lightrag_logger = logging.getLogger(\"lightrag\")\n",
    "\n",
    "# Set the logging level to INFO or DEBUG\n",
    "# - INFO: Shows major steps (e.g., \"Processing chunk 1/10\", \"Extracting entities\"). This is a good default.\n",
    "# - DEBUG: Shows extremely detailed information, including the exact prompts being sent to the LLM. Very useful for debugging.\n",
    "lightrag_logger.setLevel(logging.INFO)\n",
    "\n",
    "# Make sure the logs are printed to your notebook's output\n",
    "# We check if a handler already exists to avoid duplicate messages\n",
    "if not any(isinstance(handler, logging.StreamHandler) for handler in lightrag_logger.handlers):\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    lightrag_logger.addHandler(handler)\n",
    "\n",
    "print(\"Logging configured. You will now see detailed progress from the LightRAG library.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cb16a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Process 3777 Shared-Data already initialized (multiprocess=False)\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './pa_rag_storage/vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './pa_rag_storage/vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './pa_rag_storage/vdb_chunks.json'} 0 data\n",
      "INFO: Process 3777 storage namespace already initialized: [full_docs]\n",
      "INFO: Process 3777 storage namespace already initialized: [text_chunks]\n",
      "INFO: Process 3777 storage namespace already initialized: [llm_response_cache]\n",
      "INFO: Process 3777 storage namespace already initialized: [doc_status]\n",
      "INFO: Process 3777 storage namespace already initialized: [full_docs]\n",
      "INFO: Process 3777 storage namespace already initialized: [text_chunks]\n",
      "INFO: Process 3777 storage namespace already initialized: [llm_response_cache]\n",
      "INFO: Process 3777 storage namespace already initialized: [doc_status]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing LightRAG Storages (connecting to Neo4j...) ---\n",
      "2025-07-07 16:02:54,359 - lightrag - INFO - Chunk-entity-relation at neo4j://localhost:7687 not found. try to create specified database.\n",
      "2025-07-07 16:02:54,360 - lightrag - INFO - Chunk-entity-relation at neo4j://localhost:7687 not found. try to create specified database.\n",
      "2025-07-07 16:02:54,389 - lightrag - WARNING - This Neo4j instance does not support creating databases. Try to use Neo4j Desktop/Enterprise version or DozerDB instead. Fallback to use the default database.\n",
      "2025-07-07 16:02:54,390 - lightrag - WARNING - This Neo4j instance does not support creating databases. Try to use Neo4j Desktop/Enterprise version or DozerDB instead. Fallback to use the default database.\n",
      "2025-07-07 16:02:54,404 - lightrag - INFO - Connected to None at neo4j://localhost:7687\n",
      "2025-07-07 16:02:54,405 - lightrag - INFO - Connected to None at neo4j://localhost:7687\n",
      "2025-07-07 16:02:54,421 - lightrag - INFO - Storage Initialization completed!\n",
      "--- Reading PA Regulation PDFs ---\n",
      "Reading PDF: Legge regionale n_37_2014 artt. 20-21-22.pdf\n",
      "Reading PDF: Direttiva 2014_25_UE.pdf\n",
      "Reading PDF: Direttiva 2014_23_UE.pdf\n",
      "Reading PDF: Decreto Legislativo 7 marzo 2005_agg_L_147_2013.pdf\n",
      "Reading PDF: L. 27 Dicembre 2006 n.296 (Finanziaria 2007).pdf\n",
      "Reading PDF: L. 23 Dicembre 2000 n.388 (Finanziaria 2001).pdf\n",
      "Reading PDF: dPR 5 ottobre 2010_207_agg_DM_infrastrutture_24apr2014.pdf\n",
      "Reading PDF: Direttiva 2014_24_UE.pdf\n",
      "Reading PDF: D.Lgs. 50_2016.pdf\n",
      "Reading PDF: DGR_17_2024_01_22_signed_signed.pdf\n",
      "Reading PDF: Decreto legislativo 12 aprile  2006_163_agg_DL_24apr2014_n_66.pdf\n",
      "Reading PDF: 2023_0036_Codice_Contratti_Relazione.pdf\n",
      "Reading PDF: L. 23 Dicembre 1999 n.488 (Finanziaria 2000).pdf\n",
      "Reading PDF: BURP_n.177_del_17112008.pdf\n",
      "Reading PDF: DELIBERAZIONE DELLA GIUNTA REGIONALE 21 marzo 2017 n_354.pdf\n",
      "Reading PDF: Dir.1999 93 CE del Parlamento Europeo e del Consiglio.pdf\n",
      "\n",
      "--- Ingesting document with ID 'pa_regulations_corpus_lmstudio' into LightRAG... ---\n",
      "2025-07-07 16:03:24,074 - lightrag - INFO - No new unique documents were found.\n",
      "2025-07-07 16:03:24,075 - lightrag - INFO - Processing 2 document(s)\n",
      "2025-07-07 16:03:24,076 - lightrag - INFO - Extracting stage 1/2: unknown_source\n",
      "2025-07-07 16:03:24,076 - lightrag - INFO - Processing d-id: pa_regulations_corpus\n",
      "2025-07-07 16:03:25,312 - lightrag - INFO - Extracting stage 2/2: unknown_source\n",
      "2025-07-07 16:03:25,313 - lightrag - INFO - Processing d-id: pa_regulations_corpus_lmstudio\n",
      "2025-07-07 16:03:26,697 - lightrag - INFO - limit_async: 16 new workers initialized\n",
      "2025-07-07 16:03:26,697 - lightrag - INFO - limit_async: 4 new workers initialized\n",
      "2025-07-07 16:09:35,486 - lightrag - INFO - Document processing pipeline completed\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mYour knowledge graph has been generated and loaded directly into Neo4j.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Run the asynchronous ingestion process\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_lightrag_ingestion()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mrun_lightrag_ingestion\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     75\u001b[39m document_ids = [\u001b[33m\"\u001b[39m\u001b[33mpa_regulations_corpus_lmstudio\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Ingesting document with ID \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument_ids[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m into LightRAG... ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m rag_instance.ainsert(documents_to_insert, ids=document_ids)\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Ingestion Complete! ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mYour knowledge graph has been generated and loaded directly into Neo4j.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/kg+llm_task2_nlp/.conda/lib/python3.11/site-packages/lightrag/lightrag.py:601\u001b[39m, in \u001b[36mLightRAG.ainsert\u001b[39m\u001b[34m(self, input, split_by_character, split_by_character_only, ids, file_paths)\u001b[39m\n\u001b[32m    589\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Async Insert documents with checkpoint support\u001b[39;00m\n\u001b[32m    590\u001b[39m \n\u001b[32m    591\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    598\u001b[39m \u001b[33;03m    file_paths: list of file paths corresponding to each document, used for citation\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apipeline_enqueue_documents(\u001b[38;5;28minput\u001b[39m, ids, file_paths)\n\u001b[32m--> \u001b[39m\u001b[32m601\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apipeline_process_enqueue_documents(\n\u001b[32m    602\u001b[39m     split_by_character, split_by_character_only\n\u001b[32m    603\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/kg+llm_task2_nlp/.conda/lib/python3.11/site-packages/lightrag/lightrag.py:1147\u001b[39m, in \u001b[36mLightRAG.apipeline_process_enqueue_documents\u001b[39m\u001b[34m(self, split_by_character, split_by_character_only)\u001b[39m\n\u001b[32m   1134\u001b[39m     doc_tasks.append(\n\u001b[32m   1135\u001b[39m         process_document(\n\u001b[32m   1136\u001b[39m             doc_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1143\u001b[39m         )\n\u001b[32m   1144\u001b[39m     )\n\u001b[32m   1146\u001b[39m \u001b[38;5;66;03m# Wait for all document processing to complete\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*doc_tasks)\n\u001b[32m   1149\u001b[39m \u001b[38;5;66;03m# Check if there's a pending request to process more documents (with lock)\u001b[39;00m\n\u001b[32m   1150\u001b[39m has_pending_request = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/kg+llm_task2_nlp/.conda/lib/python3.11/site-packages/lightrag/lightrag.py:1006\u001b[39m, in \u001b[36mLightRAG.apipeline_process_enqueue_documents.<locals>.process_document\u001b[39m\u001b[34m(doc_id, status_doc, split_by_character, split_by_character_only, pipeline_status, pipeline_status_lock, semaphore)\u001b[39m\n\u001b[32m    996\u001b[39m     text_chunks_task = asyncio.create_task(\n\u001b[32m    997\u001b[39m         \u001b[38;5;28mself\u001b[39m.text_chunks.upsert(chunks)\n\u001b[32m    998\u001b[39m     )\n\u001b[32m    999\u001b[39m     tasks = [\n\u001b[32m   1000\u001b[39m         doc_status_task,\n\u001b[32m   1001\u001b[39m         chunks_vdb_task,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1004\u001b[39m         text_chunks_task,\n\u001b[32m   1005\u001b[39m     ]\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n\u001b[32m   1007\u001b[39m     file_extraction_stage_ok = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1010\u001b[39m     \u001b[38;5;66;03m# Log error and update pipeline status\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/kg+llm_task2_nlp/.conda/lib/python3.11/site-packages/lightrag/lightrag.py:1190\u001b[39m, in \u001b[36mLightRAG._process_entity_relation_graph\u001b[39m\u001b[34m(self, chunk, pipeline_status, pipeline_status_lock)\u001b[39m\n\u001b[32m   1186\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_process_entity_relation_graph\u001b[39m(\n\u001b[32m   1187\u001b[39m     \u001b[38;5;28mself\u001b[39m, chunk: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], pipeline_status=\u001b[38;5;28;01mNone\u001b[39;00m, pipeline_status_lock=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1188\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m   1189\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1190\u001b[39m         chunk_results = \u001b[38;5;28;01mawait\u001b[39;00m extract_entities(\n\u001b[32m   1191\u001b[39m             chunk,\n\u001b[32m   1192\u001b[39m             global_config=asdict(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m   1193\u001b[39m             pipeline_status=pipeline_status,\n\u001b[32m   1194\u001b[39m             pipeline_status_lock=pipeline_status_lock,\n\u001b[32m   1195\u001b[39m             llm_response_cache=\u001b[38;5;28mself\u001b[39m.llm_response_cache,\n\u001b[32m   1196\u001b[39m         )\n\u001b[32m   1197\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m chunk_results\n\u001b[32m   1198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/kg+llm_task2_nlp/.conda/lib/python3.11/site-packages/lightrag/operate.py:1301\u001b[39m, in \u001b[36mextract_entities\u001b[39m\u001b[34m(chunks, global_config, pipeline_status, pipeline_status_lock, llm_response_cache)\u001b[39m\n\u001b[32m   1297\u001b[39m     tasks.append(task)\n\u001b[32m   1299\u001b[39m \u001b[38;5;66;03m# Wait for tasks to complete or for the first exception to occur\u001b[39;00m\n\u001b[32m   1300\u001b[39m \u001b[38;5;66;03m# This allows us to cancel remaining tasks if any task fails\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1301\u001b[39m done, pending = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait(tasks, return_when=asyncio.FIRST_EXCEPTION)\n\u001b[32m   1303\u001b[39m \u001b[38;5;66;03m# Check if any task raised an exception\u001b[39;00m\n\u001b[32m   1304\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m done:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/kg+llm_task2_nlp/.conda/lib/python3.11/asyncio/tasks.py:428\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(fs, timeout, return_when)\u001b[39m\n\u001b[32m    425\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPassing coroutines is forbidden, use tasks explicitly.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    427\u001b[39m loop = events.get_running_loop()\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _wait(fs, timeout, return_when, loop)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/kg+llm_task2_nlp/.conda/lib/python3.11/asyncio/tasks.py:535\u001b[39m, in \u001b[36m_wait\u001b[39m\u001b[34m(fs, timeout, return_when, loop)\u001b[39m\n\u001b[32m    532\u001b[39m     f.add_done_callback(_on_completion)\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[32m    536\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447377 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451209 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469781 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448269 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Error code: 400 - {'error': 'Model unloaded.'}\n",
      "Error during LM Studio generation: Error code: 400 - {'error': 'Model unloaded.'}\n",
      "Error during LM Studio generation: Error code: 400 - {'error': 'Model unloaded.'}\n",
      "Error during LM Studio generation: Error code: 400 - {'error': 'Model unloaded.'}\n",
      "Error during LM Studio generation: Error code: 404 - {'error': {'message': 'Failed to load model \"google/gemma-3-1b\". Error: Model does not exist.', 'type': 'invalid_request_error', 'param': 'model', 'code': 'model_not_found'}}\n",
      "Error during LM Studio generation: Error code: 404 - {'error': {'message': 'Failed to load model \"google/gemma-3-1b\". Error: Model does not exist.', 'type': 'invalid_request_error', 'param': 'model', 'code': 'model_not_found'}}\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: Error code: 404 - {'error': {'message': 'Failed to load model \"google/gemma-3-1b\". Error: Model does not exist.', 'type': 'invalid_request_error', 'param': 'model', 'code': 'model_not_found'}}\n",
      "2025-07-07 16:14:22,645 - lightrag - INFO - Chunk 1 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:22,652 - lightrag - INFO - Chunk 2 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:22,669 - lightrag - INFO - Chunk 3 of 3990 extracted 0 Ent + 0 Rel\n",
      "2025-07-07 16:14:22,680 - lightrag - INFO - Chunk 4 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:22,691 - lightrag - INFO - Chunk 1 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:22,693 - lightrag - INFO - Chunk 2 of 3990 extracted 0 Ent + 0 Rel\n",
      "2025-07-07 16:14:22,694 - lightrag - INFO - Chunk 3 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387138 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403631 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464546 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391535 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771341 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936580 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964402 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397395 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450215 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375805 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417298 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760302 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951507 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974406 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822778 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:26,844 - lightrag - INFO - Chunk 4 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:26,845 - lightrag - INFO - Chunk 5 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:26,846 - lightrag - INFO - Chunk 6 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:26,847 - lightrag - INFO - Chunk 7 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:26,849 - lightrag - INFO - Chunk 8 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423421 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438784 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394433 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440520 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803794 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755821 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869661 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843590 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473013 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:28,350 - lightrag - INFO - Chunk 5 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:28,351 - lightrag - INFO - Chunk 6 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:28,352 - lightrag - INFO - Chunk 7 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:28,353 - lightrag - INFO - Chunk 8 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:28,355 - lightrag - INFO - Chunk 9 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474322 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397172 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389517 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794855 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950345 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994585 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383028 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466434 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841240 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:29,861 - lightrag - INFO - Chunk 10 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:29,863 - lightrag - INFO - Chunk 11 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:29,864 - lightrag - INFO - Chunk 12 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:29,865 - lightrag - INFO - Chunk 9 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:29,867 - lightrag - INFO - Chunk 10 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384160 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470104 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941247 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944024 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955025 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377654 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793161 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423879 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443673 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:31,392 - lightrag - INFO - Chunk 11 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:31,394 - lightrag - INFO - Chunk 12 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:31,394 - lightrag - INFO - Chunk 13 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:31,396 - lightrag - INFO - Chunk 14 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:31,399 - lightrag - INFO - Chunk 15 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483626 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939657 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871405 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430720 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994925 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839565 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417042 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489691 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497888 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885738 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:33,101 - lightrag - INFO - Chunk 16 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:33,123 - lightrag - INFO - Chunk 13 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:33,130 - lightrag - INFO - Chunk 14 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:33,131 - lightrag - INFO - Chunk 15 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:33,132 - lightrag - INFO - Chunk 16 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439423 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753964 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935294 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434651 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475143 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462071 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992899 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.925175 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467488 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886208 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918970 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:35,310 - lightrag - INFO - Chunk 17 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:35,311 - lightrag - INFO - Chunk 18 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:35,312 - lightrag - INFO - Chunk 19 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:35,313 - lightrag - INFO - Chunk 20 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:35,315 - lightrag - INFO - Chunk 17 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462935 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382113 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479775 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997564 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984692 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407065 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772448 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855241 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394863 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:36,775 - lightrag - INFO - Chunk 18 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:36,776 - lightrag - INFO - Chunk 19 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:36,776 - lightrag - INFO - Chunk 20 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:36,777 - lightrag - INFO - Chunk 21 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:36,778 - lightrag - INFO - Chunk 22 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431070 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463391 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935319 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389351 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917294 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916917 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850939 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445751 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393738 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:38,172 - lightrag - INFO - Chunk 23 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:38,174 - lightrag - INFO - Chunk 24 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:38,174 - lightrag - INFO - Chunk 21 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:38,176 - lightrag - INFO - Chunk 22 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:38,177 - lightrag - INFO - Chunk 23 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460964 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491892 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826249 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828328 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842743 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790401 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483425 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461982 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412179 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:39,749 - lightrag - INFO - Chunk 24 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:39,751 - lightrag - INFO - Chunk 25 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:39,752 - lightrag - INFO - Chunk 26 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:39,753 - lightrag - INFO - Chunk 27 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:39,754 - lightrag - INFO - Chunk 28 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447529 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841176 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860007 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952916 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763193 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446001 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490869 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486456 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420332 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997588 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962426 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756308 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977080 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:42,132 - lightrag - INFO - Chunk 25 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:42,133 - lightrag - INFO - Chunk 26 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:42,135 - lightrag - INFO - Chunk 27 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:42,139 - lightrag - INFO - Chunk 28 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:42,141 - lightrag - INFO - Chunk 29 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396620 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416693 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437255 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378699 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955634 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904711 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958705 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779048 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497932 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:43,511 - lightrag - INFO - Chunk 30 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:43,512 - lightrag - INFO - Chunk 31 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:43,513 - lightrag - INFO - Chunk 32 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:43,514 - lightrag - INFO - Chunk 29 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:43,515 - lightrag - INFO - Chunk 30 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468410 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434468 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497849 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774322 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905824 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840778 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945239 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478019 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470422 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:44,903 - lightrag - INFO - Chunk 31 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:44,905 - lightrag - INFO - Chunk 32 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:44,906 - lightrag - INFO - Chunk 33 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:44,907 - lightrag - INFO - Chunk 34 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:44,909 - lightrag - INFO - Chunk 35 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380205 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422409 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886714 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766484 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906692 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937481 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452763 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459546 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455676 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:46,421 - lightrag - INFO - Chunk 36 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:46,422 - lightrag - INFO - Chunk 33 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:46,423 - lightrag - INFO - Chunk 34 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:46,425 - lightrag - INFO - Chunk 35 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:46,427 - lightrag - INFO - Chunk 36 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464506 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836915 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970606 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896870 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751045 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497893 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470660 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479675 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458637 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865961 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863157 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800980 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834084 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:48,749 - lightrag - INFO - Chunk 37 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:48,750 - lightrag - INFO - Chunk 38 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:48,751 - lightrag - INFO - Chunk 39 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:48,752 - lightrag - INFO - Chunk 40 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:48,753 - lightrag - INFO - Chunk 37 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389884 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438718 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436078 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462063 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769218 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840625 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860996 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811382 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379280 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:50,177 - lightrag - INFO - Chunk 38 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:50,178 - lightrag - INFO - Chunk 39 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:50,179 - lightrag - INFO - Chunk 40 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:50,180 - lightrag - INFO - Chunk 41 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:50,181 - lightrag - INFO - Chunk 42 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397565 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400877 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494641 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815876 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985008 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971865 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802378 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441034 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498661 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:51,582 - lightrag - INFO - Chunk 43 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752743 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:51,583 - lightrag - INFO - Chunk 44 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:51,584 - lightrag - INFO - Chunk 41 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:51,586 - lightrag - INFO - Chunk 42 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:51,587 - lightrag - INFO - Chunk 43 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487910 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496938 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895972 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876009 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404086 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444988 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430248 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:53,002 - lightrag - INFO - Chunk 44 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:53,003 - lightrag - INFO - Chunk 45 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:53,004 - lightrag - INFO - Chunk 46 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:53,005 - lightrag - INFO - Chunk 47 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:53,006 - lightrag - INFO - Chunk 48 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378440 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903160 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754213 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427101 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886766 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444128 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472295 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421496 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844766 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987671 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787734 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:55,001 - lightrag - INFO - Chunk 45 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:55,002 - lightrag - INFO - Chunk 46 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:55,003 - lightrag - INFO - Chunk 47 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:55,004 - lightrag - INFO - Chunk 48 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:55,005 - lightrag - INFO - Chunk 49 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495289 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391948 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422537 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839452 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376099 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954595 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904005 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777397 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431997 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895627 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:56,835 - lightrag - INFO - Chunk 50 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:56,836 - lightrag - INFO - Chunk 51 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:56,837 - lightrag - INFO - Chunk 52 of 3990 extracted 0 Ent + 0 Rel\n",
      "2025-07-07 16:14:56,838 - lightrag - INFO - Chunk 49 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:56,839 - lightrag - INFO - Chunk 50 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:56,846 - lightrag - INFO - Chunk 51 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436483 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440733 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385466 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986328 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829858 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878587 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410454 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801500 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378527 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484948 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:58,233 - lightrag - INFO - Chunk 52 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:58,233 - lightrag - INFO - Chunk 53 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:58,234 - lightrag - INFO - Chunk 54 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:58,235 - lightrag - INFO - Chunk 55 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:14:58,236 - lightrag - INFO - Chunk 56 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497528 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844676 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947870 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788943 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463664 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446910 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959196 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433384 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475071 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972241 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767456 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905475 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:00,357 - lightrag - INFO - Chunk 53 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:00,358 - lightrag - INFO - Chunk 54 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:00,359 - lightrag - INFO - Chunk 55 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:00,361 - lightrag - INFO - Chunk 56 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:00,362 - lightrag - INFO - Chunk 57 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446582 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478986 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986427 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464243 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411795 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754540 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824381 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917270 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375872 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:01,998 - lightrag - INFO - Chunk 58 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:01,999 - lightrag - INFO - Chunk 59 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:02,001 - lightrag - INFO - Chunk 60 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:02,004 - lightrag - INFO - Chunk 57 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:02,006 - lightrag - INFO - Chunk 58 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409187 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484274 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952585 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495802 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836483 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810347 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937569 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419052 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497718 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:03,423 - lightrag - INFO - Chunk 59 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:03,425 - lightrag - INFO - Chunk 60 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:03,426 - lightrag - INFO - Chunk 61 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:03,428 - lightrag - INFO - Chunk 62 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:03,429 - lightrag - INFO - Chunk 63 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391753 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872726 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989922 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389641 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929088 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875055 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459154 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410944 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382353 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864969 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:05,099 - lightrag - INFO - Chunk 64 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:05,100 - lightrag - INFO - Chunk 61 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:05,102 - lightrag - INFO - Chunk 62 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:05,103 - lightrag - INFO - Chunk 63 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:05,104 - lightrag - INFO - Chunk 64 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383168 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825519 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840396 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906947 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393972 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466349 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486873 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801586 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464891 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992390 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885824 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876517 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:06,995 - lightrag - INFO - Chunk 65 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:06,996 - lightrag - INFO - Chunk 66 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:06,997 - lightrag - INFO - Chunk 67 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:06,998 - lightrag - INFO - Chunk 68 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:06,999 - lightrag - INFO - Chunk 65 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416432 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434859 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751571 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477865 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438840 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877143 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889456 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429960 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935160 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911419 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:08,733 - lightrag - INFO - Chunk 66 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:08,735 - lightrag - INFO - Chunk 67 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:08,736 - lightrag - INFO - Chunk 68 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:08,737 - lightrag - INFO - Chunk 69 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:08,739 - lightrag - INFO - Chunk 70 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431761 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409249 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944733 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846725 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454201 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837165 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850952 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411675 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:10,176 - lightrag - INFO - Chunk 71 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:10,178 - lightrag - INFO - Chunk 72 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:10,179 - lightrag - INFO - Chunk 69 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:10,180 - lightrag - INFO - Chunk 70 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:10,181 - lightrag - INFO - Chunk 71 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471478 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429714 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.849915 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829029 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847661 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459130 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998540 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376267 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449185 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:11,705 - lightrag - INFO - Chunk 72 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:11,706 - lightrag - INFO - Chunk 73 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:11,707 - lightrag - INFO - Chunk 74 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:11,708 - lightrag - INFO - Chunk 75 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:11,709 - lightrag - INFO - Chunk 76 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493048 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843899 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899822 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381694 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497776 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872294 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422810 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488246 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768357 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911873 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885118 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:13,598 - lightrag - INFO - Chunk 73 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:13,599 - lightrag - INFO - Chunk 74 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:13,600 - lightrag - INFO - Chunk 75 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:13,609 - lightrag - INFO - Chunk 76 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:13,611 - lightrag - INFO - Chunk 77 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449750 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418591 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809464 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406348 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901179 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485078 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817568 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412777 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896557 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:15,239 - lightrag - INFO - Chunk 78 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:15,240 - lightrag - INFO - Chunk 79 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:15,242 - lightrag - INFO - Chunk 80 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:15,244 - lightrag - INFO - Chunk 77 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:15,246 - lightrag - INFO - Chunk 78 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376661 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931196 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479141 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983104 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386727 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911294 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854092 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376182 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761119 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464204 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:16,844 - lightrag - INFO - Chunk 79 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:16,845 - lightrag - INFO - Chunk 80 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:16,846 - lightrag - INFO - Chunk 81 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:16,847 - lightrag - INFO - Chunk 82 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:16,849 - lightrag - INFO - Chunk 83 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397202 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439344 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784503 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855606 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394185 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.764578 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797637 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399694 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486269 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.967084 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:18,294 - lightrag - INFO - Chunk 84 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:18,294 - lightrag - INFO - Chunk 81 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:18,295 - lightrag - INFO - Chunk 82 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:18,296 - lightrag - INFO - Chunk 83 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:18,297 - lightrag - INFO - Chunk 84 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390494 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458670 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843163 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971082 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987165 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384117 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483237 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982198 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414944 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847903 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:20,045 - lightrag - INFO - Chunk 85 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:20,046 - lightrag - INFO - Chunk 86 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:20,048 - lightrag - INFO - Chunk 87 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:20,053 - lightrag - INFO - Chunk 88 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:20,055 - lightrag - INFO - Chunk 85 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438830 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878635 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996728 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439821 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493814 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473033 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762628 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813248 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943143 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375622 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:21,852 - lightrag - INFO - Chunk 86 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:21,853 - lightrag - INFO - Chunk 87 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:21,854 - lightrag - INFO - Chunk 88 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:21,855 - lightrag - INFO - Chunk 89 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:21,856 - lightrag - INFO - Chunk 90 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442659 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956727 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457173 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853199 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462243 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784577 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418731 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952560 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435444 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763322 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:23,365 - lightrag - INFO - Chunk 91 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:23,366 - lightrag - INFO - Chunk 92 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:23,367 - lightrag - INFO - Chunk 89 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:23,369 - lightrag - INFO - Chunk 90 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:23,370 - lightrag - INFO - Chunk 91 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383847 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932743 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891743 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472806 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403335 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758584 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948167 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492833 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407958 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795030 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:25,069 - lightrag - INFO - Chunk 92 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:25,070 - lightrag - INFO - Chunk 93 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:25,071 - lightrag - INFO - Chunk 94 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:25,072 - lightrag - INFO - Chunk 95 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:25,073 - lightrag - INFO - Chunk 96 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809019 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466522 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398985 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937383 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855499 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434981 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402389 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926104 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769175 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390223 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:26,678 - lightrag - INFO - Chunk 93 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:26,679 - lightrag - INFO - Chunk 94 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:26,680 - lightrag - INFO - Chunk 95 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:26,682 - lightrag - INFO - Chunk 96 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:26,683 - lightrag - INFO - Chunk 97 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471655 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927508 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439986 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973625 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389707 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774913 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818812 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379269 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393623 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903073 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:28,294 - lightrag - INFO - Chunk 98 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:28,294 - lightrag - INFO - Chunk 99 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:28,295 - lightrag - INFO - Chunk 100 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:28,296 - lightrag - INFO - Chunk 97 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:28,297 - lightrag - INFO - Chunk 98 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490899 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491586 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798343 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872868 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761066 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406041 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465562 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889901 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439388 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:29,692 - lightrag - INFO - Chunk 99 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:29,693 - lightrag - INFO - Chunk 100 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:29,694 - lightrag - INFO - Chunk 101 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:29,695 - lightrag - INFO - Chunk 102 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:29,696 - lightrag - INFO - Chunk 103 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430954 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979837 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937209 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837767 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397118 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414344 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766277 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425610 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470004 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.942342 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897450 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787257 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:31,596 - lightrag - INFO - Chunk 104 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:31,597 - lightrag - INFO - Chunk 101 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:31,598 - lightrag - INFO - Chunk 102 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:31,598 - lightrag - INFO - Chunk 103 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:31,599 - lightrag - INFO - Chunk 104 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444757 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879496 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380886 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402407 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391079 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976477 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922008 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777006 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428916 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873025 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:33,505 - lightrag - INFO - Chunk 105 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:33,505 - lightrag - INFO - Chunk 106 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:33,506 - lightrag - INFO - Chunk 107 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:33,507 - lightrag - INFO - Chunk 108 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:33,508 - lightrag - INFO - Chunk 105 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495871 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483887 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498600 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874180 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944292 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753154 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473638 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912025 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442336 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:34,901 - lightrag - INFO - Chunk 106 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:34,902 - lightrag - INFO - Chunk 107 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:34,905 - lightrag - INFO - Chunk 108 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:34,906 - lightrag - INFO - Chunk 109 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:34,907 - lightrag - INFO - Chunk 110 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442608 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396838 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831662 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873920 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820995 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426371 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976058 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410385 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446099 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:36,236 - lightrag - INFO - Chunk 111 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:36,237 - lightrag - INFO - Chunk 112 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:36,238 - lightrag - INFO - Chunk 109 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:36,238 - lightrag - INFO - Chunk 110 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:36,239 - lightrag - INFO - Chunk 111 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477971 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757765 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861560 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992421 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397658 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413326 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810504 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443042 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484956 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884330 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979797 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837470 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:38,282 - lightrag - INFO - Chunk 112 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:38,283 - lightrag - INFO - Chunk 113 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:38,284 - lightrag - INFO - Chunk 114 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:38,286 - lightrag - INFO - Chunk 115 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:38,286 - lightrag - INFO - Chunk 116 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429480 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398334 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.967013 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422381 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459355 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903365 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963007 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785638 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447703 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:39,972 - lightrag - INFO - Chunk 113 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:39,973 - lightrag - INFO - Chunk 114 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:39,974 - lightrag - INFO - Chunk 115 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:39,977 - lightrag - INFO - Chunk 116 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:39,979 - lightrag - INFO - Chunk 117 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477042 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948514 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493817 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496642 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768332 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862003 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858488 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470057 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378890 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770938 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940770 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:41,681 - lightrag - INFO - Chunk 118 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:41,682 - lightrag - INFO - Chunk 119 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:41,683 - lightrag - INFO - Chunk 120 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:41,684 - lightrag - INFO - Chunk 117 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:41,685 - lightrag - INFO - Chunk 118 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400784 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464057 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882283 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898435 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380526 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490986 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899430 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461267 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858584 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:43,101 - lightrag - INFO - Chunk 119 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:43,101 - lightrag - INFO - Chunk 120 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:43,102 - lightrag - INFO - Chunk 121 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:43,103 - lightrag - INFO - Chunk 122 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:43,103 - lightrag - INFO - Chunk 123 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481749 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989427 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858302 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441260 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478028 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856149 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953273 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401153 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463782 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834945 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886022 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:44,959 - lightrag - INFO - Chunk 124 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:44,960 - lightrag - INFO - Chunk 121 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:44,961 - lightrag - INFO - Chunk 122 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:44,963 - lightrag - INFO - Chunk 123 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:44,964 - lightrag - INFO - Chunk 124 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464362 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389781 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845049 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445904 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900235 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476913 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989039 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958814 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422398 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:46,681 - lightrag - INFO - Chunk 125 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:46,682 - lightrag - INFO - Chunk 126 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:46,683 - lightrag - INFO - Chunk 127 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:46,685 - lightrag - INFO - Chunk 128 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:46,686 - lightrag - INFO - Chunk 125 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376910 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963075 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769801 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418320 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483037 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962331 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488660 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992384 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390642 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966294 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867559 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:48,527 - lightrag - INFO - Chunk 126 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:48,527 - lightrag - INFO - Chunk 127 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:48,528 - lightrag - INFO - Chunk 128 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:48,529 - lightrag - INFO - Chunk 129 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:48,530 - lightrag - INFO - Chunk 130 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379728 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489798 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978628 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468809 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483502 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838693 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792641 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763756 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489253 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:50,097 - lightrag - INFO - Chunk 131 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:50,098 - lightrag - INFO - Chunk 129 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:50,099 - lightrag - INFO - Chunk 132 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:50,100 - lightrag - INFO - Chunk 130 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:50,101 - lightrag - INFO - Chunk 131 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433356 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448478 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859783 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489474 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882454 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863181 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960856 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472140 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424223 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:51,697 - lightrag - INFO - Chunk 132 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:51,698 - lightrag - INFO - Chunk 133 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:51,698 - lightrag - INFO - Chunk 134 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:51,700 - lightrag - INFO - Chunk 135 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:51,702 - lightrag - INFO - Chunk 133 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375622 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834515 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878029 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434943 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883013 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872187 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440707 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458981 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430719 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848943 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830744 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:53,213 - lightrag - INFO - Chunk 136 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:53,214 - lightrag - INFO - Chunk 134 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:53,214 - lightrag - INFO - Chunk 135 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:53,215 - lightrag - INFO - Chunk 136 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:53,216 - lightrag - INFO - Chunk 137 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376550 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990328 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913506 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453533 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489637 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875113 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433309 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406088 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894259 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959521 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877014 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:55,224 - lightrag - INFO - Chunk 138 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:55,224 - lightrag - INFO - Chunk 139 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:55,225 - lightrag - INFO - Chunk 137 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:55,226 - lightrag - INFO - Chunk 140 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:55,227 - lightrag - INFO - Chunk 138 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397073 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443500 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866780 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436333 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459554 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847276 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975884 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965173 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468121 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:56,723 - lightrag - INFO - Chunk 139 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:56,724 - lightrag - INFO - Chunk 140 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:56,724 - lightrag - INFO - Chunk 141 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:56,725 - lightrag - INFO - Chunk 142 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:56,727 - lightrag - INFO - Chunk 143 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455347 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936890 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894736 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387991 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482995 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796262 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945092 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417568 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428737 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893497 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:58,408 - lightrag - INFO - Chunk 141 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:58,409 - lightrag - INFO - Chunk 144 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:58,410 - lightrag - INFO - Chunk 142 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:58,411 - lightrag - INFO - Chunk 143 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:15:58,411 - lightrag - INFO - Chunk 144 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397516 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855846 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487373 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830587 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932852 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450724 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463120 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496650 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978287 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935966 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:00,107 - lightrag - INFO - Chunk 145 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:00,108 - lightrag - INFO - Chunk 146 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:00,109 - lightrag - INFO - Chunk 147 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:00,110 - lightrag - INFO - Chunk 145 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:00,110 - lightrag - INFO - Chunk 148 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477587 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934269 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792110 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475402 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480931 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448647 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777776 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964785 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485129 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978341 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859191 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:01,923 - lightrag - INFO - Chunk 146 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:01,924 - lightrag - INFO - Chunk 147 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:01,925 - lightrag - INFO - Chunk 148 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:01,926 - lightrag - INFO - Chunk 149 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:01,927 - lightrag - INFO - Chunk 150 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410191 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490434 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978979 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385898 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752592 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492389 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889697 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751360 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470525 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:03,485 - lightrag - INFO - Chunk 151 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:03,486 - lightrag - INFO - Chunk 149 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:03,486 - lightrag - INFO - Chunk 152 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:03,487 - lightrag - INFO - Chunk 150 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:03,488 - lightrag - INFO - Chunk 151 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434400 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853018 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387430 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876471 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469389 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801502 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792703 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450856 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405713 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:04,998 - lightrag - INFO - Chunk 152 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:04,998 - lightrag - INFO - Chunk 153 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:04,999 - lightrag - INFO - Chunk 154 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:05,000 - lightrag - INFO - Chunk 155 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:05,002 - lightrag - INFO - Chunk 153 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422554 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808203 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973684 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397323 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869210 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940041 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380818 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499678 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386332 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847682 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:06,606 - lightrag - INFO - Chunk 156 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:06,606 - lightrag - INFO - Chunk 154 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:06,607 - lightrag - INFO - Chunk 155 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:06,608 - lightrag - INFO - Chunk 156 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:06,610 - lightrag - INFO - Chunk 157 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387697 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797164 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990915 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755724 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491856 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487647 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910977 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433384 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412970 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793102 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944594 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827923 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:08,566 - lightrag - INFO - Chunk 158 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:08,567 - lightrag - INFO - Chunk 157 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:08,567 - lightrag - INFO - Chunk 159 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:08,568 - lightrag - INFO - Chunk 160 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:08,569 - lightrag - INFO - Chunk 158 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452605 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471920 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451868 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841821 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433325 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775775 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928259 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984299 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412965 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:10,033 - lightrag - INFO - Chunk 159 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:10,034 - lightrag - INFO - Chunk 161 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:10,035 - lightrag - INFO - Chunk 160 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:10,036 - lightrag - INFO - Chunk 162 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:10,036 - lightrag - INFO - Chunk 161 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495479 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978681 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478870 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376599 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864622 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978936 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772798 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390291 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392275 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:11,657 - lightrag - INFO - Chunk 163 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:11,658 - lightrag - INFO - Chunk 164 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:11,658 - lightrag - INFO - Chunk 162 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:11,659 - lightrag - INFO - Chunk 163 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:11,661 - lightrag - INFO - Chunk 164 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440014 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883860 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754311 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401573 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773014 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998386 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491978 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422925 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475402 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920866 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.925664 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:13,266 - lightrag - INFO - Chunk 165 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:13,267 - lightrag - INFO - Chunk 165 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:13,267 - lightrag - INFO - Chunk 166 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:13,268 - lightrag - INFO - Chunk 167 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:13,269 - lightrag - INFO - Chunk 168 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431201 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879508 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965284 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455984 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474289 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444988 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959496 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773615 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473738 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794089 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821839 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:15,242 - lightrag - INFO - Chunk 166 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:15,243 - lightrag - INFO - Chunk 167 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:15,244 - lightrag - INFO - Chunk 168 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:15,245 - lightrag - INFO - Chunk 169 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:15,246 - lightrag - INFO - Chunk 170 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487174 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480980 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486089 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882722 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883533 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444195 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941092 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891476 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494376 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:16,740 - lightrag - INFO - Chunk 169 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:16,741 - lightrag - INFO - Chunk 171 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:16,741 - lightrag - INFO - Chunk 172 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:16,742 - lightrag - INFO - Chunk 170 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:16,743 - lightrag - INFO - Chunk 171 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405525 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436112 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940266 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927102 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479765 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907088 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797132 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447538 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386027 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:18,317 - lightrag - INFO - Chunk 172 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:18,318 - lightrag - INFO - Chunk 173 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:18,318 - lightrag - INFO - Chunk 174 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:18,319 - lightrag - INFO - Chunk 173 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:18,320 - lightrag - INFO - Chunk 175 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488230 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926471 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990437 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482917 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801682 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816631 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438159 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393865 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476149 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994229 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832804 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:19,915 - lightrag - INFO - Chunk 176 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:19,916 - lightrag - INFO - Chunk 174 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:19,916 - lightrag - INFO - Chunk 175 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:19,917 - lightrag - INFO - Chunk 176 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:19,918 - lightrag - INFO - Chunk 177 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415428 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844194 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845974 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385963 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440036 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432873 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929104 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385044 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828565 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862465 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883193 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:22,074 - lightrag - INFO - Chunk 177 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:22,075 - lightrag - INFO - Chunk 178 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:22,076 - lightrag - INFO - Chunk 179 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:22,078 - lightrag - INFO - Chunk 180 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:22,080 - lightrag - INFO - Chunk 178 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380690 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432140 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398245 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463255 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901536 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847553 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958544 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797006 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490256 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:23,457 - lightrag - INFO - Chunk 179 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:23,458 - lightrag - INFO - Chunk 180 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:23,460 - lightrag - INFO - Chunk 181 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:23,464 - lightrag - INFO - Chunk 181 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:23,467 - lightrag - INFO - Chunk 182 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472012 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454650 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402291 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811491 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789671 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755280 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991637 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460510 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381192 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:24,832 - lightrag - INFO - Chunk 183 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:24,833 - lightrag - INFO - Chunk 184 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:24,834 - lightrag - INFO - Chunk 182 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:24,835 - lightrag - INFO - Chunk 183 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:24,835 - lightrag - INFO - Chunk 184 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497268 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819034 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403268 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827312 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948563 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816251 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413261 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486588 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413336 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:26,359 - lightrag - INFO - Chunk 185 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:26,359 - lightrag - INFO - Chunk 186 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:26,361 - lightrag - INFO - Chunk 185 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:26,361 - lightrag - INFO - Chunk 187 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:26,362 - lightrag - INFO - Chunk 188 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969082 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430181 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966588 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843405 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873328 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444926 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459502 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494239 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435846 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985110 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840481 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766987 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:28,746 - lightrag - INFO - Chunk 186 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:28,746 - lightrag - INFO - Chunk 187 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:28,747 - lightrag - INFO - Chunk 188 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:28,748 - lightrag - INFO - Chunk 189 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:28,749 - lightrag - INFO - Chunk 189 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494249 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432387 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442788 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416541 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915946 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771749 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832054 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917230 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488226 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:30,103 - lightrag - INFO - Chunk 190 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:30,104 - lightrag - INFO - Chunk 191 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:30,104 - lightrag - INFO - Chunk 192 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:30,105 - lightrag - INFO - Chunk 190 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:30,106 - lightrag - INFO - Chunk 191 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467893 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440455 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497296 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877492 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.890074 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953437 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859005 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449455 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484491 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:31,535 - lightrag - INFO - Chunk 192 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:31,535 - lightrag - INFO - Chunk 193 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:31,536 - lightrag - INFO - Chunk 193 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:31,537 - lightrag - INFO - Chunk 194 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:31,537 - lightrag - INFO - Chunk 195 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448131 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467655 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884388 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847784 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936956 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882586 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468816 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388641 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498915 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:33,132 - lightrag - INFO - Chunk 196 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:33,133 - lightrag - INFO - Chunk 194 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:33,134 - lightrag - INFO - Chunk 195 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:33,135 - lightrag - INFO - Chunk 196 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:33,135 - lightrag - INFO - Chunk 197 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455553 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779571 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957057 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911327 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817006 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476784 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396153 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492246 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482267 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831536 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782320 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966921 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:35,378 - lightrag - INFO - Chunk 198 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:35,379 - lightrag - INFO - Chunk 197 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:35,380 - lightrag - INFO - Chunk 199 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:35,380 - lightrag - INFO - Chunk 200 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:35,381 - lightrag - INFO - Chunk 198 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419292 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395123 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468818 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818221 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816427 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494740 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956036 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447357 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:36,629 - lightrag - INFO - Chunk 199 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:36,630 - lightrag - INFO - Chunk 200 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:36,631 - lightrag - INFO - Chunk 201 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:36,632 - lightrag - INFO - Chunk 202 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:36,633 - lightrag - INFO - Chunk 201 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416325 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449636 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751637 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979299 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485353 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982035 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441082 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843613 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483359 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864278 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:38,384 - lightrag - INFO - Chunk 203 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:38,384 - lightrag - INFO - Chunk 204 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:38,385 - lightrag - INFO - Chunk 202 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:38,386 - lightrag - INFO - Chunk 203 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:38,387 - lightrag - INFO - Chunk 204 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387240 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913486 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385363 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913262 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951804 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454955 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463112 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992575 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463208 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843375 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:40,009 - lightrag - INFO - Chunk 205 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:40,009 - lightrag - INFO - Chunk 206 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:40,010 - lightrag - INFO - Chunk 205 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:40,010 - lightrag - INFO - Chunk 207 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:40,011 - lightrag - INFO - Chunk 208 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377554 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772151 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874062 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467278 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416897 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467780 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772917 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946210 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489496 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909790 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919186 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:41,819 - lightrag - INFO - Chunk 206 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:41,819 - lightrag - INFO - Chunk 207 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:41,821 - lightrag - INFO - Chunk 208 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:41,822 - lightrag - INFO - Chunk 209 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:41,823 - lightrag - INFO - Chunk 210 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469429 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420828 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842357 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382346 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473585 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902300 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839124 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395906 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:43,554 - lightrag - INFO - Chunk 209 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:43,554 - lightrag - INFO - Chunk 211 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:43,555 - lightrag - INFO - Chunk 212 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:43,556 - lightrag - INFO - Chunk 210 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:43,557 - lightrag - INFO - Chunk 211 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462413 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991131 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383494 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943951 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454956 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778050 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844845 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450357 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390755 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:44,954 - lightrag - INFO - Chunk 212 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:44,954 - lightrag - INFO - Chunk 213 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:44,955 - lightrag - INFO - Chunk 214 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:44,956 - lightrag - INFO - Chunk 213 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:44,957 - lightrag - INFO - Chunk 215 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445865 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998244 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774794 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381511 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958654 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937407 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377401 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408429 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883689 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435647 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903866 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:46,641 - lightrag - INFO - Chunk 216 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:46,642 - lightrag - INFO - Chunk 214 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:46,642 - lightrag - INFO - Chunk 215 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:46,643 - lightrag - INFO - Chunk 216 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:46,645 - lightrag - INFO - Chunk 217 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477228 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775690 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911395 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414020 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384522 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462917 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769606 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784472 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382362 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992642 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891514 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:48,445 - lightrag - INFO - Chunk 218 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:48,446 - lightrag - INFO - Chunk 217 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:48,447 - lightrag - INFO - Chunk 219 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:48,448 - lightrag - INFO - Chunk 220 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:48,449 - lightrag - INFO - Chunk 218 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464019 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420241 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986242 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827546 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471351 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450960 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871316 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961031 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379056 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:49,909 - lightrag - INFO - Chunk 219 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:49,910 - lightrag - INFO - Chunk 220 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:49,910 - lightrag - INFO - Chunk 221 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:49,911 - lightrag - INFO - Chunk 221 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:49,911 - lightrag - INFO - Chunk 222 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481681 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885041 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850481 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468976 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399704 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904812 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420024 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779857 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498691 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876700 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962825 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:51,786 - lightrag - INFO - Chunk 223 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:51,787 - lightrag - INFO - Chunk 224 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:51,788 - lightrag - INFO - Chunk 222 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:51,789 - lightrag - INFO - Chunk 223 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:51,790 - lightrag - INFO - Chunk 224 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478941 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405888 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760942 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912720 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417416 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396359 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833395 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477853 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807851 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:53,268 - lightrag - INFO - Chunk 225 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:53,269 - lightrag - INFO - Chunk 225 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:53,270 - lightrag - INFO - Chunk 226 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:53,271 - lightrag - INFO - Chunk 227 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:53,272 - lightrag - INFO - Chunk 228 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460531 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791708 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426439 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884009 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398483 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850579 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433013 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922705 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467178 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904393 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:54,921 - lightrag - INFO - Chunk 226 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:54,921 - lightrag - INFO - Chunk 227 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:54,923 - lightrag - INFO - Chunk 228 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:54,924 - lightrag - INFO - Chunk 229 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:54,926 - lightrag - INFO - Chunk 229 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401810 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987845 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478184 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973585 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460280 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943642 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435725 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907852 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452028 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821892 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:56,698 - lightrag - INFO - Chunk 230 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:56,699 - lightrag - INFO - Chunk 231 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:56,701 - lightrag - INFO - Chunk 232 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:56,703 - lightrag - INFO - Chunk 230 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:56,704 - lightrag - INFO - Chunk 231 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379415 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777543 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443553 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931097 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389325 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860326 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423290 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954923 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986684 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384096 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:58,357 - lightrag - INFO - Chunk 232 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:58,359 - lightrag - INFO - Chunk 233 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:58,360 - lightrag - INFO - Chunk 233 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:58,364 - lightrag - INFO - Chunk 234 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:58,367 - lightrag - INFO - Chunk 235 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437728 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901159 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477484 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856141 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420064 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767105 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386375 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927408 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442660 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975991 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:59,968 - lightrag - INFO - Chunk 236 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:59,969 - lightrag - INFO - Chunk 234 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:59,969 - lightrag - INFO - Chunk 235 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:59,971 - lightrag - INFO - Chunk 236 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:16:59,971 - lightrag - INFO - Chunk 237 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464118 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869144 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480521 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902043 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393939 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955946 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479141 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873813 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415869 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941418 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778450 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:01,775 - lightrag - INFO - Chunk 237 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:01,777 - lightrag - INFO - Chunk 238 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:01,779 - lightrag - INFO - Chunk 239 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:01,781 - lightrag - INFO - Chunk 240 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:01,783 - lightrag - INFO - Chunk 238 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474419 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477360 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951974 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498465 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984320 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384727 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880255 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776739 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499324 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:03,441 - lightrag - INFO - Chunk 239 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:03,443 - lightrag - INFO - Chunk 240 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:03,444 - lightrag - INFO - Chunk 241 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:03,445 - lightrag - INFO - Chunk 241 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:03,447 - lightrag - INFO - Chunk 242 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391900 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439103 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832133 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474087 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839716 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846720 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950915 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424009 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952207 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:05,028 - lightrag - INFO - Chunk 243 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:05,029 - lightrag - INFO - Chunk 244 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:05,030 - lightrag - INFO - Chunk 242 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:05,031 - lightrag - INFO - Chunk 243 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:05,032 - lightrag - INFO - Chunk 244 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395068 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913560 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388518 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853811 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770650 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428384 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464839 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459953 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.780538 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:06,421 - lightrag - INFO - Chunk 245 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:06,422 - lightrag - INFO - Chunk 245 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:06,424 - lightrag - INFO - Chunk 246 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:06,425 - lightrag - INFO - Chunk 247 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:06,426 - lightrag - INFO - Chunk 248 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465996 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789924 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985303 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919063 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497597 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405406 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798042 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899589 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478094 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444924 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808270 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761290 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:08,479 - lightrag - INFO - Chunk 246 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:08,480 - lightrag - INFO - Chunk 247 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:08,481 - lightrag - INFO - Chunk 248 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:08,483 - lightrag - INFO - Chunk 249 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:08,484 - lightrag - INFO - Chunk 249 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447162 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450177 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877967 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474345 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491855 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773535 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985209 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882806 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416602 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:09,854 - lightrag - INFO - Chunk 250 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:09,855 - lightrag - INFO - Chunk 251 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:09,856 - lightrag - INFO - Chunk 252 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:09,857 - lightrag - INFO - Chunk 250 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:09,858 - lightrag - INFO - Chunk 251 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386195 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956531 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788822 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461636 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476898 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934158 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851072 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400404 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390235 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923958 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904255 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:11,840 - lightrag - INFO - Chunk 253 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:11,841 - lightrag - INFO - Chunk 252 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:11,844 - lightrag - INFO - Chunk 254 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:11,845 - lightrag - INFO - Chunk 253 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:11,847 - lightrag - INFO - Chunk 255 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497115 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435686 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901515 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929535 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406507 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419854 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751985 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996797 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375041 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:13,288 - lightrag - INFO - Chunk 256 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:13,289 - lightrag - INFO - Chunk 254 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:13,290 - lightrag - INFO - Chunk 255 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:13,291 - lightrag - INFO - Chunk 256 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:13,291 - lightrag - INFO - Chunk 257 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443301 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437388 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853734 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822396 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386050 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753061 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787516 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423379 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378955 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:14,752 - lightrag - INFO - Chunk 258 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:14,753 - lightrag - INFO - Chunk 257 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:14,754 - lightrag - INFO - Chunk 259 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:14,754 - lightrag - INFO - Chunk 260 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:14,756 - lightrag - INFO - Chunk 258 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452854 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773887 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828666 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411721 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801818 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948987 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481449 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399524 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425869 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901845 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929060 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851785 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:16,507 - lightrag - INFO - Chunk 259 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:16,508 - lightrag - INFO - Chunk 260 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:16,509 - lightrag - INFO - Chunk 261 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:16,511 - lightrag - INFO - Chunk 262 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:16,512 - lightrag - INFO - Chunk 261 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408771 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.968679 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416649 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406983 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476614 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823875 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873268 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833332 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478848 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:18,299 - lightrag - INFO - Chunk 263 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:18,301 - lightrag - INFO - Chunk 264 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:18,302 - lightrag - INFO - Chunk 262 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:18,304 - lightrag - INFO - Chunk 263 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:18,305 - lightrag - INFO - Chunk 264 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480735 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906893 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394660 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421065 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951983 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855735 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897540 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432824 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398409 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793229 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:19,751 - lightrag - INFO - Chunk 265 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:19,753 - lightrag - INFO - Chunk 266 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:19,753 - lightrag - INFO - Chunk 265 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:19,755 - lightrag - INFO - Chunk 267 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:19,756 - lightrag - INFO - Chunk 268 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382938 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416811 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955784 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948157 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767363 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434303 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755806 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431747 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431172 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:21,154 - lightrag - INFO - Chunk 266 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:21,155 - lightrag - INFO - Chunk 267 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:21,155 - lightrag - INFO - Chunk 268 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:21,156 - lightrag - INFO - Chunk 269 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:21,157 - lightrag - INFO - Chunk 270 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383437 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753194 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900803 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390378 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963733 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496097 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408929 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380386 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809483 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777916 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771349 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:23,110 - lightrag - INFO - Chunk 269 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:23,111 - lightrag - INFO - Chunk 271 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:23,113 - lightrag - INFO - Chunk 272 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:23,114 - lightrag - INFO - Chunk 270 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:23,117 - lightrag - INFO - Chunk 271 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930408 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430517 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405057 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490366 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867205 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830829 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751022 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435427 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:24,848 - lightrag - INFO - Chunk 272 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:24,850 - lightrag - INFO - Chunk 273 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:24,852 - lightrag - INFO - Chunk 274 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:24,854 - lightrag - INFO - Chunk 273 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:24,857 - lightrag - INFO - Chunk 275 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394134 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468659 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462191 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.799385 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982036 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802831 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937660 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429269 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842030 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383636 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:26,249 - lightrag - INFO - Chunk 274 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:26,251 - lightrag - INFO - Chunk 276 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:26,253 - lightrag - INFO - Chunk 275 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:26,255 - lightrag - INFO - Chunk 277 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:26,256 - lightrag - INFO - Chunk 276 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482480 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443675 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782436 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772894 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820303 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444212 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424804 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948881 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384349 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:27,580 - lightrag - INFO - Chunk 278 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:27,581 - lightrag - INFO - Chunk 277 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:27,581 - lightrag - INFO - Chunk 279 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:27,582 - lightrag - INFO - Chunk 278 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:27,583 - lightrag - INFO - Chunk 280 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464655 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964855 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761615 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390486 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467526 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880434 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432264 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480066 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812877 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897149 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806621 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:29,689 - lightrag - INFO - Chunk 279 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:29,690 - lightrag - INFO - Chunk 281 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:29,692 - lightrag - INFO - Chunk 282 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:29,693 - lightrag - INFO - Chunk 280 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:29,694 - lightrag - INFO - Chunk 281 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390173 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401843 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887591 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484184 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406471 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774718 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911789 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797601 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451444 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:31,033 - lightrag - INFO - Chunk 283 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:31,035 - lightrag - INFO - Chunk 282 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:31,036 - lightrag - INFO - Chunk 284 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:31,037 - lightrag - INFO - Chunk 283 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:31,038 - lightrag - INFO - Chunk 285 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446271 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931760 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436223 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859581 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407675 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998300 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822025 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487255 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436497 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:32,752 - lightrag - INFO - Chunk 286 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:32,753 - lightrag - INFO - Chunk 284 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:32,755 - lightrag - INFO - Chunk 287 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:32,756 - lightrag - INFO - Chunk 285 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:32,758 - lightrag - INFO - Chunk 288 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470476 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906029 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916444 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470638 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918278 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969400 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421144 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433443 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949491 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424279 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855419 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:34,347 - lightrag - INFO - Chunk 286 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:34,348 - lightrag - INFO - Chunk 289 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:34,349 - lightrag - INFO - Chunk 287 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:34,350 - lightrag - INFO - Chunk 290 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:34,351 - lightrag - INFO - Chunk 288 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474218 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946389 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860877 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486897 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489139 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420747 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972421 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969633 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450116 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839538 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886471 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:36,562 - lightrag - INFO - Chunk 289 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:36,563 - lightrag - INFO - Chunk 291 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:36,564 - lightrag - INFO - Chunk 292 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:36,570 - lightrag - INFO - Chunk 290 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:36,571 - lightrag - INFO - Chunk 293 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437695 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454795 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936112 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857750 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396403 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888577 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904795 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446768 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:37,920 - lightrag - INFO - Chunk 291 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:37,921 - lightrag - INFO - Chunk 294 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:37,922 - lightrag - INFO - Chunk 292 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:37,924 - lightrag - INFO - Chunk 295 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:37,925 - lightrag - INFO - Chunk 293 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412086 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466294 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859844 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456756 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894996 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902728 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973360 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440978 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465098 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:39,552 - lightrag - INFO - Chunk 296 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:39,554 - lightrag - INFO - Chunk 294 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:39,556 - lightrag - INFO - Chunk 295 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:39,558 - lightrag - INFO - Chunk 297 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:39,559 - lightrag - INFO - Chunk 298 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475581 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923061 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760729 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465500 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812360 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854547 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497731 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413998 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487586 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816505 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953876 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:41,131 - lightrag - INFO - Chunk 296 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:41,132 - lightrag - INFO - Chunk 297 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:41,133 - lightrag - INFO - Chunk 299 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:41,133 - lightrag - INFO - Chunk 300 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:41,133 - lightrag - INFO - Chunk 298 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422466 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813868 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971227 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396052 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413107 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496073 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805454 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972481 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439701 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889607 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787830 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:43,033 - lightrag - INFO - Chunk 299 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:43,034 - lightrag - INFO - Chunk 301 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:43,035 - lightrag - INFO - Chunk 302 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:43,036 - lightrag - INFO - Chunk 300 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:43,037 - lightrag - INFO - Chunk 301 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415539 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468680 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875124 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456174 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458640 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948120 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899046 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789759 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441213 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986658 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:44,794 - lightrag - INFO - Chunk 303 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:44,796 - lightrag - INFO - Chunk 304 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:44,797 - lightrag - INFO - Chunk 302 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:44,799 - lightrag - INFO - Chunk 303 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:44,800 - lightrag - INFO - Chunk 305 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440869 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483816 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454633 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773446 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835823 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997300 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493132 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466100 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:46,269 - lightrag - INFO - Chunk 306 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:46,270 - lightrag - INFO - Chunk 304 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:46,271 - lightrag - INFO - Chunk 305 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:46,273 - lightrag - INFO - Chunk 307 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:46,274 - lightrag - INFO - Chunk 308 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397340 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976857 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820535 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406710 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935004 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918710 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496607 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408703 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821066 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813523 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:47,836 - lightrag - INFO - Chunk 306 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:47,837 - lightrag - INFO - Chunk 307 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:47,837 - lightrag - INFO - Chunk 309 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:47,838 - lightrag - INFO - Chunk 310 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:47,838 - lightrag - INFO - Chunk 308 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481829 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.908907 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917685 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382719 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493662 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901417 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394279 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840934 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398660 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819164 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940060 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:49,812 - lightrag - INFO - Chunk 309 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:49,813 - lightrag - INFO - Chunk 311 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:49,814 - lightrag - INFO - Chunk 312 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:49,816 - lightrag - INFO - Chunk 310 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:49,817 - lightrag - INFO - Chunk 311 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463777 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454254 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441880 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771504 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915761 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492397 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966899 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426616 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846802 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:51,373 - lightrag - INFO - Chunk 313 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:51,375 - lightrag - INFO - Chunk 314 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:51,376 - lightrag - INFO - Chunk 312 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:51,378 - lightrag - INFO - Chunk 313 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:51,381 - lightrag - INFO - Chunk 315 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426102 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787500 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401609 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987866 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475506 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863064 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400191 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930762 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840836 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412716 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:52,872 - lightrag - INFO - Chunk 316 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:52,873 - lightrag - INFO - Chunk 314 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:52,874 - lightrag - INFO - Chunk 315 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:52,875 - lightrag - INFO - Chunk 317 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:52,875 - lightrag - INFO - Chunk 318 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466245 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785096 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963745 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383907 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490423 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975447 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409031 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988757 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818170 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874412 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:54,736 - lightrag - INFO - Chunk 316 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:54,737 - lightrag - INFO - Chunk 317 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:54,737 - lightrag - INFO - Chunk 319 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:54,738 - lightrag - INFO - Chunk 320 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:54,739 - lightrag - INFO - Chunk 318 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434281 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397203 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819925 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442383 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760145 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447501 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996749 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445341 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858695 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:56,206 - lightrag - INFO - Chunk 319 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:56,207 - lightrag - INFO - Chunk 321 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:56,210 - lightrag - INFO - Chunk 322 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:56,211 - lightrag - INFO - Chunk 320 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:56,213 - lightrag - INFO - Chunk 321 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380266 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996890 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755926 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492874 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395002 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831933 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862724 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460940 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441844 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894245 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935909 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:58,038 - lightrag - INFO - Chunk 323 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:58,039 - lightrag - INFO - Chunk 324 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:58,040 - lightrag - INFO - Chunk 322 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:58,041 - lightrag - INFO - Chunk 323 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:58,043 - lightrag - INFO - Chunk 325 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397900 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391275 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989204 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972298 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476341 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497597 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957298 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984018 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390249 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:59,565 - lightrag - INFO - Chunk 326 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:59,567 - lightrag - INFO - Chunk 324 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:59,568 - lightrag - INFO - Chunk 325 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:59,569 - lightrag - INFO - Chunk 327 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:17:59,571 - lightrag - INFO - Chunk 328 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940121 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456114 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470799 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979949 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498796 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917561 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404037 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870185 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913324 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:01,631 - lightrag - INFO - Chunk 326 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:01,632 - lightrag - INFO - Chunk 327 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:01,633 - lightrag - INFO - Chunk 329 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:01,637 - lightrag - INFO - Chunk 330 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:01,639 - lightrag - INFO - Chunk 328 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383891 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427135 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929861 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437699 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803308 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482533 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826851 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920381 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408963 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:02,982 - lightrag - INFO - Chunk 329 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:02,983 - lightrag - INFO - Chunk 331 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:02,984 - lightrag - INFO - Chunk 332 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:02,985 - lightrag - INFO - Chunk 330 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:02,986 - lightrag - INFO - Chunk 331 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493862 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891193 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431473 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922173 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452192 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.780617 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774607 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387484 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420919 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:04,660 - lightrag - INFO - Chunk 333 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:04,662 - lightrag - INFO - Chunk 334 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:04,669 - lightrag - INFO - Chunk 332 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:04,671 - lightrag - INFO - Chunk 333 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:04,672 - lightrag - INFO - Chunk 335 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472298 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766690 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777157 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453957 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909636 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484766 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864354 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398931 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969797 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778113 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431995 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:06,380 - lightrag - INFO - Chunk 336 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:06,381 - lightrag - INFO - Chunk 334 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:06,383 - lightrag - INFO - Chunk 335 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:06,384 - lightrag - INFO - Chunk 337 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:06,386 - lightrag - INFO - Chunk 338 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471372 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855777 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489677 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910304 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404133 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914994 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819919 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490986 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428065 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782860 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:08,148 - lightrag - INFO - Chunk 336 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:08,149 - lightrag - INFO - Chunk 337 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:08,150 - lightrag - INFO - Chunk 339 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:08,151 - lightrag - INFO - Chunk 340 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:08,152 - lightrag - INFO - Chunk 338 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452274 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805896 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415342 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949174 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833607 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496485 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419399 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865128 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917820 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416969 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:09,566 - lightrag - INFO - Chunk 339 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:09,567 - lightrag - INFO - Chunk 341 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:09,569 - lightrag - INFO - Chunk 342 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:09,573 - lightrag - INFO - Chunk 340 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:09,575 - lightrag - INFO - Chunk 341 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431209 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934143 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939327 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410934 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424487 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833162 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998902 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388160 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483888 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903389 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:11,293 - lightrag - INFO - Chunk 343 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:11,294 - lightrag - INFO - Chunk 344 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:11,294 - lightrag - INFO - Chunk 342 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:11,295 - lightrag - INFO - Chunk 343 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:11,295 - lightrag - INFO - Chunk 345 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753503 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851330 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467893 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410135 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382005 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805115 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965543 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450667 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752420 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915843 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:13,095 - lightrag - INFO - Chunk 346 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:13,096 - lightrag - INFO - Chunk 344 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:13,098 - lightrag - INFO - Chunk 345 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:13,099 - lightrag - INFO - Chunk 347 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:13,100 - lightrag - INFO - Chunk 348 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380448 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498252 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774080 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382423 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904155 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909168 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412984 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458144 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773634 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865387 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:14,761 - lightrag - INFO - Chunk 346 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:14,761 - lightrag - INFO - Chunk 347 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:14,762 - lightrag - INFO - Chunk 349 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:14,763 - lightrag - INFO - Chunk 350 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:14,764 - lightrag - INFO - Chunk 348 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407179 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445760 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960197 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460332 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810215 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470989 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844770 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775845 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417030 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:16,142 - lightrag - INFO - Chunk 349 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:16,143 - lightrag - INFO - Chunk 351 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:16,144 - lightrag - INFO - Chunk 352 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:16,145 - lightrag - INFO - Chunk 350 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:16,146 - lightrag - INFO - Chunk 351 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439920 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385051 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973691 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878763 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390554 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828872 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922411 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435978 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491336 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:17,719 - lightrag - INFO - Chunk 353 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:17,720 - lightrag - INFO - Chunk 354 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:17,722 - lightrag - INFO - Chunk 352 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:17,723 - lightrag - INFO - Chunk 353 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:17,724 - lightrag - INFO - Chunk 355 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457748 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842633 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879385 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483137 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958772 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836301 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402532 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417242 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405107 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954123 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904208 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:19,519 - lightrag - INFO - Chunk 356 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:19,520 - lightrag - INFO - Chunk 354 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:19,521 - lightrag - INFO - Chunk 355 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:19,524 - lightrag - INFO - Chunk 357 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:19,525 - lightrag - INFO - Chunk 358 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438503 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797140 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851747 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379389 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438190 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497615 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853107 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482550 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811885 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829726 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:21,374 - lightrag - INFO - Chunk 356 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:21,374 - lightrag - INFO - Chunk 357 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:21,375 - lightrag - INFO - Chunk 359 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:21,377 - lightrag - INFO - Chunk 360 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:21,378 - lightrag - INFO - Chunk 358 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376575 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380747 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386268 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997052 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791103 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428048 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958325 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477979 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:22,807 - lightrag - INFO - Chunk 359 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:22,808 - lightrag - INFO - Chunk 361 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:22,810 - lightrag - INFO - Chunk 362 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:22,811 - lightrag - INFO - Chunk 360 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:22,812 - lightrag - INFO - Chunk 361 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482598 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455245 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883048 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778645 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808383 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494647 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938151 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427422 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431417 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:24,140 - lightrag - INFO - Chunk 363 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:24,141 - lightrag - INFO - Chunk 364 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:24,141 - lightrag - INFO - Chunk 362 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:24,142 - lightrag - INFO - Chunk 363 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:24,142 - lightrag - INFO - Chunk 365 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452575 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759318 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877126 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774563 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395586 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485289 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495535 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985283 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422799 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.799419 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970909 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779764 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:26,390 - lightrag - INFO - Chunk 366 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:26,392 - lightrag - INFO - Chunk 364 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:26,393 - lightrag - INFO - Chunk 367 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:26,394 - lightrag - INFO - Chunk 365 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:26,397 - lightrag - INFO - Chunk 368 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444921 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482402 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455741 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831978 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377656 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896212 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933036 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930978 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391717 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:27,967 - lightrag - INFO - Chunk 366 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:27,968 - lightrag - INFO - Chunk 367 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:27,968 - lightrag - INFO - Chunk 369 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:27,969 - lightrag - INFO - Chunk 370 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:27,970 - lightrag - INFO - Chunk 368 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403996 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470935 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870427 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390335 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930492 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817493 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828637 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432454 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449843 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:29,363 - lightrag - INFO - Chunk 371 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:29,363 - lightrag - INFO - Chunk 369 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:29,364 - lightrag - INFO - Chunk 372 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:29,366 - lightrag - INFO - Chunk 370 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:29,367 - lightrag - INFO - Chunk 371 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472924 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819329 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419391 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.764407 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784135 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773922 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388274 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409978 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468272 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962383 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:30,630 - lightrag - INFO - Chunk 373 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:30,631 - lightrag - INFO - Chunk 374 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:30,632 - lightrag - INFO - Chunk 372 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:30,633 - lightrag - INFO - Chunk 375 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:30,634 - lightrag - INFO - Chunk 373 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470656 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984572 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941564 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886130 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499631 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451491 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408431 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499335 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810373 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804517 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989599 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762990 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:32,918 - lightrag - INFO - Chunk 376 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:32,919 - lightrag - INFO - Chunk 374 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:32,921 - lightrag - INFO - Chunk 377 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:32,922 - lightrag - INFO - Chunk 375 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:32,923 - lightrag - INFO - Chunk 378 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449713 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457997 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472482 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944747 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485657 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767772 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793531 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787321 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459987 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:34,452 - lightrag - INFO - Chunk 376 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:34,453 - lightrag - INFO - Chunk 377 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:34,455 - lightrag - INFO - Chunk 379 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:34,456 - lightrag - INFO - Chunk 380 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:34,457 - lightrag - INFO - Chunk 378 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421752 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499227 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402706 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962913 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987294 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816790 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898365 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481840 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406749 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:35,921 - lightrag - INFO - Chunk 381 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:35,922 - lightrag - INFO - Chunk 379 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:35,922 - lightrag - INFO - Chunk 382 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:35,923 - lightrag - INFO - Chunk 380 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:35,925 - lightrag - INFO - Chunk 383 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412814 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480488 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893174 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870372 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498084 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485447 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462220 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:37,331 - lightrag - INFO - Chunk 381 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:37,332 - lightrag - INFO - Chunk 384 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:37,333 - lightrag - INFO - Chunk 382 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:37,334 - lightrag - INFO - Chunk 385 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:37,334 - lightrag - INFO - Chunk 383 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965465 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926989 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822483 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935267 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485043 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491949 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388926 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467739 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792757 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975044 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844241 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982321 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:39,785 - lightrag - INFO - Chunk 386 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:39,786 - lightrag - INFO - Chunk 387 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:39,788 - lightrag - INFO - Chunk 384 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:39,791 - lightrag - INFO - Chunk 385 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:39,793 - lightrag - INFO - Chunk 388 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419531 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410053 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432835 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380758 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946809 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971636 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855498 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869709 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493102 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:41,311 - lightrag - INFO - Chunk 386 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:41,312 - lightrag - INFO - Chunk 389 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:41,313 - lightrag - INFO - Chunk 387 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:41,315 - lightrag - INFO - Chunk 390 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:41,316 - lightrag - INFO - Chunk 388 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450157 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457043 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383687 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840542 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930159 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828375 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839352 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495936 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:42,640 - lightrag - INFO - Chunk 391 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:42,641 - lightrag - INFO - Chunk 389 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:42,642 - lightrag - INFO - Chunk 392 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423603 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:42,649 - lightrag - INFO - Chunk 393 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:42,650 - lightrag - INFO - Chunk 390 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462748 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466319 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814305 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863191 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937829 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770903 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454433 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492934 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381501 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:44,059 - lightrag - INFO - Chunk 391 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:44,060 - lightrag - INFO - Chunk 394 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:44,061 - lightrag - INFO - Chunk 392 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:44,062 - lightrag - INFO - Chunk 393 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:44,063 - lightrag - INFO - Chunk 395 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375406 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941448 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863576 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776356 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959247 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443988 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426576 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413152 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383677 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806205 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806042 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898491 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892744 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:46,470 - lightrag - INFO - Chunk 394 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:46,471 - lightrag - INFO - Chunk 396 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:46,473 - lightrag - INFO - Chunk 397 of 3990 extracted 0 Ent + 0 Rel\n",
      "2025-07-07 16:18:46,474 - lightrag - INFO - Chunk 395 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:46,477 - lightrag - INFO - Chunk 396 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:46,479 - lightrag - INFO - Chunk 398 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495415 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499624 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430652 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405447 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954601 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809018 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.925674 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846918 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379333 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467106 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:47,940 - lightrag - INFO - Chunk 397 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:47,941 - lightrag - INFO - Chunk 399 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:47,942 - lightrag - INFO - Chunk 400 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:47,943 - lightrag - INFO - Chunk 401 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:47,943 - lightrag - INFO - Chunk 398 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433183 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386684 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882682 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876952 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992955 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918092 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414714 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457526 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443982 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:49,377 - lightrag - INFO - Chunk 399 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:49,378 - lightrag - INFO - Chunk 400 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:49,379 - lightrag - INFO - Chunk 402 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:49,379 - lightrag - INFO - Chunk 403 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:49,380 - lightrag - INFO - Chunk 401 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462277 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801009 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804467 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852150 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930443 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405147 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446707 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483403 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468427 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830097 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759852 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906664 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:51,717 - lightrag - INFO - Chunk 404 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:51,718 - lightrag - INFO - Chunk 405 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:51,719 - lightrag - INFO - Chunk 402 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:51,721 - lightrag - INFO - Chunk 403 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:51,722 - lightrag - INFO - Chunk 404 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395327 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471832 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498072 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787002 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387729 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895308 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903444 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491409 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:53,163 - lightrag - INFO - Chunk 406 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:53,164 - lightrag - INFO - Chunk 407 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:53,165 - lightrag - INFO - Chunk 405 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:53,167 - lightrag - INFO - Chunk 408 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:53,168 - lightrag - INFO - Chunk 409 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392678 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388801 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456657 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839964 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918241 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751729 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782320 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482049 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379658 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:54,501 - lightrag - INFO - Chunk 406 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:54,502 - lightrag - INFO - Chunk 407 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:54,502 - lightrag - INFO - Chunk 408 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:54,503 - lightrag - INFO - Chunk 410 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:54,503 - lightrag - INFO - Chunk 411 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389823 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493354 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831728 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977378 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829561 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950016 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482534 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484957 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387589 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962037 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:56,109 - lightrag - INFO - Chunk 409 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:56,109 - lightrag - INFO - Chunk 412 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:56,110 - lightrag - INFO - Chunk 410 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:56,113 - lightrag - INFO - Chunk 413 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:56,114 - lightrag - INFO - Chunk 411 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458203 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772418 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785144 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825349 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482458 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437052 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464187 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432969 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812714 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770906 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833499 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851996 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:58,268 - lightrag - INFO - Chunk 414 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:58,269 - lightrag - INFO - Chunk 415 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:58,270 - lightrag - INFO - Chunk 412 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:58,272 - lightrag - INFO - Chunk 413 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:58,273 - lightrag - INFO - Chunk 414 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429699 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490285 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392351 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879269 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408833 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991179 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911334 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399241 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:59,597 - lightrag - INFO - Chunk 416 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:59,598 - lightrag - INFO - Chunk 417 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:59,599 - lightrag - INFO - Chunk 415 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:59,601 - lightrag - INFO - Chunk 416 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:18:59,603 - lightrag - INFO - Chunk 418 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497940 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383544 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939428 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454804 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994336 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752060 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893732 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443917 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432317 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:01,108 - lightrag - INFO - Chunk 419 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:01,109 - lightrag - INFO - Chunk 417 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:01,110 - lightrag - INFO - Chunk 418 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:01,112 - lightrag - INFO - Chunk 420 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:01,114 - lightrag - INFO - Chunk 421 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828936 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841296 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439681 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945044 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979114 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457018 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491695 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439496 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988002 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971306 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:02,831 - lightrag - INFO - Chunk 419 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:02,831 - lightrag - INFO - Chunk 420 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:02,832 - lightrag - INFO - Chunk 422 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:02,833 - lightrag - INFO - Chunk 423 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:02,835 - lightrag - INFO - Chunk 421 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438468 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941555 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902512 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459482 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420162 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433052 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876501 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877046 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481740 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982204 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961603 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:05,028 - lightrag - INFO - Chunk 422 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:05,030 - lightrag - INFO - Chunk 424 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:05,032 - lightrag - INFO - Chunk 425 of 3990 extracted 0 Ent + 0 Rel\n",
      "2025-07-07 16:19:05,032 - lightrag - INFO - Chunk 423 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:05,036 - lightrag - INFO - Chunk 424 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:05,038 - lightrag - INFO - Chunk 426 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455496 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438406 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430169 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.849108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957324 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415986 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920208 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961567 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388604 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464183 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989291 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:06,737 - lightrag - INFO - Chunk 427 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:06,738 - lightrag - INFO - Chunk 425 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:06,738 - lightrag - INFO - Chunk 428 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:06,739 - lightrag - INFO - Chunk 426 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:06,739 - lightrag - INFO - Chunk 429 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416856 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970581 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424646 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760995 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916996 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431583 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396395 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400798 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921284 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911667 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912262 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:08,401 - lightrag - INFO - Chunk 427 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:08,402 - lightrag - INFO - Chunk 428 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:08,403 - lightrag - INFO - Chunk 430 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:08,405 - lightrag - INFO - Chunk 431 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:08,405 - lightrag - INFO - Chunk 429 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386358 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815149 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450611 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402789 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474445 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863728 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983446 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425722 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903858 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830024 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:10,420 - lightrag - INFO - Chunk 432 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:10,421 - lightrag - INFO - Chunk 430 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:10,422 - lightrag - INFO - Chunk 433 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:10,423 - lightrag - INFO - Chunk 431 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:10,424 - lightrag - INFO - Chunk 432 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457858 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414568 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415922 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829686 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383088 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989196 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823371 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843332 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477595 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:11,885 - lightrag - INFO - Chunk 434 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:11,886 - lightrag - INFO - Chunk 435 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:11,886 - lightrag - INFO - Chunk 433 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:11,887 - lightrag - INFO - Chunk 436 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:11,888 - lightrag - INFO - Chunk 437 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441338 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479341 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400026 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875780 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864853 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893080 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762234 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425185 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425435 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:13,313 - lightrag - INFO - Chunk 434 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:13,313 - lightrag - INFO - Chunk 435 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:13,314 - lightrag - INFO - Chunk 436 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:13,315 - lightrag - INFO - Chunk 438 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:13,316 - lightrag - INFO - Chunk 437 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378219 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418123 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754070 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752711 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750931 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.908756 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466353 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484331 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375746 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961424 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:14,762 - lightrag - INFO - Chunk 439 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:14,762 - lightrag - INFO - Chunk 440 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:14,763 - lightrag - INFO - Chunk 441 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:14,764 - lightrag - INFO - Chunk 438 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:14,764 - lightrag - INFO - Chunk 439 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442920 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953841 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986232 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927557 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472187 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414912 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421434 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475194 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932099 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874539 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965008 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987476 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:17,122 - lightrag - INFO - Chunk 440 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:17,123 - lightrag - INFO - Chunk 441 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:17,124 - lightrag - INFO - Chunk 442 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:17,126 - lightrag - INFO - Chunk 443 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:17,127 - lightrag - INFO - Chunk 444 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457479 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422090 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479579 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857670 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924244 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438306 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863474 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889206 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497865 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:18,522 - lightrag - INFO - Chunk 445 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:18,523 - lightrag - INFO - Chunk 442 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:18,524 - lightrag - INFO - Chunk 443 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:18,526 - lightrag - INFO - Chunk 444 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:18,528 - lightrag - INFO - Chunk 445 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432223 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469601 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922163 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492275 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830619 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754030 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826073 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494077 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443284 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:19,862 - lightrag - INFO - Chunk 446 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:19,862 - lightrag - INFO - Chunk 447 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:19,863 - lightrag - INFO - Chunk 448 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:19,863 - lightrag - INFO - Chunk 446 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:19,864 - lightrag - INFO - Chunk 449 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479985 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473315 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819061 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806309 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852041 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903162 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421552 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460206 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442633 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877162 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893221 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861821 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:21,674 - lightrag - INFO - Chunk 447 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:21,675 - lightrag - INFO - Chunk 448 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:21,676 - lightrag - INFO - Chunk 449 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:21,676 - lightrag - INFO - Chunk 450 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:21,677 - lightrag - INFO - Chunk 451 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401087 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998587 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481808 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465122 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497576 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779445 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912170 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862641 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443446 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866676 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:23,701 - lightrag - INFO - Chunk 452 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:23,702 - lightrag - INFO - Chunk 450 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:23,704 - lightrag - INFO - Chunk 453 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:23,706 - lightrag - INFO - Chunk 451 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:23,707 - lightrag - INFO - Chunk 452 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449887 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380497 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420416 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857556 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.925673 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985442 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496858 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966883 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409757 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:25,192 - lightrag - INFO - Chunk 453 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:25,193 - lightrag - INFO - Chunk 454 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:25,194 - lightrag - INFO - Chunk 455 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:25,195 - lightrag - INFO - Chunk 456 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:25,196 - lightrag - INFO - Chunk 454 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418663 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412973 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932655 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802534 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816330 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440639 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982138 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392498 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457772 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:26,540 - lightrag - INFO - Chunk 457 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:26,540 - lightrag - INFO - Chunk 455 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:26,541 - lightrag - INFO - Chunk 456 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:26,542 - lightrag - INFO - Chunk 457 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:26,543 - lightrag - INFO - Chunk 458 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476496 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839828 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928631 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965096 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423697 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481601 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811788 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468460 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440324 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971278 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765417 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933942 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:28,567 - lightrag - INFO - Chunk 459 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:28,568 - lightrag - INFO - Chunk 460 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:28,569 - lightrag - INFO - Chunk 458 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:28,570 - lightrag - INFO - Chunk 461 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:28,572 - lightrag - INFO - Chunk 459 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450716 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796345 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406681 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390516 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470874 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861812 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973896 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381593 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757180 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997055 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:30,356 - lightrag - INFO - Chunk 460 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:30,358 - lightrag - INFO - Chunk 461 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:30,360 - lightrag - INFO - Chunk 462 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:30,361 - lightrag - INFO - Chunk 463 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:30,362 - lightrag - INFO - Chunk 462 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489101 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397154 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391625 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997461 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933664 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786269 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492943 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790774 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392381 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:31,816 - lightrag - INFO - Chunk 464 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:31,817 - lightrag - INFO - Chunk 465 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:31,818 - lightrag - INFO - Chunk 463 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:31,819 - lightrag - INFO - Chunk 466 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:31,820 - lightrag - INFO - Chunk 464 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411820 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455327 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755160 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873333 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415406 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756321 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455435 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405008 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:33,205 - lightrag - INFO - Chunk 465 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:33,206 - lightrag - INFO - Chunk 467 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:33,207 - lightrag - INFO - Chunk 468 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:33,208 - lightrag - INFO - Chunk 466 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:33,208 - lightrag - INFO - Chunk 469 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438014 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877457 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802892 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482913 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795364 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496739 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487269 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443271 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882564 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798389 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845641 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:34,998 - lightrag - INFO - Chunk 467 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:34,998 - lightrag - INFO - Chunk 470 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:34,999 - lightrag - INFO - Chunk 468 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:34,999 - lightrag - INFO - Chunk 469 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:35,001 - lightrag - INFO - Chunk 471 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446307 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832599 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474529 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424446 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392008 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836357 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904258 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.764139 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480463 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953654 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:36,957 - lightrag - INFO - Chunk 472 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:36,959 - lightrag - INFO - Chunk 473 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:36,960 - lightrag - INFO - Chunk 470 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:36,962 - lightrag - INFO - Chunk 471 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:36,964 - lightrag - INFO - Chunk 474 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394381 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400244 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487567 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960569 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784492 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460124 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853645 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483485 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:38,356 - lightrag - INFO - Chunk 472 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:38,357 - lightrag - INFO - Chunk 473 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:38,358 - lightrag - INFO - Chunk 475 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:38,359 - lightrag - INFO - Chunk 476 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:38,361 - lightrag - INFO - Chunk 474 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413176 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489386 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950584 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847298 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878252 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393231 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779588 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415059 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436672 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:39,762 - lightrag - INFO - Chunk 477 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:39,763 - lightrag - INFO - Chunk 475 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:39,764 - lightrag - INFO - Chunk 476 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:39,765 - lightrag - INFO - Chunk 478 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:39,766 - lightrag - INFO - Chunk 477 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493261 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999337 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963588 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437939 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994404 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895812 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410525 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496497 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377951 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880397 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:41,589 - lightrag - INFO - Chunk 479 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:41,591 - lightrag - INFO - Chunk 480 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:41,592 - lightrag - INFO - Chunk 478 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:41,593 - lightrag - INFO - Chunk 481 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:41,594 - lightrag - INFO - Chunk 479 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412870 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815102 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966320 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999273 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469423 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415119 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384452 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989345 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966024 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457073 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926825 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:43,826 - lightrag - INFO - Chunk 480 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:43,827 - lightrag - INFO - Chunk 482 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:43,830 - lightrag - INFO - Chunk 481 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:43,832 - lightrag - INFO - Chunk 483 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:43,834 - lightrag - INFO - Chunk 482 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407126 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469665 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463604 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944479 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956109 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496967 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936402 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996433 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461330 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:45,276 - lightrag - INFO - Chunk 484 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:45,277 - lightrag - INFO - Chunk 485 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:45,279 - lightrag - INFO - Chunk 483 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:45,280 - lightrag - INFO - Chunk 484 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:45,280 - lightrag - INFO - Chunk 486 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467018 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428867 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868556 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932204 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463862 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395472 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401351 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:46,746 - lightrag - INFO - Chunk 485 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:46,747 - lightrag - INFO - Chunk 487 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:46,751 - lightrag - INFO - Chunk 486 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:46,752 - lightrag - INFO - Chunk 488 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:46,754 - lightrag - INFO - Chunk 489 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399877 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910693 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859526 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790262 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467340 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960773 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479744 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459253 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375778 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825795 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763799 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855451 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:48,725 - lightrag - INFO - Chunk 487 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:48,726 - lightrag - INFO - Chunk 488 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:48,728 - lightrag - INFO - Chunk 490 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:48,731 - lightrag - INFO - Chunk 489 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:48,733 - lightrag - INFO - Chunk 491 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499255 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475003 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437427 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810052 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499250 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965744 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848019 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839484 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404464 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898692 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:50,471 - lightrag - INFO - Chunk 492 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:50,472 - lightrag - INFO - Chunk 490 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:50,473 - lightrag - INFO - Chunk 493 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:50,473 - lightrag - INFO - Chunk 491 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:50,474 - lightrag - INFO - Chunk 494 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489851 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482540 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378554 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751607 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905583 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804569 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424460 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389445 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810317 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:51,871 - lightrag - INFO - Chunk 492 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:51,872 - lightrag - INFO - Chunk 493 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:51,873 - lightrag - INFO - Chunk 495 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:51,874 - lightrag - INFO - Chunk 496 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:51,875 - lightrag - INFO - Chunk 494 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448469 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489063 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842159 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880673 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986985 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436634 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484848 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765682 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469353 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:53,418 - lightrag - INFO - Chunk 497 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:53,420 - lightrag - INFO - Chunk 495 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:53,422 - lightrag - INFO - Chunk 498 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:53,423 - lightrag - INFO - Chunk 496 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:53,424 - lightrag - INFO - Chunk 497 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495499 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965821 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752679 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487756 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880138 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765698 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449643 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408295 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939429 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936180 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:55,094 - lightrag - INFO - Chunk 499 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:55,096 - lightrag - INFO - Chunk 498 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:55,097 - lightrag - INFO - Chunk 500 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:55,099 - lightrag - INFO - Chunk 501 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:55,099 - lightrag - INFO - Chunk 499 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896206 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791230 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411083 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471987 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477147 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894967 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393913 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986018 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922100 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823636 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:57,165 - lightrag - INFO - Chunk 500 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:57,167 - lightrag - INFO - Chunk 502 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:57,168 - lightrag - INFO - Chunk 501 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:57,172 - lightrag - INFO - Chunk 503 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:57,173 - lightrag - INFO - Chunk 502 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492469 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434070 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471255 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449870 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864469 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793936 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943106 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792748 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486590 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:58,569 - lightrag - INFO - Chunk 504 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:58,570 - lightrag - INFO - Chunk 505 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:58,570 - lightrag - INFO - Chunk 503 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:58,571 - lightrag - INFO - Chunk 504 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:19:58,573 - lightrag - INFO - Chunk 506 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443853 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493640 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427295 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926490 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914663 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860699 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762212 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426792 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464938 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:00,158 - lightrag - INFO - Chunk 507 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:00,159 - lightrag - INFO - Chunk 505 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:00,160 - lightrag - INFO - Chunk 508 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:00,161 - lightrag - INFO - Chunk 506 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:00,161 - lightrag - INFO - Chunk 507 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425128 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419374 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957448 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781754 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785795 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929402 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404409 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454160 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395116 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:01,538 - lightrag - INFO - Chunk 509 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:01,539 - lightrag - INFO - Chunk 510 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:01,539 - lightrag - INFO - Chunk 508 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:01,540 - lightrag - INFO - Chunk 511 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:01,541 - lightrag - INFO - Chunk 509 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454307 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755083 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864978 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914168 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979730 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405266 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394379 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388736 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791828 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969693 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752933 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865649 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:03,595 - lightrag - INFO - Chunk 512 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:03,596 - lightrag - INFO - Chunk 510 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:03,597 - lightrag - INFO - Chunk 511 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:03,599 - lightrag - INFO - Chunk 513 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:03,600 - lightrag - INFO - Chunk 514 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405832 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467044 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884943 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493189 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435220 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.849172 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784020 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785511 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442943 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:05,206 - lightrag - INFO - Chunk 515 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:05,207 - lightrag - INFO - Chunk 512 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:05,208 - lightrag - INFO - Chunk 513 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:05,209 - lightrag - INFO - Chunk 516 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:05,210 - lightrag - INFO - Chunk 514 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376715 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489526 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932212 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463706 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807487 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795676 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983335 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397730 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377647 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:06,617 - lightrag - INFO - Chunk 515 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:06,618 - lightrag - INFO - Chunk 517 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:06,620 - lightrag - INFO - Chunk 518 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:06,621 - lightrag - INFO - Chunk 519 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:06,622 - lightrag - INFO - Chunk 516 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460047 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972483 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863438 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487032 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931497 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945554 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450210 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465199 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475995 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771141 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964259 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:08,459 - lightrag - INFO - Chunk 517 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:08,460 - lightrag - INFO - Chunk 518 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:08,461 - lightrag - INFO - Chunk 520 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:08,462 - lightrag - INFO - Chunk 519 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:08,463 - lightrag - INFO - Chunk 521 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447655 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756275 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476797 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848237 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455689 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386454 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824393 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781593 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939209 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409113 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891750 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:10,200 - lightrag - INFO - Chunk 522 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:10,200 - lightrag - INFO - Chunk 523 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:10,201 - lightrag - INFO - Chunk 520 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:10,202 - lightrag - INFO - Chunk 521 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:10,202 - lightrag - INFO - Chunk 522 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471721 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494191 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380394 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918037 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860443 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846193 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441194 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811099 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411843 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:11,747 - lightrag - INFO - Chunk 524 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:11,748 - lightrag - INFO - Chunk 523 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:11,748 - lightrag - INFO - Chunk 525 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:11,749 - lightrag - INFO - Chunk 526 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:11,750 - lightrag - INFO - Chunk 527 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414967 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465181 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803418 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836931 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768434 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388843 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439277 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402572 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:13,078 - lightrag - INFO - Chunk 524 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:13,078 - lightrag - INFO - Chunk 525 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:13,079 - lightrag - INFO - Chunk 526 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:13,080 - lightrag - INFO - Chunk 528 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:13,080 - lightrag - INFO - Chunk 527 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378503 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965284 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914442 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839124 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481618 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988147 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498068 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415652 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470285 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791078 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851248 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791916 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:15,072 - lightrag - INFO - Chunk 529 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:15,073 - lightrag - INFO - Chunk 530 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:15,074 - lightrag - INFO - Chunk 528 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:15,080 - lightrag - INFO - Chunk 531 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:15,082 - lightrag - INFO - Chunk 529 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402425 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877986 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492817 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495920 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433533 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822679 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936613 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864205 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385776 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803613 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:16,869 - lightrag - INFO - Chunk 532 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:16,871 - lightrag - INFO - Chunk 530 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:16,872 - lightrag - INFO - Chunk 531 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:16,873 - lightrag - INFO - Chunk 533 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:16,875 - lightrag - INFO - Chunk 534 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397324 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376415 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463865 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958478 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753139 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792069 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486273 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798158 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488431 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:18,242 - lightrag - INFO - Chunk 532 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:18,243 - lightrag - INFO - Chunk 535 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:18,245 - lightrag - INFO - Chunk 533 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:18,246 - lightrag - INFO - Chunk 534 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:18,247 - lightrag - INFO - Chunk 536 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415420 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497158 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948742 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975901 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796713 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457431 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846268 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493209 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445219 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:19,647 - lightrag - INFO - Chunk 535 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:19,648 - lightrag - INFO - Chunk 537 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:19,649 - lightrag - INFO - Chunk 538 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:19,650 - lightrag - INFO - Chunk 539 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:19,651 - lightrag - INFO - Chunk 536 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455229 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868546 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775909 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950205 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475875 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956367 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405881 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393965 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466296 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938851 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848945 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934241 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:21,635 - lightrag - INFO - Chunk 537 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:21,636 - lightrag - INFO - Chunk 538 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:21,638 - lightrag - INFO - Chunk 540 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:21,640 - lightrag - INFO - Chunk 539 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:21,642 - lightrag - INFO - Chunk 541 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409618 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838679 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489909 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432079 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415749 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923188 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980147 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846277 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461586 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778854 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:23,570 - lightrag - INFO - Chunk 542 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:23,571 - lightrag - INFO - Chunk 543 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:23,573 - lightrag - INFO - Chunk 540 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:23,576 - lightrag - INFO - Chunk 541 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:23,578 - lightrag - INFO - Chunk 544 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417421 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499027 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462268 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926777 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907659 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434767 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873572 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930380 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439107 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:25,047 - lightrag - INFO - Chunk 542 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:25,048 - lightrag - INFO - Chunk 543 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:25,049 - lightrag - INFO - Chunk 545 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:25,054 - lightrag - INFO - Chunk 546 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:25,056 - lightrag - INFO - Chunk 547 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486294 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492457 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866055 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412792 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976613 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832505 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937284 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499840 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453293 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:26,531 - lightrag - INFO - Chunk 544 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:26,531 - lightrag - INFO - Chunk 545 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:26,532 - lightrag - INFO - Chunk 548 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:26,534 - lightrag - INFO - Chunk 546 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:26,534 - lightrag - INFO - Chunk 547 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387770 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491283 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926417 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812831 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759905 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473605 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376560 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451479 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846013 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:28,156 - lightrag - INFO - Chunk 549 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:28,157 - lightrag - INFO - Chunk 550 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:28,157 - lightrag - INFO - Chunk 548 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:28,159 - lightrag - INFO - Chunk 551 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:28,160 - lightrag - INFO - Chunk 549 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488832 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.908037 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871328 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930511 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428351 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478344 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479979 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855770 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383090 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879722 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752989 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.890795 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:30,275 - lightrag - INFO - Chunk 550 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:30,277 - lightrag - INFO - Chunk 552 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:30,279 - lightrag - INFO - Chunk 551 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:30,281 - lightrag - INFO - Chunk 553 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:30,282 - lightrag - INFO - Chunk 554 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494775 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481774 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499565 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801718 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397934 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895321 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869105 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983683 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392674 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:31,804 - lightrag - INFO - Chunk 555 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:31,804 - lightrag - INFO - Chunk 552 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:31,805 - lightrag - INFO - Chunk 553 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:31,806 - lightrag - INFO - Chunk 554 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:31,806 - lightrag - INFO - Chunk 556 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451063 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468468 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861574 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917090 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434737 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896696 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872656 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454529 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380579 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:33,251 - lightrag - INFO - Chunk 555 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:33,252 - lightrag - INFO - Chunk 557 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:33,253 - lightrag - INFO - Chunk 558 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:33,254 - lightrag - INFO - Chunk 559 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:33,255 - lightrag - INFO - Chunk 556 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494060 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758744 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893554 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441705 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790897 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950341 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427018 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428712 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781945 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411963 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984114 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822332 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:34,992 - lightrag - INFO - Chunk 557 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:34,993 - lightrag - INFO - Chunk 558 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:34,993 - lightrag - INFO - Chunk 560 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:34,994 - lightrag - INFO - Chunk 559 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:34,995 - lightrag - INFO - Chunk 561 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455063 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402365 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951353 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785151 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460440 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894100 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935505 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466828 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:36,502 - lightrag - INFO - Chunk 562 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:36,503 - lightrag - INFO - Chunk 560 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:36,504 - lightrag - INFO - Chunk 563 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:36,506 - lightrag - INFO - Chunk 561 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:36,507 - lightrag - INFO - Chunk 562 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393467 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768625 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872064 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462392 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401052 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982677 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444797 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877538 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377960 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812334 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805720 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:38,600 - lightrag - INFO - Chunk 564 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:38,601 - lightrag - INFO - Chunk 563 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:38,603 - lightrag - INFO - Chunk 565 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:38,604 - lightrag - INFO - Chunk 566 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:38,607 - lightrag - INFO - Chunk 567 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472909 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436478 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480282 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454422 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837447 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776162 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926165 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973435 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489588 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:39,906 - lightrag - INFO - Chunk 564 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:39,907 - lightrag - INFO - Chunk 565 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:39,907 - lightrag - INFO - Chunk 566 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:39,908 - lightrag - INFO - Chunk 568 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:39,909 - lightrag - INFO - Chunk 567 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416879 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996356 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420973 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843863 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481485 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770727 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998016 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439932 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388026 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:41,548 - lightrag - INFO - Chunk 569 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:41,549 - lightrag - INFO - Chunk 570 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:41,550 - lightrag - INFO - Chunk 571 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:41,551 - lightrag - INFO - Chunk 568 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:41,553 - lightrag - INFO - Chunk 569 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494816 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974647 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758999 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497520 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924242 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960439 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432269 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479955 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947883 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474160 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812061 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:43,369 - lightrag - INFO - Chunk 570 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:43,370 - lightrag - INFO - Chunk 571 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:43,371 - lightrag - INFO - Chunk 572 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:43,373 - lightrag - INFO - Chunk 573 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:43,374 - lightrag - INFO - Chunk 574 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467941 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801748 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765789 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464474 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450701 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489602 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901043 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961203 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493712 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773952 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772769 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:45,258 - lightrag - INFO - Chunk 575 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:45,259 - lightrag - INFO - Chunk 572 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:45,260 - lightrag - INFO - Chunk 573 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:45,261 - lightrag - INFO - Chunk 574 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:45,263 - lightrag - INFO - Chunk 575 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442715 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382477 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460165 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930242 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.881316 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484389 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974401 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863543 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497954 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:46,650 - lightrag - INFO - Chunk 576 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:46,652 - lightrag - INFO - Chunk 577 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:46,653 - lightrag - INFO - Chunk 578 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:46,656 - lightrag - INFO - Chunk 576 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:46,658 - lightrag - INFO - Chunk 579 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436550 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446049 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863664 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974209 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488776 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790471 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867400 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436475 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456359 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:48,234 - lightrag - INFO - Chunk 577 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:48,235 - lightrag - INFO - Chunk 578 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:48,236 - lightrag - INFO - Chunk 580 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:48,236 - lightrag - INFO - Chunk 579 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:48,237 - lightrag - INFO - Chunk 581 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429505 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832343 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491576 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758157 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766884 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464873 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377965 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807339 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845677 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918332 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:49,893 - lightrag - INFO - Chunk 582 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:49,893 - lightrag - INFO - Chunk 580 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:49,894 - lightrag - INFO - Chunk 583 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:49,895 - lightrag - INFO - Chunk 581 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:49,896 - lightrag - INFO - Chunk 582 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494334 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459012 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404661 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406611 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930314 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856713 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937599 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455431 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842023 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:51,937 - lightrag - INFO - Chunk 584 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:51,938 - lightrag - INFO - Chunk 585 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: Connection error.\n",
      "2025-07-07 16:20:51,942 - lightrag - INFO - Chunk 583 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:51,945 - lightrag - INFO - Chunk 586 of 3990 extracted 0 Ent + 0 Rel\n",
      "2025-07-07 16:20:51,945 - lightrag - INFO - Chunk 584 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460312 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440545 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:52,107 - lightrag - INFO - Chunk 587 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399159 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867014 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931352 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396496 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959611 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902568 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391889 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:53,347 - lightrag - INFO - Chunk 585 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408491 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:53,475 - lightrag - INFO - Chunk 586 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:53,475 - lightrag - INFO - Chunk 588 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:53,476 - lightrag - INFO - Chunk 589 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436432 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762556 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763273 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:53,803 - lightrag - INFO - Chunk 587 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487980 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914411 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859342 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393371 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414969 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944189 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:54,836 - lightrag - INFO - Chunk 590 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433702 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882935 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:55,164 - lightrag - INFO - Chunk 588 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:55,165 - lightrag - INFO - Chunk 591 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:55,166 - lightrag - INFO - Chunk 589 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414995 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805998 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896670 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:55,784 - lightrag - INFO - Chunk 590 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385752 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419090 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498315 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934041 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978087 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:56,491 - lightrag - INFO - Chunk 592 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492871 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761407 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774470 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:57,118 - lightrag - INFO - Chunk 593 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:57,119 - lightrag - INFO - Chunk 591 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:57,120 - lightrag - INFO - Chunk 594 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489499 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:57,241 - lightrag - INFO - Chunk 592 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397078 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443868 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917327 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804306 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391571 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843197 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844903 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:58,453 - lightrag - INFO - Chunk 595 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379821 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:58,540 - lightrag - INFO - Chunk 593 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:58,540 - lightrag - INFO - Chunk 594 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:58,541 - lightrag - INFO - Chunk 596 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461133 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:58,647 - lightrag - INFO - Chunk 597 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417707 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904615 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803958 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392475 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767181 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836871 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407174 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:59,815 - lightrag - INFO - Chunk 595 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448106 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:59,840 - lightrag - INFO - Chunk 598 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:59,841 - lightrag - INFO - Chunk 596 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:20:59,841 - lightrag - INFO - Chunk 599 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471379 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805223 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:00,253 - lightrag - INFO - Chunk 597 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400309 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.908551 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832518 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.780636 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418808 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427824 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:01,193 - lightrag - INFO - Chunk 598 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472972 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873752 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:01,446 - lightrag - INFO - Chunk 600 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:01,447 - lightrag - INFO - Chunk 599 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:01,448 - lightrag - INFO - Chunk 601 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394006 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934227 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793833 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916508 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:02,284 - lightrag - INFO - Chunk 602 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427790 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434132 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412242 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771953 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:02,769 - lightrag - INFO - Chunk 600 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384540 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902088 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921818 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812014 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:03,498 - lightrag - INFO - Chunk 601 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:03,499 - lightrag - INFO - Chunk 603 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:03,500 - lightrag - INFO - Chunk 602 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463020 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:03,823 - lightrag - INFO - Chunk 604 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414040 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493222 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819354 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484893 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.968398 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904205 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992968 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:04,797 - lightrag - INFO - Chunk 603 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498039 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:05,222 - lightrag - INFO - Chunk 605 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:05,223 - lightrag - INFO - Chunk 606 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:05,225 - lightrag - INFO - Chunk 604 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376344 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:05,290 - lightrag - INFO - Chunk 605 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378198 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863185 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494414 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855429 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859645 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842939 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382516 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:06,470 - lightrag - INFO - Chunk 607 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498458 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:06,536 - lightrag - INFO - Chunk 606 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:06,537 - lightrag - INFO - Chunk 608 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:06,538 - lightrag - INFO - Chunk 607 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435656 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817491 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:06,805 - lightrag - INFO - Chunk 609 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406673 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985059 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964899 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997972 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472093 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879304 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476026 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:07,966 - lightrag - INFO - Chunk 610 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470109 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:08,222 - lightrag - INFO - Chunk 608 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:08,224 - lightrag - INFO - Chunk 611 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:08,224 - lightrag - INFO - Chunk 609 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461088 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757236 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876335 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991721 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:08,746 - lightrag - INFO - Chunk 610 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416711 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917398 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479109 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468010 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977429 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:09,691 - lightrag - INFO - Chunk 612 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413854 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781910 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:10,095 - lightrag - INFO - Chunk 611 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:10,096 - lightrag - INFO - Chunk 613 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:10,098 - lightrag - INFO - Chunk 614 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401943 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962192 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753458 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:10,578 - lightrag - INFO - Chunk 612 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395300 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441373 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947912 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386622 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878387 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:11,267 - lightrag - INFO - Chunk 613 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409151 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765967 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798342 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:11,935 - lightrag - INFO - Chunk 615 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:11,936 - lightrag - INFO - Chunk 614 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:11,942 - lightrag - INFO - Chunk 616 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419184 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:12,006 - lightrag - INFO - Chunk 615 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450064 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482433 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896060 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803639 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443717 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988023 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934816 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:13,272 - lightrag - INFO - Chunk 617 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:13,276 - lightrag - INFO - Chunk 618 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:13,278 - lightrag - INFO - Chunk 616 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:13,280 - lightrag - INFO - Chunk 619 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486066 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399635 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831143 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:13,721 - lightrag - INFO - Chunk 617 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434976 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928353 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446789 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996344 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770289 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441286 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:14,705 - lightrag - INFO - Chunk 618 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387073 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910660 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855941 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:15,101 - lightrag - INFO - Chunk 620 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:15,102 - lightrag - INFO - Chunk 621 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:15,104 - lightrag - INFO - Chunk 619 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420356 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:15,164 - lightrag - INFO - Chunk 620 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376190 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909130 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984516 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397214 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481493 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960995 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944801 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:16,450 - lightrag - INFO - Chunk 622 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386945 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:16,535 - lightrag - INFO - Chunk 623 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:16,535 - lightrag - INFO - Chunk 621 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:16,536 - lightrag - INFO - Chunk 622 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452763 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889932 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821858 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:17,262 - lightrag - INFO - Chunk 624 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456092 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460753 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795870 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387181 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:17,820 - lightrag - INFO - Chunk 625 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415229 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994538 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940291 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985904 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:18,531 - lightrag - INFO - Chunk 623 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:18,532 - lightrag - INFO - Chunk 624 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:18,533 - lightrag - INFO - Chunk 626 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391305 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:18,866 - lightrag - INFO - Chunk 627 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390818 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994190 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479276 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405195 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986275 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848145 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895470 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:19,934 - lightrag - INFO - Chunk 625 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458966 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:20,257 - lightrag - INFO - Chunk 626 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:20,258 - lightrag - INFO - Chunk 628 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:20,260 - lightrag - INFO - Chunk 629 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428041 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860631 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:20,413 - lightrag - INFO - Chunk 627 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449193 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383936 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848427 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852928 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847125 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395278 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:21,551 - lightrag - INFO - Chunk 628 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498222 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941937 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:21,725 - lightrag - INFO - Chunk 630 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:21,725 - lightrag - INFO - Chunk 631 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:21,726 - lightrag - INFO - Chunk 629 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411270 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:21,784 - lightrag - INFO - Chunk 630 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390863 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862506 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808193 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854298 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470592 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417861 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:22,981 - lightrag - INFO - Chunk 632 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405326 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:23,037 - lightrag - INFO - Chunk 633 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:23,038 - lightrag - INFO - Chunk 631 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:23,038 - lightrag - INFO - Chunk 632 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380421 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906796 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856445 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808984 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866674 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:24,001 - lightrag - INFO - Chunk 634 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474367 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422895 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379707 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:24,294 - lightrag - INFO - Chunk 635 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429915 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778270 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792478 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753571 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790508 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:25,265 - lightrag - INFO - Chunk 633 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:25,266 - lightrag - INFO - Chunk 634 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:25,267 - lightrag - INFO - Chunk 636 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467555 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:25,397 - lightrag - INFO - Chunk 637 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458763 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488542 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379244 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963995 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769866 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930092 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813334 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:26,638 - lightrag - INFO - Chunk 635 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:26,639 - lightrag - INFO - Chunk 636 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424504 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:26,707 - lightrag - INFO - Chunk 638 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:26,708 - lightrag - INFO - Chunk 637 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422753 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417026 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:26,826 - lightrag - INFO - Chunk 639 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432701 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.890214 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817041 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782729 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901021 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428018 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:27,956 - lightrag - INFO - Chunk 640 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:27,957 - lightrag - INFO - Chunk 638 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420462 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:27,969 - lightrag - INFO - Chunk 639 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:27,970 - lightrag - INFO - Chunk 640 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456965 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403286 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960358 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975541 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831460 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954568 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:29,272 - lightrag - INFO - Chunk 641 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388418 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401673 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:29,362 - lightrag - INFO - Chunk 642 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:29,363 - lightrag - INFO - Chunk 643 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378196 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:29,538 - lightrag - INFO - Chunk 641 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:29,539 - lightrag - INFO - Chunk 644 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400368 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961155 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899540 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759351 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969266 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400400 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:30,637 - lightrag - INFO - Chunk 642 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466848 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382671 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862330 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:30,920 - lightrag - INFO - Chunk 643 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:30,921 - lightrag - INFO - Chunk 644 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393146 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918942 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778782 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929839 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:31,785 - lightrag - INFO - Chunk 645 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:31,786 - lightrag - INFO - Chunk 646 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474919 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386202 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:31,959 - lightrag - INFO - Chunk 647 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396691 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398205 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831887 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949824 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891812 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775047 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:33,106 - lightrag - INFO - Chunk 645 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:33,107 - lightrag - INFO - Chunk 648 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444029 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:33,241 - lightrag - INFO - Chunk 646 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:33,242 - lightrag - INFO - Chunk 647 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444621 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488509 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:33,441 - lightrag - INFO - Chunk 648 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474604 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846797 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974981 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831569 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778439 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424751 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:34,588 - lightrag - INFO - Chunk 649 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:34,590 - lightrag - INFO - Chunk 650 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406987 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:34,674 - lightrag - INFO - Chunk 651 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:34,674 - lightrag - INFO - Chunk 652 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455437 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437769 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763984 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804155 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848799 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859104 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:35,610 - lightrag - INFO - Chunk 649 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416349 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376413 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:35,990 - lightrag - INFO - Chunk 650 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:35,991 - lightrag - INFO - Chunk 651 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478044 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:36,009 - lightrag - INFO - Chunk 652 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:36,010 - lightrag - INFO - Chunk 653 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415745 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841213 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931370 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931052 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884262 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395006 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:37,131 - lightrag - INFO - Chunk 654 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446028 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870703 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:37,371 - lightrag - INFO - Chunk 655 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:37,371 - lightrag - INFO - Chunk 656 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478400 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909885 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751365 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985169 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:38,178 - lightrag - INFO - Chunk 653 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:38,180 - lightrag - INFO - Chunk 654 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486377 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483749 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:38,581 - lightrag - INFO - Chunk 655 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420285 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904213 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413522 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771389 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977155 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904755 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:39,586 - lightrag - INFO - Chunk 656 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:39,588 - lightrag - INFO - Chunk 657 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430281 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:39,766 - lightrag - INFO - Chunk 658 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:39,767 - lightrag - INFO - Chunk 659 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400310 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384342 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994326 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829960 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:40,179 - lightrag - INFO - Chunk 660 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406613 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904195 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987195 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390765 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:41,027 - lightrag - INFO - Chunk 657 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:41,028 - lightrag - INFO - Chunk 658 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461504 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:41,291 - lightrag - INFO - Chunk 659 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:41,292 - lightrag - INFO - Chunk 660 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497703 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762391 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914937 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853828 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817398 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:42,177 - lightrag - INFO - Chunk 661 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459187 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471835 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819901 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:42,671 - lightrag - INFO - Chunk 662 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:42,672 - lightrag - INFO - Chunk 663 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467536 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854439 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:42,905 - lightrag - INFO - Chunk 664 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:42,906 - lightrag - INFO - Chunk 661 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376474 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917365 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755820 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386356 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:43,762 - lightrag - INFO - Chunk 662 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484413 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871853 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396366 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:44,103 - lightrag - INFO - Chunk 663 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:44,104 - lightrag - INFO - Chunk 664 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386187 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805695 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892900 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997443 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:44,765 - lightrag - INFO - Chunk 665 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:44,766 - lightrag - INFO - Chunk 666 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498478 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451941 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821405 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:45,349 - lightrag - INFO - Chunk 667 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474067 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385576 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928020 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802538 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953829 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:46,102 - lightrag - INFO - Chunk 668 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:46,103 - lightrag - INFO - Chunk 665 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377386 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:46,453 - lightrag - INFO - Chunk 666 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:46,454 - lightrag - INFO - Chunk 667 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455258 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754124 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441603 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:46,842 - lightrag - INFO - Chunk 668 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438861 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901007 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882536 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483793 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844762 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861155 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:47,823 - lightrag - INFO - Chunk 669 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:47,824 - lightrag - INFO - Chunk 670 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474490 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:47,976 - lightrag - INFO - Chunk 671 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:47,977 - lightrag - INFO - Chunk 672 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392158 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412234 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927040 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823690 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938626 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:48,603 - lightrag - INFO - Chunk 669 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477263 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911886 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424348 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:49,236 - lightrag - INFO - Chunk 670 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:49,237 - lightrag - INFO - Chunk 671 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392581 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:49,495 - lightrag - INFO - Chunk 673 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:49,496 - lightrag - INFO - Chunk 672 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403053 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953324 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839354 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943411 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486377 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:50,479 - lightrag - INFO - Chunk 674 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446591 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998563 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440900 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:50,853 - lightrag - INFO - Chunk 675 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:50,853 - lightrag - INFO - Chunk 673 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483531 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928420 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897641 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857117 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:51,501 - lightrag - INFO - Chunk 676 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:51,502 - lightrag - INFO - Chunk 674 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454742 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391579 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:51,939 - lightrag - INFO - Chunk 675 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388534 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962132 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446397 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960164 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920757 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997646 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:52,933 - lightrag - INFO - Chunk 677 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:52,934 - lightrag - INFO - Chunk 676 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465855 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:53,228 - lightrag - INFO - Chunk 678 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:53,229 - lightrag - INFO - Chunk 679 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448014 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896247 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:53,660 - lightrag - INFO - Chunk 677 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462073 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842721 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937238 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954219 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496859 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:54,514 - lightrag - INFO - Chunk 680 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:54,516 - lightrag - INFO - Chunk 678 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399029 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:54,627 - lightrag - INFO - Chunk 679 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:54,627 - lightrag - INFO - Chunk 680 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863422 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873812 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454904 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815420 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987204 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:55,680 - lightrag - INFO - Chunk 681 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441354 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488255 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:55,932 - lightrag - INFO - Chunk 682 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:55,933 - lightrag - INFO - Chunk 683 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409621 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996621 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884926 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788414 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:56,545 - lightrag - INFO - Chunk 681 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:56,548 - lightrag - INFO - Chunk 684 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450698 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840959 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484108 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:57,140 - lightrag - INFO - Chunk 682 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441611 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450711 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792065 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859597 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790713 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:57,854 - lightrag - INFO - Chunk 683 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:57,855 - lightrag - INFO - Chunk 685 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424231 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902405 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:58,389 - lightrag - INFO - Chunk 684 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:58,391 - lightrag - INFO - Chunk 686 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499217 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413749 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:58,484 - lightrag - INFO - Chunk 685 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474311 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882301 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755525 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751051 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404657 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907087 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:59,657 - lightrag - INFO - Chunk 687 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:59,658 - lightrag - INFO - Chunk 688 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439004 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:59,719 - lightrag - INFO - Chunk 686 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:21:59,720 - lightrag - INFO - Chunk 687 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405424 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377971 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977139 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798936 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970496 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:00,516 - lightrag - INFO - Chunk 688 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484350 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475516 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:01,084 - lightrag - INFO - Chunk 689 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:01,085 - lightrag - INFO - Chunk 690 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485383 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:01,135 - lightrag - INFO - Chunk 691 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:01,136 - lightrag - INFO - Chunk 689 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393904 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834178 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915126 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812251 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425981 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839185 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:02,269 - lightrag - INFO - Chunk 692 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379697 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480841 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:02,464 - lightrag - INFO - Chunk 690 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:02,464 - lightrag - INFO - Chunk 691 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469460 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773155 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769006 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855658 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:03,091 - lightrag - INFO - Chunk 692 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:03,093 - lightrag - INFO - Chunk 693 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490747 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422692 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864362 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:03,654 - lightrag - INFO - Chunk 694 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383654 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395907 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961720 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959488 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974809 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:04,458 - lightrag - INFO - Chunk 695 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:04,459 - lightrag - INFO - Chunk 693 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473120 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:04,828 - lightrag - INFO - Chunk 696 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:04,829 - lightrag - INFO - Chunk 694 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437923 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840184 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449346 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:05,178 - lightrag - INFO - Chunk 695 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436134 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910497 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811536 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924702 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481631 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:06,191 - lightrag - INFO - Chunk 696 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:06,192 - lightrag - INFO - Chunk 697 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422401 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950475 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:06,275 - lightrag - INFO - Chunk 698 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:06,276 - lightrag - INFO - Chunk 699 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397237 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439895 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919652 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958654 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953311 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:07,225 - lightrag - INFO - Chunk 697 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461201 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392843 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:07,671 - lightrag - INFO - Chunk 700 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:07,672 - lightrag - INFO - Chunk 698 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483045 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756513 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:07,954 - lightrag - INFO - Chunk 699 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821622 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:07,956 - lightrag - INFO - Chunk 700 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390873 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869156 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.993235 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479288 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:08,783 - lightrag - INFO - Chunk 701 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427857 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771253 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454780 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826074 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:09,352 - lightrag - INFO - Chunk 702 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:09,353 - lightrag - INFO - Chunk 703 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432296 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873721 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:09,717 - lightrag - INFO - Chunk 701 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:09,718 - lightrag - INFO - Chunk 704 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435865 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.780390 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409681 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756187 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:10,372 - lightrag - INFO - Chunk 702 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460112 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976102 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384693 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959922 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:10,925 - lightrag - INFO - Chunk 703 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:10,925 - lightrag - INFO - Chunk 704 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397138 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985130 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894865 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:11,445 - lightrag - INFO - Chunk 705 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:11,446 - lightrag - INFO - Chunk 706 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416723 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412310 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985683 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:11,953 - lightrag - INFO - Chunk 707 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408878 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852917 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404794 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910693 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857333 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:12,860 - lightrag - INFO - Chunk 705 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:12,862 - lightrag - INFO - Chunk 708 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437922 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:13,082 - lightrag - INFO - Chunk 706 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:13,083 - lightrag - INFO - Chunk 707 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412666 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431976 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893387 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996701 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:13,506 - lightrag - INFO - Chunk 708 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485293 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785588 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833005 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448909 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:14,506 - lightrag - INFO - Chunk 709 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:14,508 - lightrag - INFO - Chunk 710 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380124 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:14,513 - lightrag - INFO - Chunk 711 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:14,515 - lightrag - INFO - Chunk 709 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491837 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825766 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458521 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937603 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937707 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:15,493 - lightrag - INFO - Chunk 712 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487231 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440647 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:15,925 - lightrag - INFO - Chunk 710 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:15,926 - lightrag - INFO - Chunk 711 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465445 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850358 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:16,244 - lightrag - INFO - Chunk 712 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:16,246 - lightrag - INFO - Chunk 713 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494287 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865410 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893938 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841164 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453665 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:17,152 - lightrag - INFO - Chunk 714 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419103 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404701 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809299 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784141 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:17,595 - lightrag - INFO - Chunk 715 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:17,596 - lightrag - INFO - Chunk 713 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494927 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893961 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788064 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:18,114 - lightrag - INFO - Chunk 716 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:18,128 - lightrag - INFO - Chunk 714 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417828 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402903 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930566 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:18,605 - lightrag - INFO - Chunk 715 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382346 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873863 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414943 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784177 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800481 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:19,507 - lightrag - INFO - Chunk 716 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:19,508 - lightrag - INFO - Chunk 717 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458680 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:19,650 - lightrag - INFO - Chunk 718 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:19,651 - lightrag - INFO - Chunk 719 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495095 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385280 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792312 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:20,114 - lightrag - INFO - Chunk 717 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473235 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752771 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938200 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808645 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438603 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:20,908 - lightrag - INFO - Chunk 720 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:20,909 - lightrag - INFO - Chunk 718 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460272 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:21,111 - lightrag - INFO - Chunk 719 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:21,112 - lightrag - INFO - Chunk 720 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476475 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793034 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972855 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415688 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813183 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848452 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:22,014 - lightrag - INFO - Chunk 721 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388098 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404912 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845298 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:22,414 - lightrag - INFO - Chunk 722 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:22,415 - lightrag - INFO - Chunk 723 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386537 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:22,684 - lightrag - INFO - Chunk 721 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:22,685 - lightrag - INFO - Chunk 724 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493184 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976458 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944362 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812861 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467348 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922158 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:23,756 - lightrag - INFO - Chunk 722 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388180 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429797 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:24,006 - lightrag - INFO - Chunk 723 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:24,007 - lightrag - INFO - Chunk 724 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479324 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847795 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807744 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779244 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:24,663 - lightrag - INFO - Chunk 725 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:24,664 - lightrag - INFO - Chunk 726 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446538 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439772 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:25,017 - lightrag - INFO - Chunk 727 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476808 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794774 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410276 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856225 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857589 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924589 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:25,944 - lightrag - INFO - Chunk 725 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:25,945 - lightrag - INFO - Chunk 728 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461065 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:26,310 - lightrag - INFO - Chunk 726 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:26,311 - lightrag - INFO - Chunk 727 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444549 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425432 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874243 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:26,625 - lightrag - INFO - Chunk 728 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426896 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940159 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896948 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944330 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460025 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:27,690 - lightrag - INFO - Chunk 729 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:27,691 - lightrag - INFO - Chunk 730 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499957 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:27,708 - lightrag - INFO - Chunk 731 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:27,709 - lightrag - INFO - Chunk 732 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433558 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830835 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440854 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791754 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847035 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917848 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:28,597 - lightrag - INFO - Chunk 729 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459169 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471269 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:29,048 - lightrag - INFO - Chunk 730 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:29,049 - lightrag - INFO - Chunk 731 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469137 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933348 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:29,376 - lightrag - INFO - Chunk 733 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:29,378 - lightrag - INFO - Chunk 732 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489613 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781220 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897861 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811436 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379735 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:30,220 - lightrag - INFO - Chunk 734 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488008 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965729 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429094 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:30,696 - lightrag - INFO - Chunk 735 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:30,697 - lightrag - INFO - Chunk 736 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492293 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781236 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823369 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885948 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:31,358 - lightrag - INFO - Chunk 733 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:31,358 - lightrag - INFO - Chunk 734 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467221 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431580 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:31,723 - lightrag - INFO - Chunk 735 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424779 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907298 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471660 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811846 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987110 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:32,721 - lightrag - INFO - Chunk 737 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:32,722 - lightrag - INFO - Chunk 736 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450550 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:32,743 - lightrag - INFO - Chunk 738 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:32,743 - lightrag - INFO - Chunk 739 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424117 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465084 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836975 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956560 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874756 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:33,563 - lightrag - INFO - Chunk 740 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427389 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989042 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492348 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:34,143 - lightrag - INFO - Chunk 737 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:34,144 - lightrag - INFO - Chunk 738 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399733 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:34,328 - lightrag - INFO - Chunk 741 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:34,329 - lightrag - INFO - Chunk 739 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441957 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973745 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819820 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951061 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411637 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:35,383 - lightrag - INFO - Chunk 740 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420262 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954465 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401755 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:35,734 - lightrag - INFO - Chunk 742 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:35,735 - lightrag - INFO - Chunk 743 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451064 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766923 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792321 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782815 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:36,395 - lightrag - INFO - Chunk 744 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:36,396 - lightrag - INFO - Chunk 741 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477676 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418421 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:36,697 - lightrag - INFO - Chunk 742 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475386 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964939 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430399 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769563 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860466 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769785 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:37,788 - lightrag - INFO - Chunk 745 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:37,789 - lightrag - INFO - Chunk 743 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480333 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:37,855 - lightrag - INFO - Chunk 744 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:37,856 - lightrag - INFO - Chunk 746 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375369 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423853 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:38,194 - lightrag - INFO - Chunk 747 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411801 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803824 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884021 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795833 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959799 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410429 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:39,172 - lightrag - INFO - Chunk 748 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:39,173 - lightrag - INFO - Chunk 745 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487557 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:39,271 - lightrag - INFO - Chunk 749 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:39,272 - lightrag - INFO - Chunk 746 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474478 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898722 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394687 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971699 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945845 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776964 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:40,399 - lightrag - INFO - Chunk 747 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422020 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393601 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:40,703 - lightrag - INFO - Chunk 748 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:40,704 - lightrag - INFO - Chunk 750 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440308 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:40,757 - lightrag - INFO - Chunk 751 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:40,758 - lightrag - INFO - Chunk 752 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457721 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899692 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963375 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941520 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785690 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485824 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:42,016 - lightrag - INFO - Chunk 749 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375785 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408382 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:42,097 - lightrag - INFO - Chunk 753 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:42,098 - lightrag - INFO - Chunk 750 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392940 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935044 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914364 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788676 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957349 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:43,172 - lightrag - INFO - Chunk 751 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:43,173 - lightrag - INFO - Chunk 752 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439671 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395055 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:43,326 - lightrag - INFO - Chunk 754 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412892 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408040 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789548 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977591 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830182 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874865 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:44,419 - lightrag - INFO - Chunk 755 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:44,421 - lightrag - INFO - Chunk 756 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446694 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:44,579 - lightrag - INFO - Chunk 753 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:44,580 - lightrag - INFO - Chunk 757 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406847 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493153 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:44,750 - lightrag - INFO - Chunk 754 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423603 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947534 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449729 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:45,972 - lightrag - INFO - Chunk 755 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:45,973 - lightrag - INFO - Chunk 756 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498258 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:46,038 - lightrag - INFO - Chunk 758 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:46,039 - lightrag - INFO - Chunk 759 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490292 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971284 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463634 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847563 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755609 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957239 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:47,074 - lightrag - INFO - Chunk 760 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448597 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411312 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:47,334 - lightrag - INFO - Chunk 757 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:47,335 - lightrag - INFO - Chunk 761 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468535 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914666 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:47,572 - lightrag - INFO - Chunk 758 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:47,573 - lightrag - INFO - Chunk 759 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956917 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974059 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762562 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415922 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:48,677 - lightrag - INFO - Chunk 760 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396784 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449019 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:48,830 - lightrag - INFO - Chunk 762 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:48,831 - lightrag - INFO - Chunk 763 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487202 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777469 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750474 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752787 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882633 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:49,665 - lightrag - INFO - Chunk 764 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:49,666 - lightrag - INFO - Chunk 761 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491882 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475144 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:50,004 - lightrag - INFO - Chunk 765 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384661 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823389 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495091 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840049 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892226 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795782 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:50,997 - lightrag - INFO - Chunk 762 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:50,998 - lightrag - INFO - Chunk 763 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493503 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:51,164 - lightrag - INFO - Chunk 764 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:51,165 - lightrag - INFO - Chunk 766 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397699 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416059 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845931 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:51,518 - lightrag - INFO - Chunk 767 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494239 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772381 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894074 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884214 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:52,356 - lightrag - INFO - Chunk 768 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:52,358 - lightrag - INFO - Chunk 765 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467258 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376023 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:52,613 - lightrag - INFO - Chunk 766 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:52,614 - lightrag - INFO - Chunk 769 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440069 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767692 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796419 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478293 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.908652 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970622 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:53,516 - lightrag - INFO - Chunk 767 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411201 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463206 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914215 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:53,984 - lightrag - INFO - Chunk 768 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:53,985 - lightrag - INFO - Chunk 770 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479814 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958118 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:54,371 - lightrag - INFO - Chunk 771 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:54,372 - lightrag - INFO - Chunk 772 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438947 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851322 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895267 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402621 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:55,066 - lightrag - INFO - Chunk 769 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453322 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960570 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446594 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901043 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:55,728 - lightrag - INFO - Chunk 770 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:55,729 - lightrag - INFO - Chunk 773 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378090 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.799270 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790810 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:56,227 - lightrag - INFO - Chunk 771 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:56,228 - lightrag - INFO - Chunk 772 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426208 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415747 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:56,581 - lightrag - INFO - Chunk 774 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411434 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810249 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800726 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486417 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766457 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777782 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:57,478 - lightrag - INFO - Chunk 775 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:57,478 - lightrag - INFO - Chunk 776 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445490 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:57,661 - lightrag - INFO - Chunk 773 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:57,662 - lightrag - INFO - Chunk 774 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438793 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430351 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865677 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803020 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:58,189 - lightrag - INFO - Chunk 777 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499128 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871885 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895436 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496321 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:58,919 - lightrag - INFO - Chunk 775 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:58,921 - lightrag - INFO - Chunk 776 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496362 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:59,118 - lightrag - INFO - Chunk 778 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:22:59,119 - lightrag - INFO - Chunk 779 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393624 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861068 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778776 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835141 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394730 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813062 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:00,170 - lightrag - INFO - Chunk 780 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416995 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499171 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:00,362 - lightrag - INFO - Chunk 777 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:00,363 - lightrag - INFO - Chunk 778 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420028 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830288 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928068 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979027 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:00,822 - lightrag - INFO - Chunk 781 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:00,824 - lightrag - INFO - Chunk 779 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404629 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907836 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391960 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:01,646 - lightrag - INFO - Chunk 780 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444670 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423587 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921457 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949773 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:02,148 - lightrag - INFO - Chunk 782 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:02,149 - lightrag - INFO - Chunk 783 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422195 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936607 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909172 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:02,749 - lightrag - INFO - Chunk 784 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:02,750 - lightrag - INFO - Chunk 781 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480584 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387994 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:03,147 - lightrag - INFO - Chunk 782 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423610 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932162 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759031 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475858 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847007 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767682 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:04,174 - lightrag - INFO - Chunk 785 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:04,176 - lightrag - INFO - Chunk 783 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380074 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:04,212 - lightrag - INFO - Chunk 784 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:04,213 - lightrag - INFO - Chunk 786 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475215 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462235 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806749 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797360 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:04,745 - lightrag - INFO - Chunk 787 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447769 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.890094 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882122 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406027 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:05,496 - lightrag - INFO - Chunk 788 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:05,497 - lightrag - INFO - Chunk 785 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398918 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765866 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:05,794 - lightrag - INFO - Chunk 786 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:05,796 - lightrag - INFO - Chunk 789 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381205 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865231 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495211 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902681 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:06,563 - lightrag - INFO - Chunk 787 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431541 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884301 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457974 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894609 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:07,094 - lightrag - INFO - Chunk 788 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:07,095 - lightrag - INFO - Chunk 790 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404573 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826922 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:07,478 - lightrag - INFO - Chunk 791 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:07,479 - lightrag - INFO - Chunk 792 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459456 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983710 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405752 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902630 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:08,073 - lightrag - INFO - Chunk 789 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410822 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772586 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976308 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488765 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:08,866 - lightrag - INFO - Chunk 790 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:08,867 - lightrag - INFO - Chunk 793 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484156 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932753 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:09,093 - lightrag - INFO - Chunk 791 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:09,094 - lightrag - INFO - Chunk 792 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496016 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948805 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467296 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914692 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:09,930 - lightrag - INFO - Chunk 794 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398196 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798137 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466029 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811925 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:10,521 - lightrag - INFO - Chunk 795 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:10,522 - lightrag - INFO - Chunk 796 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422006 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:10,750 - lightrag - INFO - Chunk 793 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:10,751 - lightrag - INFO - Chunk 794 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443733 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792638 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783447 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383041 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894673 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887859 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:11,610 - lightrag - INFO - Chunk 797 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385977 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431110 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954682 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:12,105 - lightrag - INFO - Chunk 795 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:12,107 - lightrag - INFO - Chunk 796 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420192 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986856 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:12,443 - lightrag - INFO - Chunk 798 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:12,446 - lightrag - INFO - Chunk 799 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407177 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846234 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759300 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396709 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:13,166 - lightrag - INFO - Chunk 800 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472424 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961876 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391801 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:13,627 - lightrag - INFO - Chunk 797 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:13,628 - lightrag - INFO - Chunk 798 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435861 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830143 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803591 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866253 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:14,336 - lightrag - INFO - Chunk 801 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:14,337 - lightrag - INFO - Chunk 799 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433525 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376615 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:14,595 - lightrag - INFO - Chunk 800 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432759 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787510 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758293 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404556 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861654 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818609 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:15,575 - lightrag - INFO - Chunk 802 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:15,576 - lightrag - INFO - Chunk 803 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427407 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:15,650 - lightrag - INFO - Chunk 804 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:15,651 - lightrag - INFO - Chunk 801 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382496 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406952 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859928 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990364 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:16,183 - lightrag - INFO - Chunk 802 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468689 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756241 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446730 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:17,036 - lightrag - INFO - Chunk 805 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:17,037 - lightrag - INFO - Chunk 803 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468730 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:17,074 - lightrag - INFO - Chunk 804 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:17,074 - lightrag - INFO - Chunk 806 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437909 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841868 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437052 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852847 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892542 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:18,178 - lightrag - INFO - Chunk 807 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422010 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431788 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:18,376 - lightrag - INFO - Chunk 808 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:18,377 - lightrag - INFO - Chunk 805 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407436 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931969 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:18,768 - lightrag - INFO - Chunk 806 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:18,770 - lightrag - INFO - Chunk 809 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448378 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962118 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777656 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920104 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441192 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:19,576 - lightrag - INFO - Chunk 807 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459966 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423006 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997848 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839364 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:20,157 - lightrag - INFO - Chunk 808 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:20,158 - lightrag - INFO - Chunk 810 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770376 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867761 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:20,885 - lightrag - INFO - Chunk 811 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:20,887 - lightrag - INFO - Chunk 812 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390866 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395506 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:20,999 - lightrag - INFO - Chunk 809 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469507 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802461 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938214 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445232 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932527 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839066 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:22,095 - lightrag - INFO - Chunk 813 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:22,096 - lightrag - INFO - Chunk 810 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431818 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:22,334 - lightrag - INFO - Chunk 811 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:22,336 - lightrag - INFO - Chunk 812 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428498 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477888 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973715 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:22,711 - lightrag - INFO - Chunk 814 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497087 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810603 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783678 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961370 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494466 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:23,590 - lightrag - INFO - Chunk 815 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:23,598 - lightrag - INFO - Chunk 816 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405317 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:23,688 - lightrag - INFO - Chunk 813 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:23,689 - lightrag - INFO - Chunk 817 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429098 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781671 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863584 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864987 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481951 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836898 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:24,803 - lightrag - INFO - Chunk 814 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476135 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399037 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:24,996 - lightrag - INFO - Chunk 815 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:24,997 - lightrag - INFO - Chunk 818 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380929 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899778 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889810 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936345 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:25,513 - lightrag - INFO - Chunk 816 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:25,514 - lightrag - INFO - Chunk 819 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482305 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992709 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426476 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:26,189 - lightrag - INFO - Chunk 820 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441281 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385967 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872805 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970635 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:27,000 - lightrag - INFO - Chunk 821 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:27,001 - lightrag - INFO - Chunk 817 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469626 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:27,392 - lightrag - INFO - Chunk 818 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:27,394 - lightrag - INFO - Chunk 819 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449212 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984252 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468137 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:27,690 - lightrag - INFO - Chunk 822 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464960 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835787 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831700 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884723 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468366 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:28,721 - lightrag - INFO - Chunk 820 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:28,722 - lightrag - INFO - Chunk 823 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389548 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:28,826 - lightrag - INFO - Chunk 824 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:28,826 - lightrag - INFO - Chunk 825 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431100 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821755 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381240 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970352 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803207 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845219 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:29,774 - lightrag - INFO - Chunk 821 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484186 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391506 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:30,092 - lightrag - INFO - Chunk 822 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:30,093 - lightrag - INFO - Chunk 823 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409933 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820314 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:30,289 - lightrag - INFO - Chunk 824 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:30,290 - lightrag - INFO - Chunk 826 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424600 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955081 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989908 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872220 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493962 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:31,430 - lightrag - INFO - Chunk 827 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495282 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426993 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912114 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:31,599 - lightrag - INFO - Chunk 828 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:31,600 - lightrag - INFO - Chunk 829 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453616 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996492 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836728 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903480 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:32,516 - lightrag - INFO - Chunk 825 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:32,517 - lightrag - INFO - Chunk 826 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391804 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456210 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787434 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:32,937 - lightrag - INFO - Chunk 827 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438234 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481453 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960400 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855693 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888517 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:33,711 - lightrag - INFO - Chunk 830 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:33,712 - lightrag - INFO - Chunk 828 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434774 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862887 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:34,204 - lightrag - INFO - Chunk 831 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:34,205 - lightrag - INFO - Chunk 832 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462275 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378759 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:34,368 - lightrag - INFO - Chunk 833 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468669 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766058 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822322 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475249 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:35,399 - lightrag - INFO - Chunk 829 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:35,400 - lightrag - INFO - Chunk 830 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450369 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929581 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:35,503 - lightrag - INFO - Chunk 831 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:35,503 - lightrag - INFO - Chunk 832 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463036 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419624 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932416 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852237 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985620 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:36,438 - lightrag - INFO - Chunk 834 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478493 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444388 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:36,829 - lightrag - INFO - Chunk 835 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:36,830 - lightrag - INFO - Chunk 836 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414615 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775592 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:37,072 - lightrag - INFO - Chunk 837 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:37,073 - lightrag - INFO - Chunk 833 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449365 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943055 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988801 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816342 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441395 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898790 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:38,211 - lightrag - INFO - Chunk 834 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497110 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399776 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:38,355 - lightrag - INFO - Chunk 835 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:38,356 - lightrag - INFO - Chunk 836 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444770 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946932 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771644 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795441 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:39,064 - lightrag - INFO - Chunk 838 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:39,065 - lightrag - INFO - Chunk 839 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439639 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435909 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850262 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:39,601 - lightrag - INFO - Chunk 840 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445810 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375417 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865718 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848696 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819054 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:40,381 - lightrag - INFO - Chunk 841 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:40,382 - lightrag - INFO - Chunk 837 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450633 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:40,813 - lightrag - INFO - Chunk 838 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:40,814 - lightrag - INFO - Chunk 839 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441588 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867284 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495094 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:40,881 - lightrag - INFO - Chunk 840 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449262 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921091 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984743 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892011 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446264 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:42,192 - lightrag - INFO - Chunk 842 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:42,193 - lightrag - INFO - Chunk 843 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989668 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455048 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:42,270 - lightrag - INFO - Chunk 844 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:42,271 - lightrag - INFO - Chunk 845 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388184 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382565 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878773 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767073 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971211 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:43,199 - lightrag - INFO - Chunk 841 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464685 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:43,546 - lightrag - INFO - Chunk 842 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:43,547 - lightrag - INFO - Chunk 843 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383038 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916340 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:43,688 - lightrag - INFO - Chunk 846 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:43,689 - lightrag - INFO - Chunk 844 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420440 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950410 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991030 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893752 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394122 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:44,865 - lightrag - INFO - Chunk 847 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436914 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471374 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752112 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:45,016 - lightrag - INFO - Chunk 848 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:45,017 - lightrag - INFO - Chunk 849 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434851 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827751 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898981 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777383 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:45,740 - lightrag - INFO - Chunk 845 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:45,741 - lightrag - INFO - Chunk 846 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419167 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375711 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891203 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:46,259 - lightrag - INFO - Chunk 847 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412092 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457750 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903480 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830900 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894264 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:47,066 - lightrag - INFO - Chunk 850 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:47,068 - lightrag - INFO - Chunk 851 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433484 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:47,435 - lightrag - INFO - Chunk 848 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:47,436 - lightrag - INFO - Chunk 852 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404514 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971043 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481853 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:47,678 - lightrag - INFO - Chunk 853 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376986 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778105 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983437 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826581 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417304 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:48,635 - lightrag - INFO - Chunk 849 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:48,637 - lightrag - INFO - Chunk 850 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395897 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:48,895 - lightrag - INFO - Chunk 851 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:48,896 - lightrag - INFO - Chunk 854 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458576 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922245 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427784 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920953 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816211 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868145 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:49,842 - lightrag - INFO - Chunk 852 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465918 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417541 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:50,184 - lightrag - INFO - Chunk 855 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:50,185 - lightrag - INFO - Chunk 856 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470390 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:50,292 - lightrag - INFO - Chunk 857 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:50,293 - lightrag - INFO - Chunk 853 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417145 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994515 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831469 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782745 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950153 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381522 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:51,316 - lightrag - INFO - Chunk 854 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464912 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378558 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766142 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:51,671 - lightrag - INFO - Chunk 858 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:51,672 - lightrag - INFO - Chunk 855 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431669 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933757 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847362 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790058 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:52,391 - lightrag - INFO - Chunk 856 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:52,393 - lightrag - INFO - Chunk 859 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495542 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479054 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:52,732 - lightrag - INFO - Chunk 860 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400685 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918999 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397492 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.942706 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996857 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914394 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:53,822 - lightrag - INFO - Chunk 857 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:53,823 - lightrag - INFO - Chunk 861 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446139 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:54,114 - lightrag - INFO - Chunk 858 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:54,115 - lightrag - INFO - Chunk 862 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491193 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469018 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:54,222 - lightrag - INFO - Chunk 859 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379060 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858693 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760367 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836883 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847900 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387732 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:55,371 - lightrag - INFO - Chunk 860 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:55,373 - lightrag - INFO - Chunk 863 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452651 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:55,455 - lightrag - INFO - Chunk 864 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:55,455 - lightrag - INFO - Chunk 861 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467599 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750941 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935930 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827266 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899449 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:56,291 - lightrag - INFO - Chunk 862 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496058 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421277 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:56,773 - lightrag - INFO - Chunk 865 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:56,775 - lightrag - INFO - Chunk 866 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443111 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812331 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:56,924 - lightrag - INFO - Chunk 863 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:56,925 - lightrag - INFO - Chunk 864 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430643 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782474 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864114 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773146 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415610 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:57,980 - lightrag - INFO - Chunk 867 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492522 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814258 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435238 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:58,160 - lightrag - INFO - Chunk 868 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:58,167 - lightrag - INFO - Chunk 865 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398325 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977804 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901829 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909243 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:58,890 - lightrag - INFO - Chunk 866 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:58,891 - lightrag - INFO - Chunk 869 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446671 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851014 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459340 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:23:59,463 - lightrag - INFO - Chunk 870 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400086 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383762 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810374 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788993 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990632 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:00,207 - lightrag - INFO - Chunk 867 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:00,208 - lightrag - INFO - Chunk 868 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459307 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:00,670 - lightrag - INFO - Chunk 871 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:00,671 - lightrag - INFO - Chunk 872 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446048 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944079 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386278 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:00,905 - lightrag - INFO - Chunk 873 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474683 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945004 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931758 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943869 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448998 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:02,027 - lightrag - INFO - Chunk 869 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:02,029 - lightrag - INFO - Chunk 870 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434602 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:02,060 - lightrag - INFO - Chunk 874 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:02,060 - lightrag - INFO - Chunk 871 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448370 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872918 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401700 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919693 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863762 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873572 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:02,988 - lightrag - INFO - Chunk 872 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385075 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783891 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459971 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:03,397 - lightrag - INFO - Chunk 875 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:03,398 - lightrag - INFO - Chunk 876 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493211 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:03,626 - lightrag - INFO - Chunk 873 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:03,626 - lightrag - INFO - Chunk 877 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418082 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831616 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759586 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759610 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393952 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948526 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:04,662 - lightrag - INFO - Chunk 874 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475155 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403334 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:04,815 - lightrag - INFO - Chunk 878 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:04,816 - lightrag - INFO - Chunk 875 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375499 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873274 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932749 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907104 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:05,528 - lightrag - INFO - Chunk 876 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:05,529 - lightrag - INFO - Chunk 879 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390679 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913692 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409445 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:06,079 - lightrag - INFO - Chunk 880 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484144 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453375 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941633 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796655 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810599 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:06,850 - lightrag - INFO - Chunk 881 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:06,851 - lightrag - INFO - Chunk 877 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442718 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.764335 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:07,336 - lightrag - INFO - Chunk 878 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:07,337 - lightrag - INFO - Chunk 882 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420038 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376463 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:07,382 - lightrag - INFO - Chunk 879 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463788 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997589 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812241 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765680 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412059 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929737 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:08,580 - lightrag - INFO - Chunk 883 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:08,580 - lightrag - INFO - Chunk 880 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414939 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:08,620 - lightrag - INFO - Chunk 884 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:08,621 - lightrag - INFO - Chunk 885 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380963 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387603 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960088 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932811 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879006 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:09,423 - lightrag - INFO - Chunk 881 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491599 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779783 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499190 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:09,963 - lightrag - INFO - Chunk 882 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:09,964 - lightrag - INFO - Chunk 886 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403723 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:10,023 - lightrag - INFO - Chunk 887 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:10,023 - lightrag - INFO - Chunk 883 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418275 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875949 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984120 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818573 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402800 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997827 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:11,255 - lightrag - INFO - Chunk 884 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469074 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466127 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:11,437 - lightrag - INFO - Chunk 888 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:11,439 - lightrag - INFO - Chunk 885 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490326 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.799535 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981160 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850069 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:12,126 - lightrag - INFO - Chunk 889 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:12,128 - lightrag - INFO - Chunk 886 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377873 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876500 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414980 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:12,731 - lightrag - INFO - Chunk 890 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435161 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471652 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866574 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895404 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969222 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:13,399 - lightrag - INFO - Chunk 891 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:13,400 - lightrag - INFO - Chunk 887 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441975 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:13,848 - lightrag - INFO - Chunk 888 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:13,850 - lightrag - INFO - Chunk 892 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901351 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412825 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470154 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:14,241 - lightrag - INFO - Chunk 889 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391366 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778312 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924296 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959261 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433390 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:15,056 - lightrag - INFO - Chunk 893 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:15,056 - lightrag - INFO - Chunk 890 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483753 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903224 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:15,485 - lightrag - INFO - Chunk 894 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:15,486 - lightrag - INFO - Chunk 895 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430943 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839155 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441744 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894963 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962133 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:16,111 - lightrag - INFO - Chunk 891 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462625 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390788 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753013 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815687 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:16,827 - lightrag - INFO - Chunk 892 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:16,828 - lightrag - INFO - Chunk 896 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435663 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:17,017 - lightrag - INFO - Chunk 893 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:17,018 - lightrag - INFO - Chunk 897 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467807 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974333 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455083 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847512 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:17,608 - lightrag - INFO - Chunk 894 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499992 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.780106 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889971 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419133 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:18,343 - lightrag - INFO - Chunk 898 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:18,344 - lightrag - INFO - Chunk 899 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465884 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:18,588 - lightrag - INFO - Chunk 895 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:18,589 - lightrag - INFO - Chunk 896 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464285 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903470 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878438 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403562 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885910 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868233 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:19,585 - lightrag - INFO - Chunk 900 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408172 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455195 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:19,953 - lightrag - INFO - Chunk 897 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:19,954 - lightrag - INFO - Chunk 901 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446659 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.799256 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927510 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:20,299 - lightrag - INFO - Chunk 898 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:20,300 - lightrag - INFO - Chunk 902 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452843 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937544 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861638 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442082 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:21,094 - lightrag - INFO - Chunk 903 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405115 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770016 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:21,629 - lightrag - INFO - Chunk 899 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:21,630 - lightrag - INFO - Chunk 900 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452775 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846484 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:22,006 - lightrag - INFO - Chunk 904 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:22,007 - lightrag - INFO - Chunk 901 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424426 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817424 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471111 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978593 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:22,609 - lightrag - INFO - Chunk 905 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434219 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860256 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484840 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808185 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:23,419 - lightrag - INFO - Chunk 902 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:23,419 - lightrag - INFO - Chunk 906 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406392 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:23,689 - lightrag - INFO - Chunk 907 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:23,689 - lightrag - INFO - Chunk 903 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377579 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785583 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924836 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:24,212 - lightrag - INFO - Chunk 904 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420269 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759695 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418319 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843922 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:25,008 - lightrag - INFO - Chunk 908 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:25,009 - lightrag - INFO - Chunk 905 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460799 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850349 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:25,131 - lightrag - INFO - Chunk 909 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:25,131 - lightrag - INFO - Chunk 906 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380865 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822393 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458393 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838658 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:25,910 - lightrag - INFO - Chunk 910 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376630 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899006 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919639 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429156 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:26,362 - lightrag - INFO - Chunk 911 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:26,363 - lightrag - INFO - Chunk 907 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394233 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783094 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856716 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:26,855 - lightrag - INFO - Chunk 908 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:26,856 - lightrag - INFO - Chunk 912 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422092 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936099 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:27,532 - lightrag - INFO - Chunk 909 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484212 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380247 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901892 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854472 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888734 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:28,230 - lightrag - INFO - Chunk 913 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:28,231 - lightrag - INFO - Chunk 910 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435844 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:28,639 - lightrag - INFO - Chunk 914 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:28,641 - lightrag - INFO - Chunk 915 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443604 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832459 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404052 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:28,917 - lightrag - INFO - Chunk 911 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468222 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796666 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831351 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936038 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414911 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:29,897 - lightrag - INFO - Chunk 916 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:29,899 - lightrag - INFO - Chunk 912 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385777 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903112 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:30,118 - lightrag - INFO - Chunk 913 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:30,119 - lightrag - INFO - Chunk 917 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397583 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835549 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425378 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862189 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787065 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:30,862 - lightrag - INFO - Chunk 914 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396584 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449049 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786848 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:31,391 - lightrag - INFO - Chunk 918 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:31,392 - lightrag - INFO - Chunk 919 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497163 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:31,560 - lightrag - INFO - Chunk 915 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:31,561 - lightrag - INFO - Chunk 920 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491344 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948585 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970676 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827579 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389326 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950042 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:32,539 - lightrag - INFO - Chunk 916 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460537 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406041 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:32,896 - lightrag - INFO - Chunk 917 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:32,897 - lightrag - INFO - Chunk 921 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493346 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835550 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882724 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839488 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:33,439 - lightrag - INFO - Chunk 918 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:33,440 - lightrag - INFO - Chunk 922 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437132 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383798 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811277 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:34,181 - lightrag - INFO - Chunk 923 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408335 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455649 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861323 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856324 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:34,706 - lightrag - INFO - Chunk 919 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:34,707 - lightrag - INFO - Chunk 924 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487849 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:35,054 - lightrag - INFO - Chunk 920 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:35,055 - lightrag - INFO - Chunk 921 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402335 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946976 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847297 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490460 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:35,563 - lightrag - INFO - Chunk 925 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488086 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889696 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.780771 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386849 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:36,323 - lightrag - INFO - Chunk 922 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:36,324 - lightrag - INFO - Chunk 926 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391334 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864253 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965417 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:36,850 - lightrag - INFO - Chunk 927 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:36,852 - lightrag - INFO - Chunk 923 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380041 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465064 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774488 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891093 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:37,415 - lightrag - INFO - Chunk 924 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428174 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493573 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977475 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:38,020 - lightrag - INFO - Chunk 928 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:38,021 - lightrag - INFO - Chunk 925 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453092 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928839 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:38,229 - lightrag - INFO - Chunk 929 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:38,229 - lightrag - INFO - Chunk 926 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456682 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906433 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949693 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434131 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:39,129 - lightrag - INFO - Chunk 930 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448402 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836449 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434830 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789754 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:39,649 - lightrag - INFO - Chunk 931 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:39,650 - lightrag - INFO - Chunk 927 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439332 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947182 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763777 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:40,117 - lightrag - INFO - Chunk 928 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:40,118 - lightrag - INFO - Chunk 932 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388218 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480943 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:40,788 - lightrag - INFO - Chunk 929 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390718 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474581 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896129 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.995952 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:41,325 - lightrag - INFO - Chunk 933 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:41,326 - lightrag - INFO - Chunk 930 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412747 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819151 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.764427 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:41,773 - lightrag - INFO - Chunk 934 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:41,774 - lightrag - INFO - Chunk 935 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385381 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867473 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406613 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:42,184 - lightrag - INFO - Chunk 931 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437804 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475738 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750291 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790178 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770599 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:43,043 - lightrag - INFO - Chunk 936 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:43,044 - lightrag - INFO - Chunk 932 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458711 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:43,341 - lightrag - INFO - Chunk 933 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:43,342 - lightrag - INFO - Chunk 937 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448384 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450408 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974770 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:43,777 - lightrag - INFO - Chunk 934 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430739 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757429 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897279 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934957 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375419 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:44,557 - lightrag - INFO - Chunk 938 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:44,559 - lightrag - INFO - Chunk 939 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475439 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:44,783 - lightrag - INFO - Chunk 935 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:44,784 - lightrag - INFO - Chunk 940 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425104 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972390 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912982 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460388 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863240 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948310 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:45,854 - lightrag - INFO - Chunk 936 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489253 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448781 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:46,095 - lightrag - INFO - Chunk 937 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:46,101 - lightrag - INFO - Chunk 941 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416768 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972509 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992445 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835399 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:46,581 - lightrag - INFO - Chunk 938 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:46,581 - lightrag - INFO - Chunk 942 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439902 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985602 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438130 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:47,365 - lightrag - INFO - Chunk 943 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392906 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481918 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776431 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.967556 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911856 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:48,020 - lightrag - INFO - Chunk 939 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:48,021 - lightrag - INFO - Chunk 940 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485511 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865763 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:48,546 - lightrag - INFO - Chunk 944 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:48,547 - lightrag - INFO - Chunk 941 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436719 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398918 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:48,821 - lightrag - INFO - Chunk 942 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384638 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843693 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786648 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861158 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413957 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825449 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:49,839 - lightrag - INFO - Chunk 945 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:49,840 - lightrag - INFO - Chunk 946 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456823 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:49,944 - lightrag - INFO - Chunk 947 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:49,944 - lightrag - INFO - Chunk 943 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470603 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442871 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905764 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901978 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794748 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:50,645 - lightrag - INFO - Chunk 944 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410935 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786036 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429184 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:51,332 - lightrag - INFO - Chunk 948 of 3990 extracted 0 Ent + 0 Rel\n",
      "2025-07-07 16:24:51,333 - lightrag - INFO - Chunk 945 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:51,337 - lightrag - INFO - Chunk 946 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:51,340 - lightrag - INFO - Chunk 949 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:51,341 - lightrag - INFO - Chunk 950 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413335 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417705 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977966 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897537 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810433 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455222 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862062 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419675 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408528 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425920 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768620 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983816 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766235 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:53,186 - lightrag - INFO - Chunk 951 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:53,187 - lightrag - INFO - Chunk 952 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:53,187 - lightrag - INFO - Chunk 947 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:53,188 - lightrag - INFO - Chunk 948 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:53,189 - lightrag - INFO - Chunk 949 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472028 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847891 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448054 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481812 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450891 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854732 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907037 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838302 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435821 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789693 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:55,100 - lightrag - INFO - Chunk 950 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:55,101 - lightrag - INFO - Chunk 953 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:55,101 - lightrag - INFO - Chunk 954 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:55,102 - lightrag - INFO - Chunk 955 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:55,102 - lightrag - INFO - Chunk 956 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452581 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462502 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387798 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800974 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875634 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874686 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407387 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804431 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377343 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:56,629 - lightrag - INFO - Chunk 951 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:56,630 - lightrag - INFO - Chunk 952 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:56,631 - lightrag - INFO - Chunk 953 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:56,632 - lightrag - INFO - Chunk 954 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:56,633 - lightrag - INFO - Chunk 957 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466579 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439655 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757676 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427180 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896156 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834605 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801587 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451454 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410220 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868684 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:57,995 - lightrag - INFO - Chunk 958 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:57,996 - lightrag - INFO - Chunk 959 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:57,997 - lightrag - INFO - Chunk 960 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:58,004 - lightrag - INFO - Chunk 955 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:58,004 - lightrag - INFO - Chunk 956 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450339 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383487 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973278 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796797 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754098 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377531 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755780 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430190 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393864 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:59,364 - lightrag - INFO - Chunk 957 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:59,364 - lightrag - INFO - Chunk 958 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:59,365 - lightrag - INFO - Chunk 961 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:59,366 - lightrag - INFO - Chunk 962 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:24:59,366 - lightrag - INFO - Chunk 963 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458179 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817976 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957120 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876267 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495677 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769654 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445941 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391638 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498201 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836310 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894052 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862287 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:01,296 - lightrag - INFO - Chunk 964 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:01,297 - lightrag - INFO - Chunk 959 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:01,297 - lightrag - INFO - Chunk 960 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:01,298 - lightrag - INFO - Chunk 961 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:01,299 - lightrag - INFO - Chunk 962 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375878 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915415 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427221 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428509 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408522 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807284 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859820 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.849965 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403069 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832574 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:03,066 - lightrag - INFO - Chunk 965 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:03,067 - lightrag - INFO - Chunk 966 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:03,068 - lightrag - INFO - Chunk 967 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:03,069 - lightrag - INFO - Chunk 968 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:03,070 - lightrag - INFO - Chunk 963 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479308 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453440 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386680 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.849105 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782507 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982103 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480459 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955059 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450397 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:04,529 - lightrag - INFO - Chunk 964 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:04,530 - lightrag - INFO - Chunk 965 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:04,531 - lightrag - INFO - Chunk 966 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:04,533 - lightrag - INFO - Chunk 969 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:04,534 - lightrag - INFO - Chunk 970 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469770 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452419 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940871 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894915 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875363 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432166 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898213 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442125 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487058 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:06,107 - lightrag - INFO - Chunk 971 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:06,107 - lightrag - INFO - Chunk 972 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:06,108 - lightrag - INFO - Chunk 967 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:06,109 - lightrag - INFO - Chunk 968 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:06,110 - lightrag - INFO - Chunk 969 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388012 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829688 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859795 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852239 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498352 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463244 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823831 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477044 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457816 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.968028 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963006 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853043 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:07,976 - lightrag - INFO - Chunk 970 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:07,977 - lightrag - INFO - Chunk 973 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:07,980 - lightrag - INFO - Chunk 974 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:07,981 - lightrag - INFO - Chunk 975 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:07,982 - lightrag - INFO - Chunk 976 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378586 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843161 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383416 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407789 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430284 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771602 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941466 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842812 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478393 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784847 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:09,709 - lightrag - INFO - Chunk 971 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:09,710 - lightrag - INFO - Chunk 972 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:09,712 - lightrag - INFO - Chunk 973 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:09,714 - lightrag - INFO - Chunk 974 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:09,715 - lightrag - INFO - Chunk 977 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383640 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435109 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381734 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796687 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929188 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790338 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450608 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439003 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851984 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:11,239 - lightrag - INFO - Chunk 978 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:11,240 - lightrag - INFO - Chunk 979 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:11,240 - lightrag - INFO - Chunk 980 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:11,241 - lightrag - INFO - Chunk 975 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:11,242 - lightrag - INFO - Chunk 976 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406877 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866654 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479379 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775775 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413225 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824205 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880115 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439681 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390688 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800611 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:12,679 - lightrag - INFO - Chunk 977 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:12,680 - lightrag - INFO - Chunk 978 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:12,681 - lightrag - INFO - Chunk 981 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:12,681 - lightrag - INFO - Chunk 982 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:12,682 - lightrag - INFO - Chunk 983 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467014 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987886 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466567 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859346 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905795 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394433 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825391 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494335 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914882 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:14,504 - lightrag - INFO - Chunk 984 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:14,505 - lightrag - INFO - Chunk 979 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:14,507 - lightrag - INFO - Chunk 980 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:14,509 - lightrag - INFO - Chunk 981 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:14,510 - lightrag - INFO - Chunk 982 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430662 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757503 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422560 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907514 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935980 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408923 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481638 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939219 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845272 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479008 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:16,076 - lightrag - INFO - Chunk 985 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:16,077 - lightrag - INFO - Chunk 986 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:16,077 - lightrag - INFO - Chunk 987 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:16,078 - lightrag - INFO - Chunk 988 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:16,078 - lightrag - INFO - Chunk 983 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455811 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855605 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413995 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805117 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407546 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855079 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864686 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491314 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432156 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.967526 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:17,792 - lightrag - INFO - Chunk 984 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:17,792 - lightrag - INFO - Chunk 985 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:17,793 - lightrag - INFO - Chunk 986 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:17,794 - lightrag - INFO - Chunk 989 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:17,794 - lightrag - INFO - Chunk 990 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484475 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847792 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459879 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875452 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947252 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392630 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452717 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949373 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907496 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414977 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:19,314 - lightrag - INFO - Chunk 991 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:19,315 - lightrag - INFO - Chunk 987 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:19,316 - lightrag - INFO - Chunk 992 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:19,317 - lightrag - INFO - Chunk 988 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:19,318 - lightrag - INFO - Chunk 989 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379453 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878775 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915548 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425745 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492874 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974930 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444614 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815580 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481835 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931323 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932630 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:21,378 - lightrag - INFO - Chunk 990 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:21,379 - lightrag - INFO - Chunk 993 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:21,381 - lightrag - INFO - Chunk 994 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:21,382 - lightrag - INFO - Chunk 995 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:21,384 - lightrag - INFO - Chunk 996 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481727 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424370 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954865 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859855 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418006 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431484 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981612 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761080 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453097 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:22,817 - lightrag - INFO - Chunk 991 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:22,818 - lightrag - INFO - Chunk 992 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:22,820 - lightrag - INFO - Chunk 993 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:22,821 - lightrag - INFO - Chunk 994 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:22,822 - lightrag - INFO - Chunk 997 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446948 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460333 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857392 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450001 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982971 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901874 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452716 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406779 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824582 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924623 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:24,665 - lightrag - INFO - Chunk 998 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:24,666 - lightrag - INFO - Chunk 999 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:24,666 - lightrag - INFO - Chunk 995 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:24,667 - lightrag - INFO - Chunk 1000 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:24,667 - lightrag - INFO - Chunk 996 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474760 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490011 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977401 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856941 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439658 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475216 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813213 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753143 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397667 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:26,138 - lightrag - INFO - Chunk 997 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:26,139 - lightrag - INFO - Chunk 1001 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:26,140 - lightrag - INFO - Chunk 998 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:26,141 - lightrag - INFO - Chunk 1002 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:26,142 - lightrag - INFO - Chunk 1003 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495751 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975475 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788800 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453807 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493329 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907615 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878349 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456214 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496252 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904929 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869670 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:28,046 - lightrag - INFO - Chunk 999 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:28,047 - lightrag - INFO - Chunk 1004 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:28,047 - lightrag - INFO - Chunk 1000 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:28,048 - lightrag - INFO - Chunk 1001 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:28,048 - lightrag - INFO - Chunk 1005 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447947 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378820 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894843 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792827 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435172 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483651 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814813 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423167 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880723 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:29,403 - lightrag - INFO - Chunk 1002 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:29,404 - lightrag - INFO - Chunk 1006 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:29,404 - lightrag - INFO - Chunk 1007 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:29,405 - lightrag - INFO - Chunk 1008 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:29,406 - lightrag - INFO - Chunk 1003 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498442 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.995142 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926456 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428439 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965169 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862410 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420699 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476046 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962279 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763978 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:31,479 - lightrag - INFO - Chunk 1004 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:31,480 - lightrag - INFO - Chunk 1005 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:31,482 - lightrag - INFO - Chunk 1009 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:31,483 - lightrag - INFO - Chunk 1006 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:31,485 - lightrag - INFO - Chunk 1010 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474898 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495122 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803450 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944214 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493009 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426086 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777992 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948354 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472951 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:33,033 - lightrag - INFO - Chunk 1011 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:33,033 - lightrag - INFO - Chunk 1007 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:33,034 - lightrag - INFO - Chunk 1012 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:33,034 - lightrag - INFO - Chunk 1008 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:33,035 - lightrag - INFO - Chunk 1009 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405535 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832541 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438451 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907705 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886311 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803257 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384798 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379299 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767254 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:34,709 - lightrag - INFO - Chunk 1010 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:34,710 - lightrag - INFO - Chunk 1013 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:34,711 - lightrag - INFO - Chunk 1014 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:34,712 - lightrag - INFO - Chunk 1015 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:34,713 - lightrag - INFO - Chunk 1011 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492508 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984504 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790995 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852620 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477469 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987297 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454365 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425174 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:36,105 - lightrag - INFO - Chunk 1016 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:36,105 - lightrag - INFO - Chunk 1012 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:36,106 - lightrag - INFO - Chunk 1013 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:36,106 - lightrag - INFO - Chunk 1014 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:36,107 - lightrag - INFO - Chunk 1017 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448568 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984645 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807461 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871968 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422083 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781139 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464041 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428445 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380573 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884429 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874090 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761597 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:37,946 - lightrag - INFO - Chunk 1018 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:37,947 - lightrag - INFO - Chunk 1019 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:37,948 - lightrag - INFO - Chunk 1015 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:37,949 - lightrag - INFO - Chunk 1020 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:37,951 - lightrag - INFO - Chunk 1016 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491456 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898989 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410281 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419800 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390390 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888087 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809727 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861232 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470317 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:39,801 - lightrag - INFO - Chunk 1017 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:39,802 - lightrag - INFO - Chunk 1018 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:39,803 - lightrag - INFO - Chunk 1021 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:39,805 - lightrag - INFO - Chunk 1022 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:39,806 - lightrag - INFO - Chunk 1023 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494437 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765313 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387985 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480704 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826263 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963594 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879106 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459168 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868926 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446212 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:41,258 - lightrag - INFO - Chunk 1024 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:41,258 - lightrag - INFO - Chunk 1019 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:41,259 - lightrag - INFO - Chunk 1020 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:41,259 - lightrag - INFO - Chunk 1021 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:41,260 - lightrag - INFO - Chunk 1025 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444151 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479790 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971107 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868568 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903455 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457112 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751320 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405865 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407058 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:42,670 - lightrag - INFO - Chunk 1022 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:42,670 - lightrag - INFO - Chunk 1026 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:42,671 - lightrag - INFO - Chunk 1027 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:42,672 - lightrag - INFO - Chunk 1028 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:42,673 - lightrag - INFO - Chunk 1023 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444847 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895592 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814705 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.925010 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487054 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923269 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480668 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424375 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394062 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798216 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858771 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905371 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:44,619 - lightrag - INFO - Chunk 1024 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:44,622 - lightrag - INFO - Chunk 1029 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:44,625 - lightrag - INFO - Chunk 1025 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:44,626 - lightrag - INFO - Chunk 1026 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:44,628 - lightrag - INFO - Chunk 1030 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406180 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975481 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399630 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492133 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418631 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895226 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808080 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862037 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375978 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:46,396 - lightrag - INFO - Chunk 1031 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:46,397 - lightrag - INFO - Chunk 1032 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:46,397 - lightrag - INFO - Chunk 1027 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:46,398 - lightrag - INFO - Chunk 1028 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:46,399 - lightrag - INFO - Chunk 1033 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375840 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911744 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395358 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411625 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945669 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867453 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989006 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455419 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467697 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:47,747 - lightrag - INFO - Chunk 1029 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:47,748 - lightrag - INFO - Chunk 1030 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:47,749 - lightrag - INFO - Chunk 1034 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:47,750 - lightrag - INFO - Chunk 1035 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:47,751 - lightrag - INFO - Chunk 1036 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377927 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795540 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401421 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850570 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.942510 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822734 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434590 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467623 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775319 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392805 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:49,306 - lightrag - INFO - Chunk 1031 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:49,306 - lightrag - INFO - Chunk 1032 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:49,307 - lightrag - INFO - Chunk 1033 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:49,308 - lightrag - INFO - Chunk 1037 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:49,309 - lightrag - INFO - Chunk 1034 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377278 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896562 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855626 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845269 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486025 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984762 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403636 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418242 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475412 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957068 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893742 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832935 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:51,304 - lightrag - INFO - Chunk 1038 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:51,305 - lightrag - INFO - Chunk 1039 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:51,306 - lightrag - INFO - Chunk 1040 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:51,307 - lightrag - INFO - Chunk 1035 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:51,309 - lightrag - INFO - Chunk 1036 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398334 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800203 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404033 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378041 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400202 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888654 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753080 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453839 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:52,898 - lightrag - INFO - Chunk 1041 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:52,899 - lightrag - INFO - Chunk 1037 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:52,901 - lightrag - INFO - Chunk 1038 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:52,903 - lightrag - INFO - Chunk 1042 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:52,905 - lightrag - INFO - Chunk 1043 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419956 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831520 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493681 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476911 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894240 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951124 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980048 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380107 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865875 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459828 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:54,479 - lightrag - INFO - Chunk 1039 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:54,479 - lightrag - INFO - Chunk 1044 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:54,480 - lightrag - INFO - Chunk 1040 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:54,481 - lightrag - INFO - Chunk 1045 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:54,482 - lightrag - INFO - Chunk 1041 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438440 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492209 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876066 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766573 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955995 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392677 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811469 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441361 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493219 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:55,967 - lightrag - INFO - Chunk 1042 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:55,968 - lightrag - INFO - Chunk 1046 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:55,968 - lightrag - INFO - Chunk 1047 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:55,969 - lightrag - INFO - Chunk 1043 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:55,970 - lightrag - INFO - Chunk 1048 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446798 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873515 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834482 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496914 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821130 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857143 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438115 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466884 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458253 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969363 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797587 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:57,662 - lightrag - INFO - Chunk 1044 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:57,663 - lightrag - INFO - Chunk 1049 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:57,664 - lightrag - INFO - Chunk 1045 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:57,665 - lightrag - INFO - Chunk 1046 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:57,666 - lightrag - INFO - Chunk 1050 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407384 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821653 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788602 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498602 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470529 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469991 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878133 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919530 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450690 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846671 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876764 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:59,689 - lightrag - INFO - Chunk 1047 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:59,689 - lightrag - INFO - Chunk 1051 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:59,693 - lightrag - INFO - Chunk 1052 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:59,694 - lightrag - INFO - Chunk 1048 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:25:59,695 - lightrag - INFO - Chunk 1049 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437217 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421594 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442445 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793659 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813290 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494680 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800296 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914724 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418735 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:00,994 - lightrag - INFO - Chunk 1053 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:00,995 - lightrag - INFO - Chunk 1050 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:00,995 - lightrag - INFO - Chunk 1054 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:00,996 - lightrag - INFO - Chunk 1051 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:00,997 - lightrag - INFO - Chunk 1055 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379257 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390430 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802288 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771817 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763608 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487956 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862013 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378102 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479513 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:02,277 - lightrag - INFO - Chunk 1056 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:02,278 - lightrag - INFO - Chunk 1052 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:02,278 - lightrag - INFO - Chunk 1057 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:02,279 - lightrag - INFO - Chunk 1053 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:02,280 - lightrag - INFO - Chunk 1054 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492903 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962998 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976135 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891831 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435780 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475250 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428237 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479757 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909807 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836794 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953996 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:04,433 - lightrag - INFO - Chunk 1058 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:04,434 - lightrag - INFO - Chunk 1055 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:04,435 - lightrag - INFO - Chunk 1059 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:04,440 - lightrag - INFO - Chunk 1060 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:04,441 - lightrag - INFO - Chunk 1056 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489381 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453460 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410187 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978960 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497655 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910934 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822910 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878202 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396168 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:06,203 - lightrag - INFO - Chunk 1061 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:06,204 - lightrag - INFO - Chunk 1057 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:06,204 - lightrag - INFO - Chunk 1058 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:06,205 - lightrag - INFO - Chunk 1062 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:06,206 - lightrag - INFO - Chunk 1059 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412821 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989153 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375597 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789631 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976788 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900979 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414772 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404542 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:07,662 - lightrag - INFO - Chunk 1063 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:07,662 - lightrag - INFO - Chunk 1064 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:07,663 - lightrag - INFO - Chunk 1060 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:07,664 - lightrag - INFO - Chunk 1065 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:07,665 - lightrag - INFO - Chunk 1061 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882378 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376218 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784271 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932732 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.993110 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407804 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450754 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408044 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825004 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927838 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:09,167 - lightrag - INFO - Chunk 1062 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:09,167 - lightrag - INFO - Chunk 1066 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:09,167 - lightrag - INFO - Chunk 1063 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:09,168 - lightrag - INFO - Chunk 1067 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:09,168 - lightrag - INFO - Chunk 1068 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429418 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992837 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997912 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472481 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489716 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999516 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442715 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824710 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457073 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773308 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874075 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:11,386 - lightrag - INFO - Chunk 1064 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:11,387 - lightrag - INFO - Chunk 1069 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:11,388 - lightrag - INFO - Chunk 1065 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:11,390 - lightrag - INFO - Chunk 1066 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:11,392 - lightrag - INFO - Chunk 1070 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400387 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416965 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405421 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952033 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.925958 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479829 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803542 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944472 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469188 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:12,766 - lightrag - INFO - Chunk 1067 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:12,767 - lightrag - INFO - Chunk 1071 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:12,767 - lightrag - INFO - Chunk 1072 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:12,768 - lightrag - INFO - Chunk 1068 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:12,768 - lightrag - INFO - Chunk 1073 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444681 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404525 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821294 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776274 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841332 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419460 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893350 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449082 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492290 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:14,140 - lightrag - INFO - Chunk 1069 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:14,141 - lightrag - INFO - Chunk 1070 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:14,141 - lightrag - INFO - Chunk 1074 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:14,142 - lightrag - INFO - Chunk 1071 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:14,143 - lightrag - INFO - Chunk 1075 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414814 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858684 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893578 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863482 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466331 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953749 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439990 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478065 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467789 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894974 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760800 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884715 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:16,149 - lightrag - INFO - Chunk 1076 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:16,150 - lightrag - INFO - Chunk 1072 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:16,151 - lightrag - INFO - Chunk 1077 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:16,152 - lightrag - INFO - Chunk 1073 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:16,154 - lightrag - INFO - Chunk 1074 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413036 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940959 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477981 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484852 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397424 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760326 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812504 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866269 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870523 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:17,943 - lightrag - INFO - Chunk 1078 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:17,944 - lightrag - INFO - Chunk 1079 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:17,945 - lightrag - INFO - Chunk 1075 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:17,946 - lightrag - INFO - Chunk 1080 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:17,947 - lightrag - INFO - Chunk 1076 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478741 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384111 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395112 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767438 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788778 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760072 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477334 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459416 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:19,239 - lightrag - INFO - Chunk 1081 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:19,239 - lightrag - INFO - Chunk 1077 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:19,240 - lightrag - INFO - Chunk 1078 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:19,240 - lightrag - INFO - Chunk 1082 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:19,241 - lightrag - INFO - Chunk 1083 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454978 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455259 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836431 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970662 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900415 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823765 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414009 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412254 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847224 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:20,616 - lightrag - INFO - Chunk 1079 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:20,617 - lightrag - INFO - Chunk 1084 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:20,617 - lightrag - INFO - Chunk 1080 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:20,618 - lightrag - INFO - Chunk 1085 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470652 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:20,618 - lightrag - INFO - Chunk 1081 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466931 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754013 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872160 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852638 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387279 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471606 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.799250 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498968 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394302 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819426 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810039 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846794 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:22,616 - lightrag - INFO - Chunk 1082 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:22,617 - lightrag - INFO - Chunk 1086 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:22,618 - lightrag - INFO - Chunk 1087 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:22,620 - lightrag - INFO - Chunk 1083 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:22,622 - lightrag - INFO - Chunk 1088 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481652 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399195 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761154 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443672 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394020 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989974 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893962 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763931 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478248 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948074 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:24,426 - lightrag - INFO - Chunk 1084 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:24,427 - lightrag - INFO - Chunk 1085 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:24,427 - lightrag - INFO - Chunk 1089 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:24,428 - lightrag - INFO - Chunk 1086 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:24,429 - lightrag - INFO - Chunk 1090 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396861 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446380 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934938 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797064 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402783 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401629 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864727 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:25,782 - lightrag - INFO - Chunk 1087 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:25,783 - lightrag - INFO - Chunk 1091 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:25,783 - lightrag - INFO - Chunk 1092 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:25,784 - lightrag - INFO - Chunk 1088 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:25,784 - lightrag - INFO - Chunk 1089 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439995 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457422 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955323 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848625 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781023 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396445 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991581 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485735 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448779 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:27,080 - lightrag - INFO - Chunk 1093 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:27,081 - lightrag - INFO - Chunk 1090 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:27,082 - lightrag - INFO - Chunk 1094 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:27,083 - lightrag - INFO - Chunk 1095 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:27,083 - lightrag - INFO - Chunk 1091 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473769 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955187 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921494 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894168 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475201 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497538 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490997 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439068 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775164 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851621 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811774 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.995430 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:29,263 - lightrag - INFO - Chunk 1096 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:29,264 - lightrag - INFO - Chunk 1097 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:29,266 - lightrag - INFO - Chunk 1092 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:29,267 - lightrag - INFO - Chunk 1093 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:29,269 - lightrag - INFO - Chunk 1094 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391670 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759762 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491661 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382353 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404960 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951657 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894678 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963283 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439900 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818844 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:31,140 - lightrag - INFO - Chunk 1095 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:31,141 - lightrag - INFO - Chunk 1098 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:31,142 - lightrag - INFO - Chunk 1099 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:31,143 - lightrag - INFO - Chunk 1100 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:31,144 - lightrag - INFO - Chunk 1096 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445166 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447257 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402186 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828972 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845559 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484913 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804782 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944536 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436943 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:32,480 - lightrag - INFO - Chunk 1101 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:32,481 - lightrag - INFO - Chunk 1097 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:32,481 - lightrag - INFO - Chunk 1098 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:32,482 - lightrag - INFO - Chunk 1099 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:32,483 - lightrag - INFO - Chunk 1102 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425823 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990240 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834066 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840957 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427828 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784065 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464964 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472833 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:33,895 - lightrag - INFO - Chunk 1103 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:33,901 - lightrag - INFO - Chunk 1104 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:33,903 - lightrag - INFO - Chunk 1105 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:33,904 - lightrag - INFO - Chunk 1100 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:33,905 - lightrag - INFO - Chunk 1101 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433604 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997252 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791767 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753391 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433714 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760142 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411745 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476564 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461170 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795708 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:35,575 - lightrag - INFO - Chunk 1102 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:35,575 - lightrag - INFO - Chunk 1106 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:35,576 - lightrag - INFO - Chunk 1107 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:35,577 - lightrag - INFO - Chunk 1103 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:35,578 - lightrag - INFO - Chunk 1108 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427312 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818659 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934030 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759465 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432139 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445832 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417416 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932960 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489620 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867740 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869228 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940391 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:37,697 - lightrag - INFO - Chunk 1109 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:37,698 - lightrag - INFO - Chunk 1104 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:37,699 - lightrag - INFO - Chunk 1105 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:37,702 - lightrag - INFO - Chunk 1106 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:37,704 - lightrag - INFO - Chunk 1110 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455627 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488678 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495086 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929990 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389068 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910843 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777065 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844152 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430175 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:39,183 - lightrag - INFO - Chunk 1111 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:39,184 - lightrag - INFO - Chunk 1107 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:39,185 - lightrag - INFO - Chunk 1112 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:39,187 - lightrag - INFO - Chunk 1113 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:39,189 - lightrag - INFO - Chunk 1108 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407135 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499940 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487579 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912067 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848935 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793012 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898052 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432270 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419927 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:40,575 - lightrag - INFO - Chunk 1109 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:40,577 - lightrag - INFO - Chunk 1110 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:40,580 - lightrag - INFO - Chunk 1114 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:40,583 - lightrag - INFO - Chunk 1115 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:40,584 - lightrag - INFO - Chunk 1111 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394615 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497329 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951616 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887210 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917947 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914063 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473011 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437979 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496502 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926208 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798089 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:42,334 - lightrag - INFO - Chunk 1116 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:42,335 - lightrag - INFO - Chunk 1117 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:42,336 - lightrag - INFO - Chunk 1112 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:42,336 - lightrag - INFO - Chunk 1113 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:42,337 - lightrag - INFO - Chunk 1114 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376332 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963200 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792770 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492520 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438789 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453675 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469313 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981064 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845252 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801389 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911819 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:44,507 - lightrag - INFO - Chunk 1118 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:44,509 - lightrag - INFO - Chunk 1119 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:44,510 - lightrag - INFO - Chunk 1115 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:44,512 - lightrag - INFO - Chunk 1120 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:44,514 - lightrag - INFO - Chunk 1116 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425961 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437591 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418433 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982630 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486026 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970431 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.995435 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864115 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394514 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:46,027 - lightrag - INFO - Chunk 1121 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:46,028 - lightrag - INFO - Chunk 1117 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:46,029 - lightrag - INFO - Chunk 1118 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:46,029 - lightrag - INFO - Chunk 1122 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:46,030 - lightrag - INFO - Chunk 1123 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491084 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465873 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418199 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829294 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923326 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871003 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985983 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481364 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479692 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:47,452 - lightrag - INFO - Chunk 1119 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:47,453 - lightrag - INFO - Chunk 1124 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:47,454 - lightrag - INFO - Chunk 1120 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:47,455 - lightrag - INFO - Chunk 1121 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:47,456 - lightrag - INFO - Chunk 1125 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483369 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946023 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399127 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976740 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874505 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835085 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435733 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463965 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483120 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:48,968 - lightrag - INFO - Chunk 1122 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:48,969 - lightrag - INFO - Chunk 1126 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:48,970 - lightrag - INFO - Chunk 1123 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:48,971 - lightrag - INFO - Chunk 1127 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:48,972 - lightrag - INFO - Chunk 1128 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826327 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.849378 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766065 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462137 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444583 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407095 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419100 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964481 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840209 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806125 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754312 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:51,313 - lightrag - INFO - Chunk 1124 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:51,314 - lightrag - INFO - Chunk 1125 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:51,315 - lightrag - INFO - Chunk 1126 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:51,317 - lightrag - INFO - Chunk 1129 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:51,319 - lightrag - INFO - Chunk 1130 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398318 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444765 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459685 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445424 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874961 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991297 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782550 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958445 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390422 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:52,656 - lightrag - INFO - Chunk 1131 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:52,657 - lightrag - INFO - Chunk 1127 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:52,658 - lightrag - INFO - Chunk 1132 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:52,659 - lightrag - INFO - Chunk 1128 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:52,660 - lightrag - INFO - Chunk 1133 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477644 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384641 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430732 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826957 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871779 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931050 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798226 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386774 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422708 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:54,099 - lightrag - INFO - Chunk 1129 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:54,099 - lightrag - INFO - Chunk 1130 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:54,100 - lightrag - INFO - Chunk 1134 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:54,101 - lightrag - INFO - Chunk 1135 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:54,105 - lightrag - INFO - Chunk 1136 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494013 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449463 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954144 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962485 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974917 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779767 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441751 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393895 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438089 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:55,591 - lightrag - INFO - Chunk 1131 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:55,592 - lightrag - INFO - Chunk 1132 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:55,593 - lightrag - INFO - Chunk 1133 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:55,594 - lightrag - INFO - Chunk 1137 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:55,594 - lightrag - INFO - Chunk 1134 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499509 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816173 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804744 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997286 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395777 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382273 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465882 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933776 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906148 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376094 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856732 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790447 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:57,927 - lightrag - INFO - Chunk 1138 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:57,929 - lightrag - INFO - Chunk 1139 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:57,931 - lightrag - INFO - Chunk 1140 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: Connection error.\n",
      "2025-07-07 16:26:57,934 - lightrag - INFO - Chunk 1135 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:57,936 - lightrag - INFO - Chunk 1136 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375234 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383827 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459170 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:58,281 - lightrag - INFO - Chunk 1137 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835314 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789218 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795657 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906840 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487411 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:59,159 - lightrag - INFO - Chunk 1141 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:59,160 - lightrag - INFO - Chunk 1138 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393252 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:59,263 - lightrag - INFO - Chunk 1142 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:26:59,263 - lightrag - INFO - Chunk 1143 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458655 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916954 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778308 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383588 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752389 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783419 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:00,402 - lightrag - INFO - Chunk 1144 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403368 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438934 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:00,484 - lightrag - INFO - Chunk 1139 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:00,485 - lightrag - INFO - Chunk 1140 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452804 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760044 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:00,857 - lightrag - INFO - Chunk 1141 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:00,859 - lightrag - INFO - Chunk 1145 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462447 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778919 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818867 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476164 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:01,711 - lightrag - INFO - Chunk 1142 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429470 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490532 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.890157 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962450 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:02,151 - lightrag - INFO - Chunk 1146 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:02,152 - lightrag - INFO - Chunk 1147 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399160 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.764297 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927581 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:02,966 - lightrag - INFO - Chunk 1148 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:02,967 - lightrag - INFO - Chunk 1143 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493486 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404122 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:03,122 - lightrag - INFO - Chunk 1144 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420688 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775091 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482139 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952589 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972125 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759298 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:04,259 - lightrag - INFO - Chunk 1145 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:04,260 - lightrag - INFO - Chunk 1149 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474745 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:04,486 - lightrag - INFO - Chunk 1146 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:04,487 - lightrag - INFO - Chunk 1150 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462730 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426977 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794893 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:04,747 - lightrag - INFO - Chunk 1151 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438291 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785572 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824363 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772535 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458992 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:05,749 - lightrag - INFO - Chunk 1152 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:05,750 - lightrag - INFO - Chunk 1147 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411528 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:05,810 - lightrag - INFO - Chunk 1148 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:05,810 - lightrag - INFO - Chunk 1149 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392363 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473776 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977143 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901012 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874996 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916527 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:06,997 - lightrag - INFO - Chunk 1153 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487696 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466688 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:07,090 - lightrag - INFO - Chunk 1150 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:07,091 - lightrag - INFO - Chunk 1154 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428245 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:07,372 - lightrag - INFO - Chunk 1155 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:07,373 - lightrag - INFO - Chunk 1156 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451039 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929652 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817610 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891662 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773054 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382782 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:08,426 - lightrag - INFO - Chunk 1151 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401326 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406943 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:08,613 - lightrag - INFO - Chunk 1157 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:08,614 - lightrag - INFO - Chunk 1152 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414585 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991531 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798851 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913615 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796573 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:09,641 - lightrag - INFO - Chunk 1153 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:09,642 - lightrag - INFO - Chunk 1154 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397890 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394758 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:09,778 - lightrag - INFO - Chunk 1158 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391217 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421980 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878012 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858447 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856798 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797325 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:10,934 - lightrag - INFO - Chunk 1159 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:10,936 - lightrag - INFO - Chunk 1160 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418913 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:11,002 - lightrag - INFO - Chunk 1155 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:11,006 - lightrag - INFO - Chunk 1161 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471103 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462745 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:11,063 - lightrag - INFO - Chunk 1156 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487352 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767584 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893899 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835917 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788394 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476994 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:12,344 - lightrag - INFO - Chunk 1157 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:12,345 - lightrag - INFO - Chunk 1158 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436899 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:12,349 - lightrag - INFO - Chunk 1162 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:12,349 - lightrag - INFO - Chunk 1163 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474131 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386896 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883772 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988376 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946691 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985136 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:13,515 - lightrag - INFO - Chunk 1159 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453562 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436088 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:13,781 - lightrag - INFO - Chunk 1164 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:13,781 - lightrag - INFO - Chunk 1165 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491924 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:13,836 - lightrag - INFO - Chunk 1160 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:13,836 - lightrag - INFO - Chunk 1161 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423881 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825408 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957290 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793437 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916970 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431465 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:15,070 - lightrag - INFO - Chunk 1162 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462335 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401321 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:15,201 - lightrag - INFO - Chunk 1166 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:15,202 - lightrag - INFO - Chunk 1167 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375100 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870582 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808960 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846006 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934554 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:16,130 - lightrag - INFO - Chunk 1168 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:16,131 - lightrag - INFO - Chunk 1163 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393154 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402409 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:16,412 - lightrag - INFO - Chunk 1169 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448900 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495830 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782933 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796727 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818852 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959172 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:17,322 - lightrag - INFO - Chunk 1164 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:17,323 - lightrag - INFO - Chunk 1165 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385610 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:17,563 - lightrag - INFO - Chunk 1166 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:17,564 - lightrag - INFO - Chunk 1170 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490359 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469103 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847266 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:17,989 - lightrag - INFO - Chunk 1171 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396663 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800805 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807701 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844684 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463177 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:18,868 - lightrag - INFO - Chunk 1172 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:18,869 - lightrag - INFO - Chunk 1167 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378805 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:18,976 - lightrag - INFO - Chunk 1173 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:18,976 - lightrag - INFO - Chunk 1168 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474110 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885419 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401118 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852099 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854449 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:19,955 - lightrag - INFO - Chunk 1169 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454207 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386100 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:20,289 - lightrag - INFO - Chunk 1170 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:20,290 - lightrag - INFO - Chunk 1174 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454856 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825008 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824496 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:20,514 - lightrag - INFO - Chunk 1175 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:20,515 - lightrag - INFO - Chunk 1176 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477886 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994903 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762110 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459519 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:21,330 - lightrag - INFO - Chunk 1171 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412251 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996473 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.967842 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415947 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:21,765 - lightrag - INFO - Chunk 1177 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:21,766 - lightrag - INFO - Chunk 1172 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457553 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779974 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963562 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:22,723 - lightrag - INFO - Chunk 1173 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:22,725 - lightrag - INFO - Chunk 1174 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443384 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400736 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:22,963 - lightrag - INFO - Chunk 1178 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490153 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837328 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987978 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455849 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874146 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987424 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:23,981 - lightrag - INFO - Chunk 1179 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:23,982 - lightrag - INFO - Chunk 1180 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395888 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:24,172 - lightrag - INFO - Chunk 1175 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:24,173 - lightrag - INFO - Chunk 1176 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455927 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498339 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752552 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827596 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:24,654 - lightrag - INFO - Chunk 1181 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462095 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888803 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864401 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422085 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:25,467 - lightrag - INFO - Chunk 1177 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:25,468 - lightrag - INFO - Chunk 1178 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445960 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917749 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:25,740 - lightrag - INFO - Chunk 1182 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:25,741 - lightrag - INFO - Chunk 1183 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390448 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805691 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444653 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906354 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795514 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:26,501 - lightrag - INFO - Chunk 1184 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491357 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470737 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905592 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:27,047 - lightrag - INFO - Chunk 1179 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:27,048 - lightrag - INFO - Chunk 1180 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458504 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781421 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:27,245 - lightrag - INFO - Chunk 1185 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:27,246 - lightrag - INFO - Chunk 1181 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446558 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882707 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777183 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481909 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:27,993 - lightrag - INFO - Chunk 1182 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448617 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.881306 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495909 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905499 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:28,481 - lightrag - INFO - Chunk 1186 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:28,481 - lightrag - INFO - Chunk 1187 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440300 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956617 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819596 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:29,292 - lightrag - INFO - Chunk 1188 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:29,293 - lightrag - INFO - Chunk 1183 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450818 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381205 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755695 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:29,754 - lightrag - INFO - Chunk 1184 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903671 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426951 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475123 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998350 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936289 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:30,509 - lightrag - INFO - Chunk 1189 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:30,510 - lightrag - INFO - Chunk 1185 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397629 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:30,663 - lightrag - INFO - Chunk 1186 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:30,663 - lightrag - INFO - Chunk 1190 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393376 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815526 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757172 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482676 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:31,291 - lightrag - INFO - Chunk 1191 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480358 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892513 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391660 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984045 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:31,824 - lightrag - INFO - Chunk 1192 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:31,825 - lightrag - INFO - Chunk 1187 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395677 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980816 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997076 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:32,583 - lightrag - INFO - Chunk 1188 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:32,584 - lightrag - INFO - Chunk 1193 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437880 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772050 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:33,121 - lightrag - INFO - Chunk 1189 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417344 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788859 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385768 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892236 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900310 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:33,874 - lightrag - INFO - Chunk 1190 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:33,875 - lightrag - INFO - Chunk 1194 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488675 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:34,001 - lightrag - INFO - Chunk 1195 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:34,002 - lightrag - INFO - Chunk 1196 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476788 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930036 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400863 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900157 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:34,536 - lightrag - INFO - Chunk 1191 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411887 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846733 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998115 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420691 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:35,389 - lightrag - INFO - Chunk 1192 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:35,391 - lightrag - INFO - Chunk 1197 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411935 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:35,705 - lightrag - INFO - Chunk 1193 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:35,706 - lightrag - INFO - Chunk 1194 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413414 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982765 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917447 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380025 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788308 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871020 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:36,728 - lightrag - INFO - Chunk 1198 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447753 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479584 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:36,919 - lightrag - INFO - Chunk 1199 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:36,920 - lightrag - INFO - Chunk 1200 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389474 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901727 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932079 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:37,220 - lightrag - INFO - Chunk 1195 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:37,221 - lightrag - INFO - Chunk 1196 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461792 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872529 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873801 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383273 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:38,158 - lightrag - INFO - Chunk 1201 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491723 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453903 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781503 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:38,569 - lightrag - INFO - Chunk 1197 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:38,570 - lightrag - INFO - Chunk 1198 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397648 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795731 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816456 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951866 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:39,272 - lightrag - INFO - Chunk 1202 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:39,273 - lightrag - INFO - Chunk 1203 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498662 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378297 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:39,476 - lightrag - INFO - Chunk 1204 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413928 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884228 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916087 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765971 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425661 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848043 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:40,669 - lightrag - INFO - Chunk 1199 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:40,671 - lightrag - INFO - Chunk 1200 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:40,677 - lightrag - INFO - Chunk 1205 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:40,678 - lightrag - INFO - Chunk 1206 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380441 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485069 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400267 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776012 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866277 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848627 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:41,219 - lightrag - INFO - Chunk 1201 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399399 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905570 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445296 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:42,026 - lightrag - INFO - Chunk 1202 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:42,027 - lightrag - INFO - Chunk 1207 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496077 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:42,037 - lightrag - INFO - Chunk 1208 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:42,038 - lightrag - INFO - Chunk 1203 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498651 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802495 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996313 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818169 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416329 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906333 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:43,105 - lightrag - INFO - Chunk 1204 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382123 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:43,539 - lightrag - INFO - Chunk 1209 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:43,540 - lightrag - INFO - Chunk 1210 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442105 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758117 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992526 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:43,881 - lightrag - INFO - Chunk 1205 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:43,883 - lightrag - INFO - Chunk 1206 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390762 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759297 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.967051 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494327 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:44,756 - lightrag - INFO - Chunk 1211 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394050 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439860 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847952 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979778 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963842 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:45,258 - lightrag - INFO - Chunk 1212 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:45,259 - lightrag - INFO - Chunk 1207 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462322 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:45,684 - lightrag - INFO - Chunk 1208 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:45,685 - lightrag - INFO - Chunk 1213 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463685 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805062 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415883 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826246 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:46,177 - lightrag - INFO - Chunk 1214 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392663 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440910 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944523 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984521 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987287 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:46,990 - lightrag - INFO - Chunk 1209 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:46,992 - lightrag - INFO - Chunk 1210 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461160 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953778 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:47,520 - lightrag - INFO - Chunk 1215 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:47,521 - lightrag - INFO - Chunk 1216 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495949 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451233 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:47,979 - lightrag - INFO - Chunk 1211 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378689 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863851 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919212 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759679 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403730 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831917 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:48,885 - lightrag - INFO - Chunk 1212 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:48,886 - lightrag - INFO - Chunk 1217 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497025 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:48,945 - lightrag - INFO - Chunk 1218 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:48,946 - lightrag - INFO - Chunk 1213 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416517 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473089 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806613 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753249 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846685 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:49,674 - lightrag - INFO - Chunk 1214 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494405 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407657 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:50,182 - lightrag - INFO - Chunk 1219 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:50,183 - lightrag - INFO - Chunk 1220 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474737 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819506 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:50,462 - lightrag - INFO - Chunk 1215 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:50,463 - lightrag - INFO - Chunk 1216 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485281 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854482 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752701 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976627 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487687 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:51,425 - lightrag - INFO - Chunk 1221 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419992 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484928 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819081 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877741 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914974 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:51,936 - lightrag - INFO - Chunk 1222 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:51,937 - lightrag - INFO - Chunk 1217 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:51,938 - lightrag - INFO - Chunk 1218 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438631 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:52,349 - lightrag - INFO - Chunk 1223 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440530 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840020 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382517 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766415 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445340 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805749 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:53,258 - lightrag - INFO - Chunk 1224 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400363 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921692 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:53,571 - lightrag - INFO - Chunk 1219 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:53,572 - lightrag - INFO - Chunk 1220 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:53,574 - lightrag - INFO - Chunk 1225 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497407 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851296 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:53,943 - lightrag - INFO - Chunk 1226 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426602 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775932 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408945 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839871 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493282 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901775 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:54,860 - lightrag - INFO - Chunk 1221 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398281 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891899 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:55,228 - lightrag - INFO - Chunk 1222 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:55,229 - lightrag - INFO - Chunk 1227 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:55,231 - lightrag - INFO - Chunk 1228 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433850 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912497 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:55,561 - lightrag - INFO - Chunk 1223 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384976 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.995285 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416243 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784663 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472048 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953874 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:56,674 - lightrag - INFO - Chunk 1224 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424383 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:56,749 - lightrag - INFO - Chunk 1229 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:56,750 - lightrag - INFO - Chunk 1230 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:56,751 - lightrag - INFO - Chunk 1225 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477452 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924078 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953826 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:57,300 - lightrag - INFO - Chunk 1226 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455074 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431261 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950109 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901638 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410433 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:58,196 - lightrag - INFO - Chunk 1231 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495071 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798375 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800941 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:58,724 - lightrag - INFO - Chunk 1232 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:58,725 - lightrag - INFO - Chunk 1227 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:58,726 - lightrag - INFO - Chunk 1228 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391665 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:58,805 - lightrag - INFO - Chunk 1233 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421008 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761818 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820225 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424606 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485701 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933672 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:27:59,899 - lightrag - INFO - Chunk 1234 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386993 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869833 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:00,059 - lightrag - INFO - Chunk 1229 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:00,060 - lightrag - INFO - Chunk 1230 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:00,061 - lightrag - INFO - Chunk 1235 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411913 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819803 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926474 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:00,637 - lightrag - INFO - Chunk 1236 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380528 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430781 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941610 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421936 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771696 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:01,408 - lightrag - INFO - Chunk 1231 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401260 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856113 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757283 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:01,979 - lightrag - INFO - Chunk 1232 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:01,980 - lightrag - INFO - Chunk 1237 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:01,983 - lightrag - INFO - Chunk 1238 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472149 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:02,090 - lightrag - INFO - Chunk 1233 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484214 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488887 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882350 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884342 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469606 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817298 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895603 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:03,359 - lightrag - INFO - Chunk 1234 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449235 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:03,471 - lightrag - INFO - Chunk 1239 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:03,472 - lightrag - INFO - Chunk 1240 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:03,472 - lightrag - INFO - Chunk 1235 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469496 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:03,736 - lightrag - INFO - Chunk 1236 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428501 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876522 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926056 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435724 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900958 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828771 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378909 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:04,881 - lightrag - INFO - Chunk 1241 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388253 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:05,081 - lightrag - INFO - Chunk 1242 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:05,082 - lightrag - INFO - Chunk 1237 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:05,083 - lightrag - INFO - Chunk 1238 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431854 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933778 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:05,236 - lightrag - INFO - Chunk 1243 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420819 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940395 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869397 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767180 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488848 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428205 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:06,396 - lightrag - INFO - Chunk 1244 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489538 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:06,438 - lightrag - INFO - Chunk 1239 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:06,438 - lightrag - INFO - Chunk 1240 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:06,439 - lightrag - INFO - Chunk 1245 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448448 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826386 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788571 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987294 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913867 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:07,360 - lightrag - INFO - Chunk 1246 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433282 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467100 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906320 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427263 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:07,887 - lightrag - INFO - Chunk 1241 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409317 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992265 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883901 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821918 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:08,718 - lightrag - INFO - Chunk 1242 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:08,720 - lightrag - INFO - Chunk 1247 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:08,721 - lightrag - INFO - Chunk 1248 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404691 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:08,942 - lightrag - INFO - Chunk 1243 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486413 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853573 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446149 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468539 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833149 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905095 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770566 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:09,997 - lightrag - INFO - Chunk 1244 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438250 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:10,275 - lightrag - INFO - Chunk 1249 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:10,276 - lightrag - INFO - Chunk 1250 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:10,277 - lightrag - INFO - Chunk 1245 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377048 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:10,387 - lightrag - INFO - Chunk 1246 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467163 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828454 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401663 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904983 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953766 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854929 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414395 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:11,571 - lightrag - INFO - Chunk 1251 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476955 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897269 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:11,762 - lightrag - INFO - Chunk 1252 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:11,763 - lightrag - INFO - Chunk 1247 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:11,764 - lightrag - INFO - Chunk 1248 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418696 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:11,816 - lightrag - INFO - Chunk 1253 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475471 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794220 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767607 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755093 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452582 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423302 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:12,965 - lightrag - INFO - Chunk 1254 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469950 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:13,059 - lightrag - INFO - Chunk 1249 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:13,059 - lightrag - INFO - Chunk 1250 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:13,060 - lightrag - INFO - Chunk 1255 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380006 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932572 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765703 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.799244 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922300 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:14,001 - lightrag - INFO - Chunk 1256 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496238 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389876 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456257 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:14,376 - lightrag - INFO - Chunk 1251 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459750 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818212 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762639 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.942559 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760210 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: Connection error.\n",
      "2025-07-07 16:28:15,274 - lightrag - INFO - Chunk 1252 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:15,275 - lightrag - INFO - Chunk 1257 of 3990 extracted 0 Ent + 0 Rel\n",
      "2025-07-07 16:28:15,276 - lightrag - INFO - Chunk 1258 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:15,280 - lightrag - INFO - Chunk 1253 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:15,281 - lightrag - INFO - Chunk 1254 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455965 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434673 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470520 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437818 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911944 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897473 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.967515 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989545 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464465 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433968 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:17,069 - lightrag - INFO - Chunk 1259 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:17,071 - lightrag - INFO - Chunk 1260 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:17,072 - lightrag - INFO - Chunk 1255 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:17,073 - lightrag - INFO - Chunk 1256 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:17,075 - lightrag - INFO - Chunk 1261 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431207 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782418 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440775 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984114 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912407 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769046 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425688 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422361 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959014 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403882 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:18,436 - lightrag - INFO - Chunk 1262 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:18,437 - lightrag - INFO - Chunk 1257 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:18,438 - lightrag - INFO - Chunk 1258 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:18,439 - lightrag - INFO - Chunk 1263 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:18,441 - lightrag - INFO - Chunk 1264 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498026 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784857 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846010 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897842 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402635 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462600 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466259 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985763 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754896 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479614 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779471 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867863 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:20,580 - lightrag - INFO - Chunk 1259 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:20,581 - lightrag - INFO - Chunk 1260 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:20,582 - lightrag - INFO - Chunk 1265 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:20,584 - lightrag - INFO - Chunk 1266 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:20,585 - lightrag - INFO - Chunk 1261 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413975 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437035 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482537 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.799564 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847475 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468636 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825023 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817165 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433117 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:21,976 - lightrag - INFO - Chunk 1262 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:21,978 - lightrag - INFO - Chunk 1267 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:21,979 - lightrag - INFO - Chunk 1268 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:21,980 - lightrag - INFO - Chunk 1263 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:21,982 - lightrag - INFO - Chunk 1264 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401736 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448372 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895704 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914748 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413043 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902490 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952753 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412385 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431439 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:23,518 - lightrag - INFO - Chunk 1269 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:23,519 - lightrag - INFO - Chunk 1270 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:23,521 - lightrag - INFO - Chunk 1265 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:23,522 - lightrag - INFO - Chunk 1266 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:23,524 - lightrag - INFO - Chunk 1271 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382873 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888318 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828742 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407439 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801073 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812969 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449578 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452514 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460195 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785771 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819008 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:25,131 - lightrag - INFO - Chunk 1272 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:25,131 - lightrag - INFO - Chunk 1267 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:25,132 - lightrag - INFO - Chunk 1268 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:25,133 - lightrag - INFO - Chunk 1273 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:25,134 - lightrag - INFO - Chunk 1274 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412533 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868490 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994289 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487026 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464204 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394140 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871099 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884654 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892115 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402901 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922061 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:27,091 - lightrag - INFO - Chunk 1269 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:27,091 - lightrag - INFO - Chunk 1270 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:27,092 - lightrag - INFO - Chunk 1275 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:27,093 - lightrag - INFO - Chunk 1276 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:27,094 - lightrag - INFO - Chunk 1271 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390575 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445558 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409368 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998024 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930975 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904808 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475686 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856220 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435654 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:28,615 - lightrag - INFO - Chunk 1272 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:28,617 - lightrag - INFO - Chunk 1277 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:28,618 - lightrag - INFO - Chunk 1278 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:28,620 - lightrag - INFO - Chunk 1273 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:28,621 - lightrag - INFO - Chunk 1274 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403575 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479730 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926219 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850425 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979809 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436740 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876460 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496375 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465466 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:30,199 - lightrag - INFO - Chunk 1279 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:30,199 - lightrag - INFO - Chunk 1280 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:30,200 - lightrag - INFO - Chunk 1275 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:30,200 - lightrag - INFO - Chunk 1276 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:30,201 - lightrag - INFO - Chunk 1281 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434497 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782345 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876128 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446313 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788146 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833140 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377166 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483364 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497597 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870587 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844839 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:31,862 - lightrag - INFO - Chunk 1282 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:31,863 - lightrag - INFO - Chunk 1277 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:31,864 - lightrag - INFO - Chunk 1278 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:31,866 - lightrag - INFO - Chunk 1283 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:31,868 - lightrag - INFO - Chunk 1284 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419574 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874577 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992638 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468387 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454765 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429529 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784579 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949289 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457964 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:33,677 - lightrag - INFO - Chunk 1279 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:33,678 - lightrag - INFO - Chunk 1280 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:33,679 - lightrag - INFO - Chunk 1285 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:33,680 - lightrag - INFO - Chunk 1286 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:33,682 - lightrag - INFO - Chunk 1281 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463713 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844736 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417118 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497787 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998145 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819924 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955800 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488168 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918994 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494600 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:35,265 - lightrag - INFO - Chunk 1282 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:35,266 - lightrag - INFO - Chunk 1287 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:35,268 - lightrag - INFO - Chunk 1288 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:35,269 - lightrag - INFO - Chunk 1283 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:35,270 - lightrag - INFO - Chunk 1284 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393351 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.925111 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982054 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820416 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415583 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424125 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:36,743 - lightrag - INFO - Chunk 1289 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:36,744 - lightrag - INFO - Chunk 1290 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472311 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:36,746 - lightrag - INFO - Chunk 1285 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:36,747 - lightrag - INFO - Chunk 1286 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:36,748 - lightrag - INFO - Chunk 1291 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443490 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889628 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869289 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976385 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492612 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947756 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424030 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476397 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378957 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806266 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933540 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.995255 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:38,873 - lightrag - INFO - Chunk 1292 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:38,874 - lightrag - INFO - Chunk 1287 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:38,875 - lightrag - INFO - Chunk 1293 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:38,877 - lightrag - INFO - Chunk 1288 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:38,878 - lightrag - INFO - Chunk 1294 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393181 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403960 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825348 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392829 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868642 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392899 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878308 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932837 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395590 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:40,460 - lightrag - INFO - Chunk 1289 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:40,461 - lightrag - INFO - Chunk 1290 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:40,462 - lightrag - INFO - Chunk 1295 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:40,464 - lightrag - INFO - Chunk 1296 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:40,466 - lightrag - INFO - Chunk 1291 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491406 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999061 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402534 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470455 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754606 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994921 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926678 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395367 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428940 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822395 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814677 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:42,196 - lightrag - INFO - Chunk 1297 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:42,197 - lightrag - INFO - Chunk 1292 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:42,197 - lightrag - INFO - Chunk 1298 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:42,198 - lightrag - INFO - Chunk 1293 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:42,198 - lightrag - INFO - Chunk 1294 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380548 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375162 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837249 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835657 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499494 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448054 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889030 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390981 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947095 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:43,592 - lightrag - INFO - Chunk 1299 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:43,594 - lightrag - INFO - Chunk 1300 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:43,595 - lightrag - INFO - Chunk 1295 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:43,597 - lightrag - INFO - Chunk 1301 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:43,598 - lightrag - INFO - Chunk 1296 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453521 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776532 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762080 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453345 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438018 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482760 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800408 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973753 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450285 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933849 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896018 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:45,429 - lightrag - INFO - Chunk 1302 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:45,430 - lightrag - INFO - Chunk 1297 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:45,432 - lightrag - INFO - Chunk 1298 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:45,433 - lightrag - INFO - Chunk 1303 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:45,435 - lightrag - INFO - Chunk 1304 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469430 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468578 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836905 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489408 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487079 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884072 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861789 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816798 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381538 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870572 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:47,178 - lightrag - INFO - Chunk 1299 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:47,179 - lightrag - INFO - Chunk 1305 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:47,179 - lightrag - INFO - Chunk 1300 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:47,180 - lightrag - INFO - Chunk 1306 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:47,181 - lightrag - INFO - Chunk 1301 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462397 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486519 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445721 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950155 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815605 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391239 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996714 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401890 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:48,716 - lightrag - INFO - Chunk 1302 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:48,718 - lightrag - INFO - Chunk 1307 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:48,719 - lightrag - INFO - Chunk 1308 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:48,722 - lightrag - INFO - Chunk 1303 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:48,723 - lightrag - INFO - Chunk 1309 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452599 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394250 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762048 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947770 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966338 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395631 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388562 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842098 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408240 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939746 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:50,252 - lightrag - INFO - Chunk 1304 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:50,253 - lightrag - INFO - Chunk 1310 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:50,254 - lightrag - INFO - Chunk 1305 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:50,254 - lightrag - INFO - Chunk 1306 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:50,255 - lightrag - INFO - Chunk 1311 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419494 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976445 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858445 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399603 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821610 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435566 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375523 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476167 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931026 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988737 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:51,931 - lightrag - INFO - Chunk 1312 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:51,933 - lightrag - INFO - Chunk 1307 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:51,934 - lightrag - INFO - Chunk 1313 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:51,935 - lightrag - INFO - Chunk 1308 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:51,935 - lightrag - INFO - Chunk 1314 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382762 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804156 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771779 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389358 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489180 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875274 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489881 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401192 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844143 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833014 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857064 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:53,799 - lightrag - INFO - Chunk 1309 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:53,801 - lightrag - INFO - Chunk 1315 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:53,807 - lightrag - INFO - Chunk 1310 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:53,809 - lightrag - INFO - Chunk 1316 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:53,810 - lightrag - INFO - Chunk 1311 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476738 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401432 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474282 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920863 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474792 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804438 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886522 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871117 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471908 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:55,413 - lightrag - INFO - Chunk 1317 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:55,414 - lightrag - INFO - Chunk 1312 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:55,415 - lightrag - INFO - Chunk 1318 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:55,417 - lightrag - INFO - Chunk 1313 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:55,418 - lightrag - INFO - Chunk 1319 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468689 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380265 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991530 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426247 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977222 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.995668 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821392 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485646 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485963 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:56,988 - lightrag - INFO - Chunk 1314 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:56,989 - lightrag - INFO - Chunk 1320 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:56,990 - lightrag - INFO - Chunk 1315 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:56,990 - lightrag - INFO - Chunk 1321 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:56,991 - lightrag - INFO - Chunk 1322 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409077 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445547 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858450 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897625 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842288 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814866 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484377 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408103 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464098 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:58,314 - lightrag - INFO - Chunk 1316 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:58,315 - lightrag - INFO - Chunk 1317 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:58,315 - lightrag - INFO - Chunk 1318 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:58,316 - lightrag - INFO - Chunk 1323 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:28:58,316 - lightrag - INFO - Chunk 1324 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427334 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986284 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763207 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793391 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980793 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433344 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381199 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402769 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777776 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850665 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943483 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962272 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:00,671 - lightrag - INFO - Chunk 1325 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:00,672 - lightrag - INFO - Chunk 1326 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:00,673 - lightrag - INFO - Chunk 1319 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:00,675 - lightrag - INFO - Chunk 1320 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:00,678 - lightrag - INFO - Chunk 1321 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456754 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388176 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441604 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891509 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467184 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795486 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763949 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891980 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437501 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:02,042 - lightrag - INFO - Chunk 1327 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:02,043 - lightrag - INFO - Chunk 1322 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:02,044 - lightrag - INFO - Chunk 1328 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:02,045 - lightrag - INFO - Chunk 1329 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:02,046 - lightrag - INFO - Chunk 1330 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490470 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439258 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760423 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408593 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975326 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986517 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964276 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485336 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407334 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:03,557 - lightrag - INFO - Chunk 1323 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:03,558 - lightrag - INFO - Chunk 1324 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:03,558 - lightrag - INFO - Chunk 1325 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:03,559 - lightrag - INFO - Chunk 1331 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:03,559 - lightrag - INFO - Chunk 1326 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394989 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903615 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402117 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830540 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940123 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.993027 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453660 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431431 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461815 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904464 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866242 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:05,332 - lightrag - INFO - Chunk 1332 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:05,334 - lightrag - INFO - Chunk 1333 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:05,335 - lightrag - INFO - Chunk 1334 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:05,336 - lightrag - INFO - Chunk 1327 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:05,338 - lightrag - INFO - Chunk 1328 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469381 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990665 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931098 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489498 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441693 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421515 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997696 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392485 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970227 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867815 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:07,323 - lightrag - INFO - Chunk 1329 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:07,324 - lightrag - INFO - Chunk 1335 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:07,325 - lightrag - INFO - Chunk 1330 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:07,326 - lightrag - INFO - Chunk 1336 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:07,327 - lightrag - INFO - Chunk 1337 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463572 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421678 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919936 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397265 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792478 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427363 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920559 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955197 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452953 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:08,788 - lightrag - INFO - Chunk 1338 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:08,789 - lightrag - INFO - Chunk 1331 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:08,791 - lightrag - INFO - Chunk 1332 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:08,792 - lightrag - INFO - Chunk 1333 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:08,794 - lightrag - INFO - Chunk 1339 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482875 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449075 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998290 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934271 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391487 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860762 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837843 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384380 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438301 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:10,449 - lightrag - INFO - Chunk 1334 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:10,450 - lightrag - INFO - Chunk 1340 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:10,450 - lightrag - INFO - Chunk 1341 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:10,451 - lightrag - INFO - Chunk 1342 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:10,452 - lightrag - INFO - Chunk 1335 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426371 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839309 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487010 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990161 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919670 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450171 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456572 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394213 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932272 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:12,077 - lightrag - INFO - Chunk 1336 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:12,077 - lightrag - INFO - Chunk 1337 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:12,078 - lightrag - INFO - Chunk 1343 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:12,078 - lightrag - INFO - Chunk 1338 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:12,079 - lightrag - INFO - Chunk 1344 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426959 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876554 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970912 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964644 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424871 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497500 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879013 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376619 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493016 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874900 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808028 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.993263 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:14,146 - lightrag - INFO - Chunk 1345 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:14,147 - lightrag - INFO - Chunk 1346 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:14,148 - lightrag - INFO - Chunk 1339 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:14,149 - lightrag - INFO - Chunk 1340 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:14,150 - lightrag - INFO - Chunk 1341 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455226 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432898 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407070 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783814 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787359 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754925 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383067 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887208 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426242 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:15,636 - lightrag - INFO - Chunk 1347 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:15,637 - lightrag - INFO - Chunk 1342 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:15,638 - lightrag - INFO - Chunk 1348 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:15,639 - lightrag - INFO - Chunk 1349 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:15,641 - lightrag - INFO - Chunk 1343 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462599 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479728 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838831 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841880 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969057 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477920 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423393 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832706 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388725 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803148 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:17,127 - lightrag - INFO - Chunk 1350 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:17,128 - lightrag - INFO - Chunk 1344 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:17,128 - lightrag - INFO - Chunk 1345 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:17,129 - lightrag - INFO - Chunk 1351 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:17,130 - lightrag - INFO - Chunk 1346 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486545 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853120 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495164 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966553 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395858 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755169 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412045 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943624 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438855 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961723 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:18,848 - lightrag - INFO - Chunk 1352 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:18,849 - lightrag - INFO - Chunk 1353 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:18,850 - lightrag - INFO - Chunk 1347 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:18,850 - lightrag - INFO - Chunk 1354 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:18,851 - lightrag - INFO - Chunk 1348 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451824 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975491 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488389 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950572 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469051 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818355 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493354 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781692 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459927 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794188 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:20,587 - lightrag - INFO - Chunk 1349 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:20,588 - lightrag - INFO - Chunk 1355 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:20,589 - lightrag - INFO - Chunk 1350 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:20,590 - lightrag - INFO - Chunk 1356 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:20,590 - lightrag - INFO - Chunk 1357 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455745 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791754 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392401 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828338 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926862 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452841 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480773 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877665 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834228 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:22,208 - lightrag - INFO - Chunk 1351 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:22,209 - lightrag - INFO - Chunk 1358 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:22,211 - lightrag - INFO - Chunk 1352 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:22,212 - lightrag - INFO - Chunk 1353 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:22,213 - lightrag - INFO - Chunk 1359 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383212 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949583 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784659 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393403 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399776 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840671 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410659 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899063 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396452 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806199 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956506 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:23,909 - lightrag - INFO - Chunk 1354 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:23,910 - lightrag - INFO - Chunk 1360 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:23,912 - lightrag - INFO - Chunk 1361 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:23,913 - lightrag - INFO - Chunk 1355 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:23,915 - lightrag - INFO - Chunk 1362 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381190 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476019 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839168 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404725 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972208 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498297 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835433 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467568 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785849 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943826 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:25,632 - lightrag - INFO - Chunk 1356 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:25,633 - lightrag - INFO - Chunk 1357 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:25,635 - lightrag - INFO - Chunk 1363 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:25,636 - lightrag - INFO - Chunk 1358 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:25,637 - lightrag - INFO - Chunk 1364 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447020 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387577 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382340 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752207 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885806 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945947 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493778 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441425 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:27,025 - lightrag - INFO - Chunk 1365 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:27,026 - lightrag - INFO - Chunk 1359 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:27,027 - lightrag - INFO - Chunk 1366 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:27,027 - lightrag - INFO - Chunk 1360 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:27,028 - lightrag - INFO - Chunk 1361 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481289 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961573 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758635 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402121 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884200 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.881497 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413819 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384486 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492829 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914502 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958853 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:28,705 - lightrag - INFO - Chunk 1367 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:28,706 - lightrag - INFO - Chunk 1362 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:28,707 - lightrag - INFO - Chunk 1368 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:28,708 - lightrag - INFO - Chunk 1369 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:28,708 - lightrag - INFO - Chunk 1363 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402641 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905227 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851896 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461734 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455806 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435259 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809617 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959957 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469866 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915332 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977558 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:30,691 - lightrag - INFO - Chunk 1364 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:30,693 - lightrag - INFO - Chunk 1370 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:30,694 - lightrag - INFO - Chunk 1365 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:30,695 - lightrag - INFO - Chunk 1371 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:30,697 - lightrag - INFO - Chunk 1366 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440933 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415652 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905634 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483010 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932665 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420739 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788884 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985432 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484057 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:32,213 - lightrag - INFO - Chunk 1372 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:32,214 - lightrag - INFO - Chunk 1373 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:32,214 - lightrag - INFO - Chunk 1367 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:32,215 - lightrag - INFO - Chunk 1368 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:32,215 - lightrag - INFO - Chunk 1374 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476753 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490726 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864185 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965307 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884262 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895134 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382252 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813508 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:33,853 - lightrag - INFO - Chunk 1369 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:33,854 - lightrag - INFO - Chunk 1375 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:33,854 - lightrag - INFO - Chunk 1370 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:33,855 - lightrag - INFO - Chunk 1376 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:33,856 - lightrag - INFO - Chunk 1377 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498376 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803403 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391526 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917371 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904602 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381580 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428470 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767319 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379740 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961918 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:35,500 - lightrag - INFO - Chunk 1371 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:35,500 - lightrag - INFO - Chunk 1372 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:35,501 - lightrag - INFO - Chunk 1378 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:35,502 - lightrag - INFO - Chunk 1373 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:35,503 - lightrag - INFO - Chunk 1379 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464058 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806454 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486553 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804226 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886241 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428162 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409557 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915700 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408290 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914617 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:37,181 - lightrag - INFO - Chunk 1374 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:37,182 - lightrag - INFO - Chunk 1380 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:37,183 - lightrag - INFO - Chunk 1381 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:37,184 - lightrag - INFO - Chunk 1375 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:37,185 - lightrag - INFO - Chunk 1376 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424311 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784051 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488959 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419940 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478631 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820030 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898163 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805216 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463464 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:38,982 - lightrag - INFO - Chunk 1382 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:38,983 - lightrag - INFO - Chunk 1377 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:38,984 - lightrag - INFO - Chunk 1383 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:38,986 - lightrag - INFO - Chunk 1378 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:38,987 - lightrag - INFO - Chunk 1384 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375090 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924880 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470601 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457607 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944665 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937880 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981201 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456850 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379058 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970157 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:40,562 - lightrag - INFO - Chunk 1385 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:40,562 - lightrag - INFO - Chunk 1379 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:40,563 - lightrag - INFO - Chunk 1380 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:40,564 - lightrag - INFO - Chunk 1386 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:40,565 - lightrag - INFO - Chunk 1381 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488555 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804989 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486954 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828767 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879305 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413809 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461747 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816634 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477687 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803868 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:42,110 - lightrag - INFO - Chunk 1387 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:42,112 - lightrag - INFO - Chunk 1382 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:42,113 - lightrag - INFO - Chunk 1388 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:42,114 - lightrag - INFO - Chunk 1389 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:42,114 - lightrag - INFO - Chunk 1383 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498345 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944066 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770008 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392169 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473755 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779215 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860507 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476235 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413311 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929559 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889936 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:43,872 - lightrag - INFO - Chunk 1384 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:43,872 - lightrag - INFO - Chunk 1390 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:43,873 - lightrag - INFO - Chunk 1385 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:43,873 - lightrag - INFO - Chunk 1391 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:43,875 - lightrag - INFO - Chunk 1386 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429275 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381629 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.799998 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895525 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375737 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407422 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841628 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446668 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903949 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:45,431 - lightrag - INFO - Chunk 1392 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:45,431 - lightrag - INFO - Chunk 1387 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:45,432 - lightrag - INFO - Chunk 1393 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:45,432 - lightrag - INFO - Chunk 1388 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:45,433 - lightrag - INFO - Chunk 1394 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463126 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900368 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980157 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456903 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471943 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883048 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384830 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893817 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978125 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444536 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:47,296 - lightrag - INFO - Chunk 1389 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:47,297 - lightrag - INFO - Chunk 1395 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:47,300 - lightrag - INFO - Chunk 1390 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:47,302 - lightrag - INFO - Chunk 1396 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:47,303 - lightrag - INFO - Chunk 1391 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431239 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787383 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992755 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497968 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820098 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468570 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885402 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916114 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406901 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:48,772 - lightrag - INFO - Chunk 1397 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:48,773 - lightrag - INFO - Chunk 1392 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:48,774 - lightrag - INFO - Chunk 1398 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:48,775 - lightrag - INFO - Chunk 1393 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:48,775 - lightrag - INFO - Chunk 1399 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408420 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.993417 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889605 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493036 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484914 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753234 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904362 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405539 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499495 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:50,516 - lightrag - INFO - Chunk 1394 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:50,517 - lightrag - INFO - Chunk 1400 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:50,518 - lightrag - INFO - Chunk 1401 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:50,519 - lightrag - INFO - Chunk 1395 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:50,521 - lightrag - INFO - Chunk 1396 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494242 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963783 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759402 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491338 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984959 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835173 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495477 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458058 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854749 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830899 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411970 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:52,275 - lightrag - INFO - Chunk 1402 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:52,276 - lightrag - INFO - Chunk 1403 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:52,276 - lightrag - INFO - Chunk 1397 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:52,277 - lightrag - INFO - Chunk 1398 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:52,278 - lightrag - INFO - Chunk 1404 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498851 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833858 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953018 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461141 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914297 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456647 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787173 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900789 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450698 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:54,067 - lightrag - INFO - Chunk 1405 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:54,068 - lightrag - INFO - Chunk 1399 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:54,069 - lightrag - INFO - Chunk 1400 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:54,077 - lightrag - INFO - Chunk 1406 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:54,078 - lightrag - INFO - Chunk 1407 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414870 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476374 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886825 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833950 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376024 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854949 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752606 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443292 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399065 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:55,520 - lightrag - INFO - Chunk 1401 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:55,522 - lightrag - INFO - Chunk 1402 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:55,523 - lightrag - INFO - Chunk 1408 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:55,525 - lightrag - INFO - Chunk 1409 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:55,526 - lightrag - INFO - Chunk 1403 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484618 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928222 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991054 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494323 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930347 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785424 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455342 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414362 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465413 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835963 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:57,093 - lightrag - INFO - Chunk 1404 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:57,094 - lightrag - INFO - Chunk 1410 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:57,094 - lightrag - INFO - Chunk 1411 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:57,095 - lightrag - INFO - Chunk 1405 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:57,095 - lightrag - INFO - Chunk 1406 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498170 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896252 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758491 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802139 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453302 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389935 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407827 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777326 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494110 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846773 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755517 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855098 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:59,104 - lightrag - INFO - Chunk 1412 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:59,105 - lightrag - INFO - Chunk 1413 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:59,106 - lightrag - INFO - Chunk 1407 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:59,107 - lightrag - INFO - Chunk 1408 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:29:59,109 - lightrag - INFO - Chunk 1414 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476322 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459980 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406644 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880961 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940737 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376618 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761546 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786374 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401349 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:00,548 - lightrag - INFO - Chunk 1415 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:00,550 - lightrag - INFO - Chunk 1409 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:00,552 - lightrag - INFO - Chunk 1410 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:00,554 - lightrag - INFO - Chunk 1416 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:00,555 - lightrag - INFO - Chunk 1417 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390847 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826315 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464906 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905745 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.908796 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986278 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441865 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472805 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:02,028 - lightrag - INFO - Chunk 1411 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:02,028 - lightrag - INFO - Chunk 1412 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:02,029 - lightrag - INFO - Chunk 1418 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:02,030 - lightrag - INFO - Chunk 1419 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:02,031 - lightrag - INFO - Chunk 1413 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457070 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882073 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976599 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412678 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789430 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903947 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486587 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444862 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391661 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997734 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932838 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:03,741 - lightrag - INFO - Chunk 1414 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:03,742 - lightrag - INFO - Chunk 1420 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:03,742 - lightrag - INFO - Chunk 1415 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:03,743 - lightrag - INFO - Chunk 1421 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:03,743 - lightrag - INFO - Chunk 1416 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430353 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976499 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497512 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435896 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486917 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823410 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905986 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447172 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903020 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.942329 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:05,899 - lightrag - INFO - Chunk 1422 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:05,900 - lightrag - INFO - Chunk 1423 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:05,901 - lightrag - INFO - Chunk 1417 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:05,903 - lightrag - INFO - Chunk 1418 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:05,904 - lightrag - INFO - Chunk 1424 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397012 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454372 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411551 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864661 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.967291 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448317 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870727 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472212 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:07,462 - lightrag - INFO - Chunk 1419 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:07,462 - lightrag - INFO - Chunk 1425 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:07,463 - lightrag - INFO - Chunk 1420 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:07,464 - lightrag - INFO - Chunk 1426 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:07,465 - lightrag - INFO - Chunk 1427 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458335 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412264 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969942 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901285 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400334 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905585 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818419 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452266 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477508 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:08,893 - lightrag - INFO - Chunk 1421 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:08,894 - lightrag - INFO - Chunk 1422 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:08,894 - lightrag - INFO - Chunk 1428 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:08,895 - lightrag - INFO - Chunk 1423 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:08,901 - lightrag - INFO - Chunk 1429 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414658 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813074 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408136 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973379 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823459 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842427 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499709 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421659 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449636 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975028 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:10,430 - lightrag - INFO - Chunk 1424 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:10,431 - lightrag - INFO - Chunk 1430 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:10,431 - lightrag - INFO - Chunk 1431 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:10,432 - lightrag - INFO - Chunk 1425 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:10,432 - lightrag - INFO - Chunk 1426 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487719 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824879 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911626 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880620 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495787 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481800 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413264 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393061 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824418 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775032 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806247 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790874 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:12,681 - lightrag - INFO - Chunk 1432 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:12,682 - lightrag - INFO - Chunk 1427 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:12,684 - lightrag - INFO - Chunk 1433 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:12,685 - lightrag - INFO - Chunk 1428 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:12,686 - lightrag - INFO - Chunk 1434 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402801 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456060 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384727 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416086 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922115 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808835 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845948 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990165 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438640 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:14,026 - lightrag - INFO - Chunk 1435 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:14,027 - lightrag - INFO - Chunk 1429 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:14,028 - lightrag - INFO - Chunk 1430 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:14,029 - lightrag - INFO - Chunk 1431 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:14,029 - lightrag - INFO - Chunk 1436 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402544 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388832 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917191 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938063 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989977 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781282 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470431 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381155 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:15,523 - lightrag - INFO - Chunk 1437 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:15,524 - lightrag - INFO - Chunk 1432 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:15,524 - lightrag - INFO - Chunk 1438 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:15,525 - lightrag - INFO - Chunk 1439 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:15,525 - lightrag - INFO - Chunk 1433 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495333 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429081 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824380 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870831 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931162 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941648 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404684 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470469 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476155 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:16,975 - lightrag - INFO - Chunk 1434 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:16,976 - lightrag - INFO - Chunk 1440 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:16,976 - lightrag - INFO - Chunk 1435 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:16,976 - lightrag - INFO - Chunk 1441 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:16,977 - lightrag - INFO - Chunk 1436 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437106 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790597 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751031 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851019 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877448 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465826 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462099 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407420 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389826 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926800 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936602 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821107 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:19,173 - lightrag - INFO - Chunk 1442 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:19,174 - lightrag - INFO - Chunk 1443 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:19,175 - lightrag - INFO - Chunk 1437 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:19,177 - lightrag - INFO - Chunk 1438 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:19,178 - lightrag - INFO - Chunk 1444 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462131 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442009 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410084 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471689 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.995158 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801924 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818822 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911031 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377157 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:20,648 - lightrag - INFO - Chunk 1439 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:20,650 - lightrag - INFO - Chunk 1440 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:20,650 - lightrag - INFO - Chunk 1445 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:20,652 - lightrag - INFO - Chunk 1446 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:20,653 - lightrag - INFO - Chunk 1447 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470736 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388494 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951186 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386880 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882070 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931372 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767327 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452140 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499719 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:22,116 - lightrag - INFO - Chunk 1441 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:22,117 - lightrag - INFO - Chunk 1442 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:22,119 - lightrag - INFO - Chunk 1448 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:22,120 - lightrag - INFO - Chunk 1443 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:22,121 - lightrag - INFO - Chunk 1444 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391515 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472363 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774066 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930593 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923178 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479237 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497828 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441199 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:23,624 - lightrag - INFO - Chunk 1449 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:23,625 - lightrag - INFO - Chunk 1450 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:23,625 - lightrag - INFO - Chunk 1445 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:23,626 - lightrag - INFO - Chunk 1451 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:23,627 - lightrag - INFO - Chunk 1446 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411563 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838337 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957981 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958053 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838465 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392651 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423562 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946054 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378036 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443589 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978080 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894602 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.908433 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:25,874 - lightrag - INFO - Chunk 1452 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:25,875 - lightrag - INFO - Chunk 1453 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:25,876 - lightrag - INFO - Chunk 1447 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:25,877 - lightrag - INFO - Chunk 1448 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:25,879 - lightrag - INFO - Chunk 1454 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475178 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782088 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463570 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391874 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865329 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929370 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398140 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896670 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:27,548 - lightrag - INFO - Chunk 1449 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:27,548 - lightrag - INFO - Chunk 1455 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:27,549 - lightrag - INFO - Chunk 1450 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:27,550 - lightrag - INFO - Chunk 1456 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:27,551 - lightrag - INFO - Chunk 1451 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399110 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455854 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917534 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947404 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888402 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402430 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882521 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432824 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:28,975 - lightrag - INFO - Chunk 1457 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:28,976 - lightrag - INFO - Chunk 1452 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:28,977 - lightrag - INFO - Chunk 1458 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:28,979 - lightrag - INFO - Chunk 1459 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:28,979 - lightrag - INFO - Chunk 1453 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383833 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416691 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795887 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824698 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835104 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380019 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971398 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425994 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458293 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:30,323 - lightrag - INFO - Chunk 1454 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:30,324 - lightrag - INFO - Chunk 1460 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:30,325 - lightrag - INFO - Chunk 1455 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:30,326 - lightrag - INFO - Chunk 1461 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:30,327 - lightrag - INFO - Chunk 1456 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377102 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950600 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943459 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821865 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439361 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983070 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379115 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428458 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957690 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875310 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949990 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:32,488 - lightrag - INFO - Chunk 1462 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:32,489 - lightrag - INFO - Chunk 1463 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:32,490 - lightrag - INFO - Chunk 1457 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:32,492 - lightrag - INFO - Chunk 1458 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:32,493 - lightrag - INFO - Chunk 1464 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497584 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457644 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435257 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998996 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378675 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.967190 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796926 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.967627 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420166 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:34,119 - lightrag - INFO - Chunk 1465 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:34,120 - lightrag - INFO - Chunk 1459 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:34,122 - lightrag - INFO - Chunk 1460 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:34,124 - lightrag - INFO - Chunk 1466 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:34,125 - lightrag - INFO - Chunk 1461 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438801 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459785 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392619 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752971 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817329 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841871 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892198 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427602 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469034 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:35,591 - lightrag - INFO - Chunk 1467 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:35,592 - lightrag - INFO - Chunk 1462 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:35,593 - lightrag - INFO - Chunk 1468 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:35,594 - lightrag - INFO - Chunk 1469 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:35,595 - lightrag - INFO - Chunk 1463 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388156 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885746 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431840 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833228 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817085 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851967 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473847 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436439 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403357 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:36,948 - lightrag - INFO - Chunk 1464 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:36,949 - lightrag - INFO - Chunk 1470 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:36,949 - lightrag - INFO - Chunk 1465 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:36,950 - lightrag - INFO - Chunk 1471 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:36,951 - lightrag - INFO - Chunk 1466 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497581 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775673 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889292 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786649 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776886 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398817 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491789 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438550 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811819 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421697 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765322 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.942353 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960098 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:39,036 - lightrag - INFO - Chunk 1472 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:39,037 - lightrag - INFO - Chunk 1467 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:39,039 - lightrag - INFO - Chunk 1473 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:39,040 - lightrag - INFO - Chunk 1468 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:39,041 - lightrag - INFO - Chunk 1474 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469309 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401214 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464873 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843689 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424175 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971935 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791501 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977794 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479822 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:40,636 - lightrag - INFO - Chunk 1475 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:40,636 - lightrag - INFO - Chunk 1469 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:40,637 - lightrag - INFO - Chunk 1470 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:40,638 - lightrag - INFO - Chunk 1476 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:40,638 - lightrag - INFO - Chunk 1471 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428607 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450435 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803808 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380982 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930113 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787685 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823528 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470801 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438199 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:42,018 - lightrag - INFO - Chunk 1477 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:42,019 - lightrag - INFO - Chunk 1472 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:42,019 - lightrag - INFO - Chunk 1478 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:42,020 - lightrag - INFO - Chunk 1473 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:42,021 - lightrag - INFO - Chunk 1479 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384130 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936252 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411505 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934817 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943384 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827778 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384967 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442088 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423341 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948316 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:43,507 - lightrag - INFO - Chunk 1474 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:43,508 - lightrag - INFO - Chunk 1480 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:43,509 - lightrag - INFO - Chunk 1481 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:43,509 - lightrag - INFO - Chunk 1475 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:43,510 - lightrag - INFO - Chunk 1476 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390462 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910036 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863335 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931286 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497742 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479019 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455933 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409017 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867739 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850390 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784459 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896229 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:45,813 - lightrag - INFO - Chunk 1482 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:45,816 - lightrag - INFO - Chunk 1477 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:45,817 - lightrag - INFO - Chunk 1483 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:45,819 - lightrag - INFO - Chunk 1478 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:45,822 - lightrag - INFO - Chunk 1484 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410815 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483935 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413115 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462421 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871119 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953640 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819563 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869557 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438013 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:47,297 - lightrag - INFO - Chunk 1479 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:47,298 - lightrag - INFO - Chunk 1485 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:47,300 - lightrag - INFO - Chunk 1480 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:47,301 - lightrag - INFO - Chunk 1486 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:47,302 - lightrag - INFO - Chunk 1481 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392792 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433222 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495977 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770493 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974724 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872938 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824179 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406798 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394199 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:48,699 - lightrag - INFO - Chunk 1487 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:48,699 - lightrag - INFO - Chunk 1482 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:48,700 - lightrag - INFO - Chunk 1488 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:48,700 - lightrag - INFO - Chunk 1483 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:48,700 - lightrag - INFO - Chunk 1489 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495211 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880596 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451421 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900088 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975968 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765174 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435706 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413285 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388576 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791185 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:50,179 - lightrag - INFO - Chunk 1484 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:50,180 - lightrag - INFO - Chunk 1490 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:50,181 - lightrag - INFO - Chunk 1485 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:50,182 - lightrag - INFO - Chunk 1486 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:50,183 - lightrag - INFO - Chunk 1491 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414278 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922820 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791305 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784907 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442140 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448633 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480943 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887585 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389937 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880549 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841880 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898372 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:52,249 - lightrag - INFO - Chunk 1492 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:52,251 - lightrag - INFO - Chunk 1493 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:52,252 - lightrag - INFO - Chunk 1487 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:52,253 - lightrag - INFO - Chunk 1488 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:52,255 - lightrag - INFO - Chunk 1494 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407622 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433114 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431712 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922647 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476216 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777518 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944254 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988075 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394119 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:53,832 - lightrag - INFO - Chunk 1489 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:53,833 - lightrag - INFO - Chunk 1495 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:53,835 - lightrag - INFO - Chunk 1490 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:53,836 - lightrag - INFO - Chunk 1496 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:53,837 - lightrag - INFO - Chunk 1497 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459398 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486211 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794415 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498920 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752783 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816232 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868752 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393833 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497436 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752729 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:55,333 - lightrag - INFO - Chunk 1491 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:55,334 - lightrag - INFO - Chunk 1492 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:55,335 - lightrag - INFO - Chunk 1498 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:55,336 - lightrag - INFO - Chunk 1493 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:55,336 - lightrag - INFO - Chunk 1499 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472032 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378024 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985909 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895629 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959285 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392487 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832540 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401527 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415975 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:56,926 - lightrag - INFO - Chunk 1494 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:56,927 - lightrag - INFO - Chunk 1500 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:56,928 - lightrag - INFO - Chunk 1501 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:56,929 - lightrag - INFO - Chunk 1495 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:56,930 - lightrag - INFO - Chunk 1496 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470840 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982102 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892606 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420882 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798228 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972788 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480581 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377854 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379161 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823091 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767358 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964216 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:58,625 - lightrag - INFO - Chunk 1502 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:58,626 - lightrag - INFO - Chunk 1497 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:58,627 - lightrag - INFO - Chunk 1503 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:58,628 - lightrag - INFO - Chunk 1498 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:30:58,628 - lightrag - INFO - Chunk 1504 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379119 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810522 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458499 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425427 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403017 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984986 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846405 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435590 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837145 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933690 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:00,556 - lightrag - INFO - Chunk 1505 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:00,559 - lightrag - INFO - Chunk 1499 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:00,562 - lightrag - INFO - Chunk 1500 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:00,564 - lightrag - INFO - Chunk 1506 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:00,566 - lightrag - INFO - Chunk 1501 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465948 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493426 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495497 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959490 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864346 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461812 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795890 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986886 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482384 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:02,039 - lightrag - INFO - Chunk 1507 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:02,040 - lightrag - INFO - Chunk 1502 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:02,042 - lightrag - INFO - Chunk 1508 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:02,044 - lightrag - INFO - Chunk 1509 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:02,045 - lightrag - INFO - Chunk 1503 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498005 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410593 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771766 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.968288 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770137 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415017 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871307 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484389 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468618 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:03,512 - lightrag - INFO - Chunk 1504 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:03,513 - lightrag - INFO - Chunk 1510 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:03,513 - lightrag - INFO - Chunk 1505 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:03,514 - lightrag - INFO - Chunk 1511 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:03,514 - lightrag - INFO - Chunk 1506 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392933 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886310 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955962 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840073 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491572 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801957 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475189 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450026 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493411 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850737 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905843 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:05,276 - lightrag - INFO - Chunk 1512 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:05,276 - lightrag - INFO - Chunk 1513 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:05,277 - lightrag - INFO - Chunk 1507 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:05,277 - lightrag - INFO - Chunk 1508 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:05,278 - lightrag - INFO - Chunk 1514 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443352 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759526 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831048 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407857 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480498 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418644 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959235 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941958 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983679 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388710 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775242 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:07,379 - lightrag - INFO - Chunk 1509 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:07,380 - lightrag - INFO - Chunk 1510 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:07,381 - lightrag - INFO - Chunk 1515 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:07,382 - lightrag - INFO - Chunk 1516 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:07,384 - lightrag - INFO - Chunk 1517 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448342 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420502 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423610 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484782 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954771 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830857 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848613 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943060 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472460 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:08,801 - lightrag - INFO - Chunk 1511 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:08,802 - lightrag - INFO - Chunk 1512 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:08,803 - lightrag - INFO - Chunk 1518 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:08,804 - lightrag - INFO - Chunk 1513 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:08,805 - lightrag - INFO - Chunk 1514 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478075 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462230 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437670 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775035 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910595 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931827 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772163 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402642 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495466 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:10,238 - lightrag - INFO - Chunk 1519 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:10,238 - lightrag - INFO - Chunk 1520 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:10,239 - lightrag - INFO - Chunk 1521 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:10,239 - lightrag - INFO - Chunk 1515 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:10,239 - lightrag - INFO - Chunk 1516 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388123 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803177 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495475 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804687 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837284 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819526 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431970 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434777 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489269 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928097 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:11,743 - lightrag - INFO - Chunk 1522 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:11,763 - lightrag - INFO - Chunk 1517 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:11,764 - lightrag - INFO - Chunk 1523 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:11,764 - lightrag - INFO - Chunk 1518 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:11,765 - lightrag - INFO - Chunk 1524 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470700 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981324 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895244 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814058 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410284 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395139 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408961 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.942363 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478714 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870143 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997112 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855925 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:13,960 - lightrag - INFO - Chunk 1525 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:13,961 - lightrag - INFO - Chunk 1519 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:13,962 - lightrag - INFO - Chunk 1520 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:13,964 - lightrag - INFO - Chunk 1526 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:13,965 - lightrag - INFO - Chunk 1521 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414398 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416406 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401164 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807426 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376054 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947177 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817569 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754343 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399856 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:15,516 - lightrag - INFO - Chunk 1527 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:15,517 - lightrag - INFO - Chunk 1522 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:15,517 - lightrag - INFO - Chunk 1528 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:15,518 - lightrag - INFO - Chunk 1529 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:15,519 - lightrag - INFO - Chunk 1523 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393296 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420832 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378474 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879475 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768053 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866352 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824994 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383168 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477626 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:16,823 - lightrag - INFO - Chunk 1530 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:16,824 - lightrag - INFO - Chunk 1524 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:16,825 - lightrag - INFO - Chunk 1525 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:16,826 - lightrag - INFO - Chunk 1531 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:16,827 - lightrag - INFO - Chunk 1526 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450693 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449874 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935204 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840835 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768820 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913184 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487754 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421948 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487255 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:18,214 - lightrag - INFO - Chunk 1532 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:18,215 - lightrag - INFO - Chunk 1533 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:18,216 - lightrag - INFO - Chunk 1527 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:18,217 - lightrag - INFO - Chunk 1534 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:18,218 - lightrag - INFO - Chunk 1528 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438122 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827990 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819587 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904042 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378870 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446715 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468516 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765099 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458216 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941878 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.799124 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919797 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:20,306 - lightrag - INFO - Chunk 1529 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:20,307 - lightrag - INFO - Chunk 1535 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:20,308 - lightrag - INFO - Chunk 1530 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:20,309 - lightrag - INFO - Chunk 1536 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:20,311 - lightrag - INFO - Chunk 1537 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458057 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385022 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461786 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945168 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393481 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906414 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911967 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421758 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:21,908 - lightrag - INFO - Chunk 1531 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:21,908 - lightrag - INFO - Chunk 1538 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:21,909 - lightrag - INFO - Chunk 1532 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:21,910 - lightrag - INFO - Chunk 1533 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:21,910 - lightrag - INFO - Chunk 1539 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423515 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432745 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829580 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416452 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896086 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.881640 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830188 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456759 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441839 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:23,364 - lightrag - INFO - Chunk 1534 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:23,364 - lightrag - INFO - Chunk 1540 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:23,365 - lightrag - INFO - Chunk 1541 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:23,365 - lightrag - INFO - Chunk 1535 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:23,366 - lightrag - INFO - Chunk 1542 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388275 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.942199 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467692 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918539 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884477 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823026 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445999 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495733 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385922 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:24,847 - lightrag - INFO - Chunk 1536 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:24,847 - lightrag - INFO - Chunk 1537 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:24,848 - lightrag - INFO - Chunk 1543 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:24,849 - lightrag - INFO - Chunk 1538 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:24,849 - lightrag - INFO - Chunk 1544 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481092 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769298 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924370 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830596 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859778 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402283 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381577 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385890 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944013 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383007 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984503 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872501 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751643 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:26,994 - lightrag - INFO - Chunk 1545 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:26,995 - lightrag - INFO - Chunk 1539 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:26,996 - lightrag - INFO - Chunk 1546 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:26,998 - lightrag - INFO - Chunk 1540 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:26,999 - lightrag - INFO - Chunk 1541 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455861 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486938 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399590 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472971 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.780983 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965431 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804149 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763597 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446299 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:28,590 - lightrag - INFO - Chunk 1542 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:28,592 - lightrag - INFO - Chunk 1547 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:28,593 - lightrag - INFO - Chunk 1548 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:28,594 - lightrag - INFO - Chunk 1549 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:28,596 - lightrag - INFO - Chunk 1543 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474417 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402863 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861527 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395575 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948199 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916674 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759924 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427056 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449102 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:29,966 - lightrag - INFO - Chunk 1544 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:29,967 - lightrag - INFO - Chunk 1550 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:29,967 - lightrag - INFO - Chunk 1545 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:29,968 - lightrag - INFO - Chunk 1551 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:29,969 - lightrag - INFO - Chunk 1552 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378628 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442432 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969776 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988233 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788723 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823039 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433381 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375569 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381716 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:31,313 - lightrag - INFO - Chunk 1546 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:31,313 - lightrag - INFO - Chunk 1553 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:31,314 - lightrag - INFO - Chunk 1547 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:31,314 - lightrag - INFO - Chunk 1554 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:31,315 - lightrag - INFO - Chunk 1548 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403820 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951722 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893985 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.881217 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770919 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478335 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389020 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436866 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473523 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972824 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953160 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902987 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:33,805 - lightrag - INFO - Chunk 1549 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:33,807 - lightrag - INFO - Chunk 1555 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:33,808 - lightrag - INFO - Chunk 1550 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:33,809 - lightrag - INFO - Chunk 1556 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:33,810 - lightrag - INFO - Chunk 1551 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387408 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476016 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484823 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473530 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903902 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879997 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916476 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928667 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482687 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:35,184 - lightrag - INFO - Chunk 1557 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:35,185 - lightrag - INFO - Chunk 1558 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:35,186 - lightrag - INFO - Chunk 1552 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:35,187 - lightrag - INFO - Chunk 1553 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:35,188 - lightrag - INFO - Chunk 1559 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404225 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462939 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439291 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893501 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793796 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982548 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914939 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457790 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438005 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:36,736 - lightrag - INFO - Chunk 1554 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: Connection error.\n",
      "2025-07-07 16:31:36,737 - lightrag - INFO - Chunk 1560 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:36,738 - lightrag - INFO - Chunk 1555 of 3990 extracted 0 Ent + 0 Rel\n",
      "2025-07-07 16:31:36,739 - lightrag - INFO - Chunk 1561 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:36,741 - lightrag - INFO - Chunk 1562 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:36,742 - lightrag - INFO - Chunk 1556 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431754 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481754 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863105 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839858 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911024 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827607 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411946 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396825 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450323 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470192 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760085 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829304 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974338 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987809 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:38,930 - lightrag - INFO - Chunk 1557 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:38,931 - lightrag - INFO - Chunk 1563 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:38,932 - lightrag - INFO - Chunk 1564 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:38,934 - lightrag - INFO - Chunk 1558 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:38,935 - lightrag - INFO - Chunk 1559 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407092 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449324 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930412 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811960 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395814 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379184 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972632 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980385 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443456 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:40,292 - lightrag - INFO - Chunk 1565 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:40,293 - lightrag - INFO - Chunk 1566 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:40,294 - lightrag - INFO - Chunk 1560 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:40,295 - lightrag - INFO - Chunk 1561 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:40,296 - lightrag - INFO - Chunk 1567 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497206 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981452 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451931 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469847 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931593 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811971 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455244 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392472 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962169 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955125 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:42,238 - lightrag - INFO - Chunk 1568 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:42,239 - lightrag - INFO - Chunk 1562 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:42,240 - lightrag - INFO - Chunk 1569 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:42,241 - lightrag - INFO - Chunk 1563 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:42,241 - lightrag - INFO - Chunk 1564 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400134 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433370 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949010 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772008 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428037 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482775 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887047 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442841 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772519 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:43,616 - lightrag - INFO - Chunk 1570 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:43,616 - lightrag - INFO - Chunk 1565 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:43,617 - lightrag - INFO - Chunk 1571 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:43,617 - lightrag - INFO - Chunk 1566 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:43,618 - lightrag - INFO - Chunk 1572 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382891 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966303 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789986 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403221 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465168 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806799 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410378 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778514 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447672 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762053 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966134 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:45,581 - lightrag - INFO - Chunk 1573 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:45,582 - lightrag - INFO - Chunk 1567 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:45,584 - lightrag - INFO - Chunk 1574 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:45,585 - lightrag - INFO - Chunk 1568 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:45,586 - lightrag - INFO - Chunk 1569 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399757 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415349 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763266 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479982 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977290 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385767 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.968146 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924890 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379833 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:47,047 - lightrag - INFO - Chunk 1575 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:47,048 - lightrag - INFO - Chunk 1570 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:47,049 - lightrag - INFO - Chunk 1576 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:47,051 - lightrag - INFO - Chunk 1577 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:47,053 - lightrag - INFO - Chunk 1571 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444423 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950545 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435529 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992557 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416416 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825405 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807058 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414681 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954236 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:48,725 - lightrag - INFO - Chunk 1578 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:48,725 - lightrag - INFO - Chunk 1572 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:48,726 - lightrag - INFO - Chunk 1573 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:48,727 - lightrag - INFO - Chunk 1579 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:48,727 - lightrag - INFO - Chunk 1574 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405247 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462423 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801635 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985895 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994454 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435679 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450445 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902145 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408287 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880503 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:50,368 - lightrag - INFO - Chunk 1580 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:50,368 - lightrag - INFO - Chunk 1581 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:50,369 - lightrag - INFO - Chunk 1575 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:50,370 - lightrag - INFO - Chunk 1582 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:50,371 - lightrag - INFO - Chunk 1576 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424334 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848577 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414561 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460771 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794311 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408740 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409906 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814255 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833354 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790491 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:52,096 - lightrag - INFO - Chunk 1577 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:52,097 - lightrag - INFO - Chunk 1583 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:52,099 - lightrag - INFO - Chunk 1578 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:52,100 - lightrag - INFO - Chunk 1584 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:52,101 - lightrag - INFO - Chunk 1585 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460963 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485953 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984344 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379227 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484374 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864847 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943118 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466766 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:53,782 - lightrag - INFO - Chunk 1579 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:53,783 - lightrag - INFO - Chunk 1586 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:53,784 - lightrag - INFO - Chunk 1580 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:53,785 - lightrag - INFO - Chunk 1581 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:53,786 - lightrag - INFO - Chunk 1587 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455221 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428282 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755253 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478352 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789005 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783768 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845713 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408456 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496790 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:55,211 - lightrag - INFO - Chunk 1582 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:55,212 - lightrag - INFO - Chunk 1588 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:55,213 - lightrag - INFO - Chunk 1589 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:55,214 - lightrag - INFO - Chunk 1583 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:55,215 - lightrag - INFO - Chunk 1590 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788701 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463134 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809038 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412250 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978290 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811763 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394926 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448485 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917938 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461638 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:56,796 - lightrag - INFO - Chunk 1584 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:56,797 - lightrag - INFO - Chunk 1585 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:56,798 - lightrag - INFO - Chunk 1591 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:56,799 - lightrag - INFO - Chunk 1586 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:56,800 - lightrag - INFO - Chunk 1592 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413437 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831645 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771691 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832570 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492350 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480895 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941324 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430232 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465229 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765436 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815886 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867090 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:58,800 - lightrag - INFO - Chunk 1593 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:58,801 - lightrag - INFO - Chunk 1587 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:58,803 - lightrag - INFO - Chunk 1594 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:58,805 - lightrag - INFO - Chunk 1588 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:31:58,806 - lightrag - INFO - Chunk 1589 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406068 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491487 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385986 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924142 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430555 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923630 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922282 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807156 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426997 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:00,373 - lightrag - INFO - Chunk 1595 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:00,374 - lightrag - INFO - Chunk 1590 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:00,375 - lightrag - INFO - Chunk 1596 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:00,376 - lightrag - INFO - Chunk 1597 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:00,377 - lightrag - INFO - Chunk 1591 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382741 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447834 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954531 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482596 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951329 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750745 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755411 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398782 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427947 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:01,722 - lightrag - INFO - Chunk 1598 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:01,723 - lightrag - INFO - Chunk 1592 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:01,725 - lightrag - INFO - Chunk 1593 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:01,726 - lightrag - INFO - Chunk 1594 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:01,727 - lightrag - INFO - Chunk 1599 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451603 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382480 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985092 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844592 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761940 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804494 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436025 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401661 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439089 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:03,096 - lightrag - INFO - Chunk 1600 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:03,098 - lightrag - INFO - Chunk 1601 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:03,099 - lightrag - INFO - Chunk 1602 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:03,100 - lightrag - INFO - Chunk 1595 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:03,102 - lightrag - INFO - Chunk 1596 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398305 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819742 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946756 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783253 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987424 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481587 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447035 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402324 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468080 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884112 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896520 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921230 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869279 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:05,558 - lightrag - INFO - Chunk 1597 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:05,559 - lightrag - INFO - Chunk 1603 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:05,560 - lightrag - INFO - Chunk 1598 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:05,562 - lightrag - INFO - Chunk 1604 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:05,563 - lightrag - INFO - Chunk 1605 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384092 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414888 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415534 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478343 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784498 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971166 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856350 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865907 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490936 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:06,957 - lightrag - INFO - Chunk 1606 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:06,959 - lightrag - INFO - Chunk 1599 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:06,960 - lightrag - INFO - Chunk 1600 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:06,961 - lightrag - INFO - Chunk 1601 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:06,962 - lightrag - INFO - Chunk 1602 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378562 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475105 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381754 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939762 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889152 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990161 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819139 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495800 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426113 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:08,411 - lightrag - INFO - Chunk 1607 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:08,412 - lightrag - INFO - Chunk 1608 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:08,413 - lightrag - INFO - Chunk 1609 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:08,414 - lightrag - INFO - Chunk 1610 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:08,415 - lightrag - INFO - Chunk 1603 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389536 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400742 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991288 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964358 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986473 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932075 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418844 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405102 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419815 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:09,820 - lightrag - INFO - Chunk 1604 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:09,821 - lightrag - INFO - Chunk 1605 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:09,821 - lightrag - INFO - Chunk 1606 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:09,822 - lightrag - INFO - Chunk 1611 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:09,822 - lightrag - INFO - Chunk 1612 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390582 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825160 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863714 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805158 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823422 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442105 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483889 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412400 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400484 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911380 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959114 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868203 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.993984 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:12,285 - lightrag - INFO - Chunk 1613 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:12,286 - lightrag - INFO - Chunk 1614 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:12,287 - lightrag - INFO - Chunk 1607 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:12,288 - lightrag - INFO - Chunk 1608 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:12,289 - lightrag - INFO - Chunk 1609 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487179 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423134 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398530 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498327 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827556 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792580 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773765 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960932 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403619 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:13,591 - lightrag - INFO - Chunk 1610 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:13,593 - lightrag - INFO - Chunk 1615 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:13,595 - lightrag - INFO - Chunk 1616 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:13,596 - lightrag - INFO - Chunk 1617 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:13,597 - lightrag - INFO - Chunk 1618 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494846 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410335 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493825 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904793 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.890231 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757636 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990426 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493054 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:14,913 - lightrag - INFO - Chunk 1611 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:14,914 - lightrag - INFO - Chunk 1612 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:14,915 - lightrag - INFO - Chunk 1613 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:14,916 - lightrag - INFO - Chunk 1614 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:14,917 - lightrag - INFO - Chunk 1619 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407056 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897949 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970830 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.942763 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437727 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902378 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440818 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489563 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400313 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928813 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979406 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:16,770 - lightrag - INFO - Chunk 1620 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:16,771 - lightrag - INFO - Chunk 1615 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:16,773 - lightrag - INFO - Chunk 1621 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:16,775 - lightrag - INFO - Chunk 1622 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:16,776 - lightrag - INFO - Chunk 1616 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404890 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921909 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958899 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480679 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481360 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469460 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812430 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445714 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795711 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802537 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804733 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:18,934 - lightrag - INFO - Chunk 1617 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:18,935 - lightrag - INFO - Chunk 1618 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:18,936 - lightrag - INFO - Chunk 1623 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:18,938 - lightrag - INFO - Chunk 1624 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:18,939 - lightrag - INFO - Chunk 1619 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425155 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447166 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416465 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886281 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396833 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910862 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865301 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897886 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441903 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:20,359 - lightrag - INFO - Chunk 1625 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:20,360 - lightrag - INFO - Chunk 1626 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:20,361 - lightrag - INFO - Chunk 1620 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:20,363 - lightrag - INFO - Chunk 1621 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:20,364 - lightrag - INFO - Chunk 1622 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388902 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483063 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970762 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445478 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823308 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773331 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947118 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483943 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376150 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:21,689 - lightrag - INFO - Chunk 1627 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:21,690 - lightrag - INFO - Chunk 1628 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:21,690 - lightrag - INFO - Chunk 1629 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:21,691 - lightrag - INFO - Chunk 1630 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:21,691 - lightrag - INFO - Chunk 1623 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460811 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947747 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853830 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396872 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756845 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863756 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483686 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443611 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454538 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752976 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:23,412 - lightrag - INFO - Chunk 1624 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:23,413 - lightrag - INFO - Chunk 1631 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:23,414 - lightrag - INFO - Chunk 1625 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912028 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:23,415 - lightrag - INFO - Chunk 1626 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:23,416 - lightrag - INFO - Chunk 1632 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377607 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896204 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887836 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404499 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384968 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461411 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853184 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432617 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906494 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887817 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:25,422 - lightrag - INFO - Chunk 1633 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:25,423 - lightrag - INFO - Chunk 1634 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:25,425 - lightrag - INFO - Chunk 1627 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:25,426 - lightrag - INFO - Chunk 1628 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:25,428 - lightrag - INFO - Chunk 1635 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452381 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428940 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806567 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460065 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852802 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997658 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898985 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412807 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:26,998 - lightrag - INFO - Chunk 1629 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:26,999 - lightrag - INFO - Chunk 1630 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:26,999 - lightrag - INFO - Chunk 1636 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:27,000 - lightrag - INFO - Chunk 1637 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:27,001 - lightrag - INFO - Chunk 1638 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392625 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931495 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438348 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959120 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470187 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919584 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898568 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474228 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430966 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:28,538 - lightrag - INFO - Chunk 1631 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:28,539 - lightrag - INFO - Chunk 1632 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:28,539 - lightrag - INFO - Chunk 1639 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:28,540 - lightrag - INFO - Chunk 1633 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:28,541 - lightrag - INFO - Chunk 1634 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400302 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789104 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448736 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825442 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920485 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930782 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431077 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448123 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794456 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471011 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981630 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:30,178 - lightrag - INFO - Chunk 1640 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:30,179 - lightrag - INFO - Chunk 1641 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:30,180 - lightrag - INFO - Chunk 1642 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:30,182 - lightrag - INFO - Chunk 1635 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:30,183 - lightrag - INFO - Chunk 1636 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487684 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875086 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392953 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807496 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983572 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384719 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439835 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.780162 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458931 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816542 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978330 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:31,964 - lightrag - INFO - Chunk 1643 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:31,965 - lightrag - INFO - Chunk 1637 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:31,966 - lightrag - INFO - Chunk 1638 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:31,966 - lightrag - INFO - Chunk 1644 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:31,967 - lightrag - INFO - Chunk 1645 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416945 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405121 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947071 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449361 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964108 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481086 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802645 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378913 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979678 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:33,636 - lightrag - INFO - Chunk 1646 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:33,637 - lightrag - INFO - Chunk 1639 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:33,638 - lightrag - INFO - Chunk 1640 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:33,640 - lightrag - INFO - Chunk 1647 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:33,641 - lightrag - INFO - Chunk 1641 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398073 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929958 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496381 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776127 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848059 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463884 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399740 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426927 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893428 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913933 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:35,112 - lightrag - INFO - Chunk 1642 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:35,113 - lightrag - INFO - Chunk 1648 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:35,114 - lightrag - INFO - Chunk 1649 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:35,115 - lightrag - INFO - Chunk 1650 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:35,116 - lightrag - INFO - Chunk 1643 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428178 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965586 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751797 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453616 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497344 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457520 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955334 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451535 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992654 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983999 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895927 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:37,214 - lightrag - INFO - Chunk 1644 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:37,215 - lightrag - INFO - Chunk 1651 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:37,216 - lightrag - INFO - Chunk 1645 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:37,217 - lightrag - INFO - Chunk 1646 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:37,219 - lightrag - INFO - Chunk 1652 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451513 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378577 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806266 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490707 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873407 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950197 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839396 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412439 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:38,756 - lightrag - INFO - Chunk 1653 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:38,757 - lightrag - INFO - Chunk 1654 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:38,758 - lightrag - INFO - Chunk 1647 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:38,760 - lightrag - INFO - Chunk 1648 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:38,761 - lightrag - INFO - Chunk 1655 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483805 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829217 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468569 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440030 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964436 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939807 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877843 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404187 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902035 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386085 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:40,446 - lightrag - INFO - Chunk 1649 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:40,447 - lightrag - INFO - Chunk 1650 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:40,447 - lightrag - INFO - Chunk 1656 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:40,448 - lightrag - INFO - Chunk 1657 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:40,449 - lightrag - INFO - Chunk 1658 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475661 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455138 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861613 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978144 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750716 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442250 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441894 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878008 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461536 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:41,916 - lightrag - INFO - Chunk 1651 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:41,917 - lightrag - INFO - Chunk 1652 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:41,917 - lightrag - INFO - Chunk 1659 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:41,918 - lightrag - INFO - Chunk 1653 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:41,919 - lightrag - INFO - Chunk 1654 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426209 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762307 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940450 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408868 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443629 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966225 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437485 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999845 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463077 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884360 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:43,787 - lightrag - INFO - Chunk 1660 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:43,789 - lightrag - INFO - Chunk 1661 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:43,791 - lightrag - INFO - Chunk 1662 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:43,792 - lightrag - INFO - Chunk 1655 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:43,793 - lightrag - INFO - Chunk 1656 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899064 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384599 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499050 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921914 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489919 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777057 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437593 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999681 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424573 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815775 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:45,455 - lightrag - INFO - Chunk 1663 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:45,456 - lightrag - INFO - Chunk 1657 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:45,456 - lightrag - INFO - Chunk 1658 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:45,458 - lightrag - INFO - Chunk 1664 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:45,458 - lightrag - INFO - Chunk 1665 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383937 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982772 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808577 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478198 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471199 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980914 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884832 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403232 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473145 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.908206 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840422 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:47,344 - lightrag - INFO - Chunk 1659 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:47,345 - lightrag - INFO - Chunk 1666 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:47,347 - lightrag - INFO - Chunk 1660 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:47,348 - lightrag - INFO - Chunk 1667 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:47,349 - lightrag - INFO - Chunk 1661 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456868 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401302 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865723 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904541 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437769 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477154 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840687 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864407 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467152 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:48,779 - lightrag - INFO - Chunk 1662 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:48,780 - lightrag - INFO - Chunk 1668 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:48,780 - lightrag - INFO - Chunk 1669 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:48,781 - lightrag - INFO - Chunk 1663 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:48,781 - lightrag - INFO - Chunk 1670 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443313 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432485 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868937 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839922 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400883 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979522 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.925046 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466324 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381689 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983967 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970119 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:50,578 - lightrag - INFO - Chunk 1664 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:50,579 - lightrag - INFO - Chunk 1671 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:50,580 - lightrag - INFO - Chunk 1665 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:50,581 - lightrag - INFO - Chunk 1666 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:50,582 - lightrag - INFO - Chunk 1672 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459168 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383178 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770841 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757652 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426377 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467104 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478948 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:51,826 - lightrag - INFO - Chunk 1673 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:51,827 - lightrag - INFO - Chunk 1674 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:51,828 - lightrag - INFO - Chunk 1667 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:51,829 - lightrag - INFO - Chunk 1675 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:51,830 - lightrag - INFO - Chunk 1668 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438545 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834812 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763558 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928318 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459103 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496692 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412191 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810533 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994886 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424328 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960828 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790853 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:54,006 - lightrag - INFO - Chunk 1669 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:54,007 - lightrag - INFO - Chunk 1670 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:54,008 - lightrag - INFO - Chunk 1676 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:54,009 - lightrag - INFO - Chunk 1677 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:54,011 - lightrag - INFO - Chunk 1678 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450809 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498568 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801265 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442061 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495191 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965882 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821068 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910788 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389206 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753003 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:55,737 - lightrag - INFO - Chunk 1671 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:55,738 - lightrag - INFO - Chunk 1672 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:55,739 - lightrag - INFO - Chunk 1679 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:55,743 - lightrag - INFO - Chunk 1673 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:55,746 - lightrag - INFO - Chunk 1674 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384367 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470700 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407709 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777255 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871144 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962851 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433611 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774260 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496005 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:57,103 - lightrag - INFO - Chunk 1680 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:57,105 - lightrag - INFO - Chunk 1681 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:57,106 - lightrag - INFO - Chunk 1682 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:57,108 - lightrag - INFO - Chunk 1675 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:57,110 - lightrag - INFO - Chunk 1676 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421883 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483395 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835038 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786651 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449394 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873048 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795506 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381780 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472923 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763460 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:58,686 - lightrag - INFO - Chunk 1683 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:58,686 - lightrag - INFO - Chunk 1677 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:58,687 - lightrag - INFO - Chunk 1678 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:58,687 - lightrag - INFO - Chunk 1684 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:32:58,688 - lightrag - INFO - Chunk 1685 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419673 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906517 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402600 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779301 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951541 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422554 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402569 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812376 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490508 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940308 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:00,285 - lightrag - INFO - Chunk 1686 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:00,286 - lightrag - INFO - Chunk 1679 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:00,287 - lightrag - INFO - Chunk 1680 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:00,288 - lightrag - INFO - Chunk 1687 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:00,289 - lightrag - INFO - Chunk 1681 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454972 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963703 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475386 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948398 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398058 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874855 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449726 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844729 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474550 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797106 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:02,025 - lightrag - INFO - Chunk 1682 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:02,026 - lightrag - INFO - Chunk 1688 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:02,027 - lightrag - INFO - Chunk 1689 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:02,028 - lightrag - INFO - Chunk 1690 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:02,028 - lightrag - INFO - Chunk 1683 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447768 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777639 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473514 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981013 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497544 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932423 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404265 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977567 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999526 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384219 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:03,747 - lightrag - INFO - Chunk 1684 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:03,747 - lightrag - INFO - Chunk 1691 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:03,748 - lightrag - INFO - Chunk 1685 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:03,749 - lightrag - INFO - Chunk 1686 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:03,749 - lightrag - INFO - Chunk 1692 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383919 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844422 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490338 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787481 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383420 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786737 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426326 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767188 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467436 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938408 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:05,402 - lightrag - INFO - Chunk 1693 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:05,403 - lightrag - INFO - Chunk 1694 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:05,404 - lightrag - INFO - Chunk 1687 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763011 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:05,405 - lightrag - INFO - Chunk 1688 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:05,406 - lightrag - INFO - Chunk 1695 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385244 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375959 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823883 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778942 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443215 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494181 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900494 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870784 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:06,706 - lightrag - INFO - Chunk 1689 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:06,707 - lightrag - INFO - Chunk 1690 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:06,708 - lightrag - INFO - Chunk 1696 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:06,709 - lightrag - INFO - Chunk 1697 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:06,709 - lightrag - INFO - Chunk 1698 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422188 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785016 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830318 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398831 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427131 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977700 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465565 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382545 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876895 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857514 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830964 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:08,847 - lightrag - INFO - Chunk 1691 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:08,848 - lightrag - INFO - Chunk 1692 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:08,849 - lightrag - INFO - Chunk 1699 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:08,850 - lightrag - INFO - Chunk 1693 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:08,851 - lightrag - INFO - Chunk 1694 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425950 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452065 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481347 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450733 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803468 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977232 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783834 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994532 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392764 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:10,301 - lightrag - INFO - Chunk 1700 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:10,302 - lightrag - INFO - Chunk 1701 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:10,303 - lightrag - INFO - Chunk 1702 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:10,305 - lightrag - INFO - Chunk 1695 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:10,306 - lightrag - INFO - Chunk 1696 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418961 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487824 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756097 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454345 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782270 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806085 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978920 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478258 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465034 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974901 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:11,805 - lightrag - INFO - Chunk 1703 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:11,806 - lightrag - INFO - Chunk 1697 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:11,806 - lightrag - INFO - Chunk 1698 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:11,807 - lightrag - INFO - Chunk 1704 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:11,807 - lightrag - INFO - Chunk 1705 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395001 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815014 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417373 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865416 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755075 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438365 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438950 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460578 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815133 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758798 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:13,334 - lightrag - INFO - Chunk 1706 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:13,334 - lightrag - INFO - Chunk 1699 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:13,335 - lightrag - INFO - Chunk 1700 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:13,336 - lightrag - INFO - Chunk 1707 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:13,336 - lightrag - INFO - Chunk 1701 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921361 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796729 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424317 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397868 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763371 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961384 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387329 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494182 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971085 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.890640 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:15,194 - lightrag - INFO - Chunk 1702 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:15,196 - lightrag - INFO - Chunk 1708 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:15,197 - lightrag - INFO - Chunk 1709 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:15,198 - lightrag - INFO - Chunk 1710 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:15,200 - lightrag - INFO - Chunk 1703 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431568 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450284 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791334 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417565 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758907 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466216 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816944 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486197 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823542 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:16,627 - lightrag - INFO - Chunk 1704 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:16,628 - lightrag - INFO - Chunk 1711 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:16,629 - lightrag - INFO - Chunk 1705 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:16,630 - lightrag - INFO - Chunk 1706 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:16,631 - lightrag - INFO - Chunk 1712 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446996 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758767 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934394 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384998 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468320 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755514 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415858 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771885 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442707 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894113 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:18,247 - lightrag - INFO - Chunk 1713 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:18,247 - lightrag - INFO - Chunk 1714 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:18,247 - lightrag - INFO - Chunk 1707 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:18,248 - lightrag - INFO - Chunk 1708 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:18,248 - lightrag - INFO - Chunk 1715 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491680 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972688 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467406 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837001 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954378 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461250 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386685 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797805 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466194 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944728 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:19,957 - lightrag - INFO - Chunk 1709 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:19,957 - lightrag - INFO - Chunk 1710 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:19,958 - lightrag - INFO - Chunk 1716 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:19,959 - lightrag - INFO - Chunk 1717 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:19,960 - lightrag - INFO - Chunk 1718 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447839 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858374 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461648 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803743 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966769 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485996 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409862 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411613 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770624 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758653 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876533 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:21,731 - lightrag - INFO - Chunk 1711 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:21,732 - lightrag - INFO - Chunk 1712 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:21,733 - lightrag - INFO - Chunk 1719 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:21,735 - lightrag - INFO - Chunk 1713 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:21,736 - lightrag - INFO - Chunk 1714 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471276 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445450 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462545 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950573 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919546 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486229 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848053 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923714 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426510 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:23,420 - lightrag - INFO - Chunk 1720 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:23,421 - lightrag - INFO - Chunk 1721 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:23,421 - lightrag - INFO - Chunk 1722 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:23,422 - lightrag - INFO - Chunk 1715 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:23,422 - lightrag - INFO - Chunk 1723 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421675 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488746 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878578 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844409 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796002 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444721 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927054 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462691 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453473 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:24,727 - lightrag - INFO - Chunk 1716 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:24,727 - lightrag - INFO - Chunk 1717 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:24,728 - lightrag - INFO - Chunk 1718 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:24,728 - lightrag - INFO - Chunk 1724 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:24,729 - lightrag - INFO - Chunk 1725 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418247 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772381 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800780 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826057 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375022 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981988 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444469 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421289 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458629 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820167 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779914 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960477 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:26,703 - lightrag - INFO - Chunk 1726 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:26,704 - lightrag - INFO - Chunk 1719 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:26,705 - lightrag - INFO - Chunk 1720 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:26,707 - lightrag - INFO - Chunk 1727 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:26,709 - lightrag - INFO - Chunk 1721 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478977 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465558 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446189 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801556 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383065 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792205 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889884 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994320 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483957 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:28,268 - lightrag - INFO - Chunk 1722 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:28,269 - lightrag - INFO - Chunk 1728 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:28,270 - lightrag - INFO - Chunk 1729 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:28,271 - lightrag - INFO - Chunk 1730 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:28,272 - lightrag - INFO - Chunk 1723 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381145 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918987 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381027 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830345 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404527 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795564 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811550 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464620 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466466 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:29,710 - lightrag - INFO - Chunk 1724 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:29,710 - lightrag - INFO - Chunk 1731 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:29,711 - lightrag - INFO - Chunk 1725 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:29,712 - lightrag - INFO - Chunk 1726 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:29,714 - lightrag - INFO - Chunk 1732 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443998 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873709 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991123 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455577 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955014 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913619 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392825 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466763 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444292 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857478 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864398 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:31,440 - lightrag - INFO - Chunk 1733 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:31,441 - lightrag - INFO - Chunk 1734 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:31,444 - lightrag - INFO - Chunk 1727 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:31,446 - lightrag - INFO - Chunk 1728 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:31,448 - lightrag - INFO - Chunk 1735 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421691 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756609 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772780 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497527 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431445 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485551 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870267 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459430 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964356 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945185 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886790 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:33,410 - lightrag - INFO - Chunk 1729 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:33,413 - lightrag - INFO - Chunk 1730 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:33,414 - lightrag - INFO - Chunk 1736 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:33,417 - lightrag - INFO - Chunk 1737 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:33,419 - lightrag - INFO - Chunk 1738 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408259 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405549 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397600 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.881180 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390976 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913798 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994446 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938111 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453929 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:35,044 - lightrag - INFO - Chunk 1731 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:35,045 - lightrag - INFO - Chunk 1732 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:35,047 - lightrag - INFO - Chunk 1739 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:35,048 - lightrag - INFO - Chunk 1733 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:35,049 - lightrag - INFO - Chunk 1734 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403041 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935819 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406398 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411335 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992727 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984357 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.967443 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499581 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399327 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:36,583 - lightrag - INFO - Chunk 1740 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:36,583 - lightrag - INFO - Chunk 1741 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:36,584 - lightrag - INFO - Chunk 1742 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:36,584 - lightrag - INFO - Chunk 1735 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:36,585 - lightrag - INFO - Chunk 1736 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462190 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803135 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389574 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757435 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817695 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957746 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499634 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448260 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991560 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807296 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:38,107 - lightrag - INFO - Chunk 1743 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:38,108 - lightrag - INFO - Chunk 1737 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:38,108 - lightrag - INFO - Chunk 1738 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:38,109 - lightrag - INFO - Chunk 1744 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:38,110 - lightrag - INFO - Chunk 1745 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380981 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927539 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994681 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420902 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444468 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487216 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822302 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817191 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406213 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887875 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945561 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:40,147 - lightrag - INFO - Chunk 1739 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:40,148 - lightrag - INFO - Chunk 1746 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:40,149 - lightrag - INFO - Chunk 1740 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:40,151 - lightrag - INFO - Chunk 1747 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:40,152 - lightrag - INFO - Chunk 1741 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449479 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379215 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887798 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919728 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466648 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461541 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840350 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782761 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428045 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:41,538 - lightrag - INFO - Chunk 1742 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:41,539 - lightrag - INFO - Chunk 1748 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:41,540 - lightrag - INFO - Chunk 1749 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:41,541 - lightrag - INFO - Chunk 1743 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:41,542 - lightrag - INFO - Chunk 1750 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428141 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817024 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824947 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463323 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467171 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941655 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994247 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445460 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446584 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836678 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887705 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:43,409 - lightrag - INFO - Chunk 1744 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:43,410 - lightrag - INFO - Chunk 1751 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:43,412 - lightrag - INFO - Chunk 1745 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:43,413 - lightrag - INFO - Chunk 1746 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:43,414 - lightrag - INFO - Chunk 1752 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378643 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420592 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766492 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797722 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440959 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388771 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973486 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765854 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444191 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:44,821 - lightrag - INFO - Chunk 1753 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:44,821 - lightrag - INFO - Chunk 1747 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:44,822 - lightrag - INFO - Chunk 1754 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:44,822 - lightrag - INFO - Chunk 1748 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:44,822 - lightrag - INFO - Chunk 1755 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411777 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918702 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470461 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409506 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899414 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878045 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407892 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476001 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979018 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887192 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:46,734 - lightrag - INFO - Chunk 1749 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:46,735 - lightrag - INFO - Chunk 1750 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:46,735 - lightrag - INFO - Chunk 1756 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:46,736 - lightrag - INFO - Chunk 1757 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:46,736 - lightrag - INFO - Chunk 1751 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387588 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410589 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781268 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860226 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396828 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377659 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837479 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465222 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825479 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:48,065 - lightrag - INFO - Chunk 1758 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:48,065 - lightrag - INFO - Chunk 1752 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:48,066 - lightrag - INFO - Chunk 1759 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:48,067 - lightrag - INFO - Chunk 1753 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:48,067 - lightrag - INFO - Chunk 1754 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491052 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978649 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396817 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775977 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490055 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.925704 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955986 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375440 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459961 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803386 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998393 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:49,881 - lightrag - INFO - Chunk 1760 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:49,881 - lightrag - INFO - Chunk 1761 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:49,882 - lightrag - INFO - Chunk 1762 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:49,883 - lightrag - INFO - Chunk 1755 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:49,883 - lightrag - INFO - Chunk 1756 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490933 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398138 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889726 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381338 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775142 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399602 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961610 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858624 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415403 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:51,404 - lightrag - INFO - Chunk 1763 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:51,404 - lightrag - INFO - Chunk 1757 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:51,405 - lightrag - INFO - Chunk 1758 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:51,406 - lightrag - INFO - Chunk 1764 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:51,406 - lightrag - INFO - Chunk 1765 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498742 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978093 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379994 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934867 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385038 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953644 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901186 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480798 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404059 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901415 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:53,253 - lightrag - INFO - Chunk 1766 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:53,253 - lightrag - INFO - Chunk 1759 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:53,254 - lightrag - INFO - Chunk 1760 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:53,254 - lightrag - INFO - Chunk 1767 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:53,255 - lightrag - INFO - Chunk 1761 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485100 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862396 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455091 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988761 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771895 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442580 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495181 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861376 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931450 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389727 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:54,746 - lightrag - INFO - Chunk 1762 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:54,747 - lightrag - INFO - Chunk 1768 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:54,748 - lightrag - INFO - Chunk 1769 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:54,749 - lightrag - INFO - Chunk 1763 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:54,750 - lightrag - INFO - Chunk 1770 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415526 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969945 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914439 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402449 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435923 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994175 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895643 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488511 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494069 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872644 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909715 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:56,807 - lightrag - INFO - Chunk 1764 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:56,808 - lightrag - INFO - Chunk 1771 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:56,810 - lightrag - INFO - Chunk 1765 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:56,811 - lightrag - INFO - Chunk 1766 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:56,812 - lightrag - INFO - Chunk 1772 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422128 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404240 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915935 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873751 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473262 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863774 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841328 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393871 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:58,202 - lightrag - INFO - Chunk 1773 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:58,203 - lightrag - INFO - Chunk 1767 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:58,205 - lightrag - INFO - Chunk 1774 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:58,207 - lightrag - INFO - Chunk 1768 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:33:58,208 - lightrag - INFO - Chunk 1775 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387676 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813045 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878231 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430127 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386275 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960565 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802901 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415571 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477060 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787042 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904509 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:00,044 - lightrag - INFO - Chunk 1769 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:00,045 - lightrag - INFO - Chunk 1770 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:00,047 - lightrag - INFO - Chunk 1776 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:00,048 - lightrag - INFO - Chunk 1777 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:00,050 - lightrag - INFO - Chunk 1778 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401429 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462306 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870733 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945918 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380139 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390752 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857662 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821769 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390340 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:01,469 - lightrag - INFO - Chunk 1771 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:01,470 - lightrag - INFO - Chunk 1772 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:01,471 - lightrag - INFO - Chunk 1779 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:01,471 - lightrag - INFO - Chunk 1773 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:01,472 - lightrag - INFO - Chunk 1774 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390023 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896594 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769723 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958915 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887203 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381128 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814359 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806346 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:03,227 - lightrag - INFO - Chunk 1780 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:03,228 - lightrag - INFO - Chunk 1781 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:03,229 - lightrag - INFO - Chunk 1782 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:03,230 - lightrag - INFO - Chunk 1775 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:03,231 - lightrag - INFO - Chunk 1776 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466207 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402074 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938876 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434227 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899275 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396794 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833934 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888123 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395941 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:04,817 - lightrag - INFO - Chunk 1783 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:04,819 - lightrag - INFO - Chunk 1777 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:04,820 - lightrag - INFO - Chunk 1778 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:04,822 - lightrag - INFO - Chunk 1784 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:04,822 - lightrag - INFO - Chunk 1785 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436527 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945624 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393323 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402208 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762454 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.849015 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825326 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468759 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487614 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:06,386 - lightrag - INFO - Chunk 1786 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:06,387 - lightrag - INFO - Chunk 1779 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:06,388 - lightrag - INFO - Chunk 1780 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:06,389 - lightrag - INFO - Chunk 1787 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:06,390 - lightrag - INFO - Chunk 1781 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468933 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449512 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958884 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862220 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958440 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990668 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498509 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468947 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472662 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:07,892 - lightrag - INFO - Chunk 1782 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:07,893 - lightrag - INFO - Chunk 1788 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:07,894 - lightrag - INFO - Chunk 1789 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:07,924 - lightrag - INFO - Chunk 1790 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:07,925 - lightrag - INFO - Chunk 1783 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777131 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808953 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432110 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842784 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832851 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493881 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499324 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392325 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467306 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763741 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814572 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975040 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923588 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:09,983 - lightrag - INFO - Chunk 1784 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:09,984 - lightrag - INFO - Chunk 1791 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:09,985 - lightrag - INFO - Chunk 1785 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:09,986 - lightrag - INFO - Chunk 1786 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:09,989 - lightrag - INFO - Chunk 1792 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455384 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452145 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991441 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795411 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460042 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415561 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767586 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.972576 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427047 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:11,451 - lightrag - INFO - Chunk 1793 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:11,452 - lightrag - INFO - Chunk 1794 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:11,453 - lightrag - INFO - Chunk 1787 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:11,454 - lightrag - INFO - Chunk 1795 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:11,455 - lightrag - INFO - Chunk 1788 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389476 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911976 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486300 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.993428 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493404 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819937 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936601 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427608 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411784 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:13,104 - lightrag - INFO - Chunk 1789 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:13,105 - lightrag - INFO - Chunk 1790 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:13,106 - lightrag - INFO - Chunk 1796 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:13,108 - lightrag - INFO - Chunk 1797 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:13,109 - lightrag - INFO - Chunk 1798 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445399 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885580 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.882341 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428342 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842884 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758342 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482088 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471099 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382467 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888298 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931952 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:14,647 - lightrag - INFO - Chunk 1791 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:14,648 - lightrag - INFO - Chunk 1799 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:14,649 - lightrag - INFO - Chunk 1792 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:14,649 - lightrag - INFO - Chunk 1793 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:14,650 - lightrag - INFO - Chunk 1794 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408077 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762457 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951042 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423690 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390610 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491599 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856445 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879061 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419456 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948209 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853219 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:16,706 - lightrag - INFO - Chunk 1800 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:16,708 - lightrag - INFO - Chunk 1801 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:16,709 - lightrag - INFO - Chunk 1802 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:16,711 - lightrag - INFO - Chunk 1795 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:16,712 - lightrag - INFO - Chunk 1803 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498559 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393741 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483463 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821186 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807409 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427178 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767141 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948216 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491321 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:18,056 - lightrag - INFO - Chunk 1796 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:18,057 - lightrag - INFO - Chunk 1797 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:18,058 - lightrag - INFO - Chunk 1798 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:18,059 - lightrag - INFO - Chunk 1804 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:18,060 - lightrag - INFO - Chunk 1805 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398364 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385485 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786529 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751934 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988411 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421216 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.849301 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429908 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410067 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:19,663 - lightrag - INFO - Chunk 1806 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:19,665 - lightrag - INFO - Chunk 1799 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:19,666 - lightrag - INFO - Chunk 1800 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:19,668 - lightrag - INFO - Chunk 1807 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:19,669 - lightrag - INFO - Chunk 1801 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392987 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.968068 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792463 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394540 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812087 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823318 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375396 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414632 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460486 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886684 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805900 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:21,200 - lightrag - INFO - Chunk 1802 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:21,200 - lightrag - INFO - Chunk 1808 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:21,201 - lightrag - INFO - Chunk 1809 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:21,202 - lightrag - INFO - Chunk 1810 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:21,202 - lightrag - INFO - Chunk 1803 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404283 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956148 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990596 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424218 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493302 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814042 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402950 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951816 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438698 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783552 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:23,031 - lightrag - INFO - Chunk 1804 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:23,032 - lightrag - INFO - Chunk 1811 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:23,033 - lightrag - INFO - Chunk 1805 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:23,034 - lightrag - INFO - Chunk 1806 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:23,035 - lightrag - INFO - Chunk 1812 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490173 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755024 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378710 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480290 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946695 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860767 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398012 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911598 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933391 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480213 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:24,603 - lightrag - INFO - Chunk 1813 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:24,603 - lightrag - INFO - Chunk 1814 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:24,604 - lightrag - INFO - Chunk 1807 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:24,604 - lightrag - INFO - Chunk 1808 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:24,605 - lightrag - INFO - Chunk 1815 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454737 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476415 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860431 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774473 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472066 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771266 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834779 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469226 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391746 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:26,186 - lightrag - INFO - Chunk 1809 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:26,187 - lightrag - INFO - Chunk 1810 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:26,188 - lightrag - INFO - Chunk 1816 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:26,188 - lightrag - INFO - Chunk 1817 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:26,189 - lightrag - INFO - Chunk 1818 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394965 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865721 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910324 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468135 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917391 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907593 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477443 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421971 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407812 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936886 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955679 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:27,861 - lightrag - INFO - Chunk 1811 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:27,861 - lightrag - INFO - Chunk 1819 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:27,862 - lightrag - INFO - Chunk 1812 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:27,863 - lightrag - INFO - Chunk 1813 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:27,864 - lightrag - INFO - Chunk 1814 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384599 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971084 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766252 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390567 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457949 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380561 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864835 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408863 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851261 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851779 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753858 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:29,842 - lightrag - INFO - Chunk 1820 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:29,844 - lightrag - INFO - Chunk 1821 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:29,845 - lightrag - INFO - Chunk 1822 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:29,847 - lightrag - INFO - Chunk 1815 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:29,849 - lightrag - INFO - Chunk 1823 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451146 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475165 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472829 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452830 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.968205 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845892 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789298 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910420 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:31,286 - lightrag - INFO - Chunk 1816 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:31,287 - lightrag - INFO - Chunk 1817 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:31,288 - lightrag - INFO - Chunk 1818 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:31,289 - lightrag - INFO - Chunk 1824 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:31,290 - lightrag - INFO - Chunk 1825 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436238 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398692 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396587 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409664 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970660 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982619 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785866 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940156 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381733 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413324 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:32,718 - lightrag - INFO - Chunk 1826 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:32,719 - lightrag - INFO - Chunk 1819 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:32,721 - lightrag - INFO - Chunk 1820 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:32,723 - lightrag - INFO - Chunk 1821 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:32,724 - lightrag - INFO - Chunk 1827 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429426 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401989 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888466 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830428 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800747 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802392 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410273 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388770 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465070 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:34,178 - lightrag - INFO - Chunk 1822 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:34,180 - lightrag - INFO - Chunk 1828 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:34,181 - lightrag - INFO - Chunk 1829 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:34,182 - lightrag - INFO - Chunk 1830 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:34,182 - lightrag - INFO - Chunk 1823 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410216 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.842322 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824638 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843381 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779097 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423529 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494062 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460677 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472646 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877446 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969798 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795331 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893879 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:36,472 - lightrag - INFO - Chunk 1824 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:36,473 - lightrag - INFO - Chunk 1825 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:36,474 - lightrag - INFO - Chunk 1831 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:36,477 - lightrag - INFO - Chunk 1826 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:36,478 - lightrag - INFO - Chunk 1832 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431737 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450163 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432362 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401453 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860610 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754145 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947874 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806289 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464327 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:37,783 - lightrag - INFO - Chunk 1833 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:37,784 - lightrag - INFO - Chunk 1834 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:37,785 - lightrag - INFO - Chunk 1827 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:37,786 - lightrag - INFO - Chunk 1828 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:37,786 - lightrag - INFO - Chunk 1829 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457406 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416895 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457978 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956085 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920012 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956442 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947583 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384761 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434318 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:39,354 - lightrag - INFO - Chunk 1830 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:39,355 - lightrag - INFO - Chunk 1835 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:39,356 - lightrag - INFO - Chunk 1836 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:39,358 - lightrag - INFO - Chunk 1837 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:39,359 - lightrag - INFO - Chunk 1838 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442370 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399700 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845853 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994446 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896990 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793027 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454760 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423258 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489107 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:40,710 - lightrag - INFO - Chunk 1831 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:40,710 - lightrag - INFO - Chunk 1832 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:40,711 - lightrag - INFO - Chunk 1833 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:40,712 - lightrag - INFO - Chunk 1839 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:40,712 - lightrag - INFO - Chunk 1834 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432811 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907119 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872755 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945669 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941110 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448901 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425902 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431691 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434952 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760639 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863428 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854645 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829333 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:43,011 - lightrag - INFO - Chunk 1840 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:43,012 - lightrag - INFO - Chunk 1841 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:43,014 - lightrag - INFO - Chunk 1842 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:43,015 - lightrag - INFO - Chunk 1835 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:43,016 - lightrag - INFO - Chunk 1836 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484434 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438412 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480418 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380758 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835019 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923248 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988083 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966163 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437144 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:44,613 - lightrag - INFO - Chunk 1837 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:44,614 - lightrag - INFO - Chunk 1838 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:44,614 - lightrag - INFO - Chunk 1843 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:44,615 - lightrag - INFO - Chunk 1844 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:44,616 - lightrag - INFO - Chunk 1845 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489652 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395343 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798517 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491925 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885235 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918725 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805578 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387022 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931324 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485479 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:46,076 - lightrag - INFO - Chunk 1839 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:46,077 - lightrag - INFO - Chunk 1846 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:46,078 - lightrag - INFO - Chunk 1840 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:46,078 - lightrag - INFO - Chunk 1841 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:46,079 - lightrag - INFO - Chunk 1842 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486605 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460780 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879998 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.908583 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460320 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425315 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381511 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761290 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:47,502 - lightrag - INFO - Chunk 1847 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:47,503 - lightrag - INFO - Chunk 1848 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:47,503 - lightrag - INFO - Chunk 1849 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:47,504 - lightrag - INFO - Chunk 1843 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:47,505 - lightrag - INFO - Chunk 1850 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375958 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903433 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784058 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984273 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477659 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903034 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433806 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418928 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785106 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952523 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.821816 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:49,555 - lightrag - INFO - Chunk 1844 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:49,556 - lightrag - INFO - Chunk 1845 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:49,558 - lightrag - INFO - Chunk 1846 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:49,560 - lightrag - INFO - Chunk 1851 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:49,561 - lightrag - INFO - Chunk 1852 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495844 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393592 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992331 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418456 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395637 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956709 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960588 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809671 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452934 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:51,234 - lightrag - INFO - Chunk 1853 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:51,235 - lightrag - INFO - Chunk 1847 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:51,236 - lightrag - INFO - Chunk 1854 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:51,237 - lightrag - INFO - Chunk 1848 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:51,239 - lightrag - INFO - Chunk 1849 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456197 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417666 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447341 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867658 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952720 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926401 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947163 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453909 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455301 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:52,687 - lightrag - INFO - Chunk 1855 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:52,688 - lightrag - INFO - Chunk 1850 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:52,688 - lightrag - INFO - Chunk 1856 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:52,689 - lightrag - INFO - Chunk 1857 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:52,689 - lightrag - INFO - Chunk 1851 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404412 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949364 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439680 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981680 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818383 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853392 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475382 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446524 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494232 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:54,181 - lightrag - INFO - Chunk 1858 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:54,183 - lightrag - INFO - Chunk 1852 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:54,185 - lightrag - INFO - Chunk 1853 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:54,186 - lightrag - INFO - Chunk 1859 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:54,191 - lightrag - INFO - Chunk 1854 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382268 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838960 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866912 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.925700 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980744 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390476 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416557 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494548 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885839 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490750 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880287 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975397 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.849205 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:56,440 - lightrag - INFO - Chunk 1860 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:56,442 - lightrag - INFO - Chunk 1861 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:56,444 - lightrag - INFO - Chunk 1862 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:56,447 - lightrag - INFO - Chunk 1855 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:56,449 - lightrag - INFO - Chunk 1856 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394928 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402259 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834850 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498912 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461604 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806747 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.881703 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912431 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382813 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:57,818 - lightrag - INFO - Chunk 1857 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:57,819 - lightrag - INFO - Chunk 1858 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:57,820 - lightrag - INFO - Chunk 1863 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:57,821 - lightrag - INFO - Chunk 1864 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:57,822 - lightrag - INFO - Chunk 1865 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475652 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922081 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911660 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470916 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479481 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794395 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923947 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395942 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429696 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954802 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:59,588 - lightrag - INFO - Chunk 1866 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:59,588 - lightrag - INFO - Chunk 1859 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:59,589 - lightrag - INFO - Chunk 1860 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:59,590 - lightrag - INFO - Chunk 1861 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:34:59,592 - lightrag - INFO - Chunk 1862 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495830 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765602 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481249 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762971 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803068 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479385 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479452 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.774044 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475215 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798024 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:01,087 - lightrag - INFO - Chunk 1867 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:01,087 - lightrag - INFO - Chunk 1868 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:01,088 - lightrag - INFO - Chunk 1869 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:01,088 - lightrag - INFO - Chunk 1870 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:01,089 - lightrag - INFO - Chunk 1863 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431213 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913697 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.890823 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418946 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488952 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784884 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466404 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382889 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981775 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794231 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:02,868 - lightrag - INFO - Chunk 1864 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:02,868 - lightrag - INFO - Chunk 1865 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:02,869 - lightrag - INFO - Chunk 1866 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:02,870 - lightrag - INFO - Chunk 1871 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:02,870 - lightrag - INFO - Chunk 1872 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383938 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426968 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.822548 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832881 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448345 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408924 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806814 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495375 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850464 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:04,278 - lightrag - INFO - Chunk 1873 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:04,279 - lightrag - INFO - Chunk 1867 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:04,279 - lightrag - INFO - Chunk 1874 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:04,280 - lightrag - INFO - Chunk 1868 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:04,280 - lightrag - INFO - Chunk 1869 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496451 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898207 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959678 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396520 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491644 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989998 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963512 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491848 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420296 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938721 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981620 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:06,270 - lightrag - INFO - Chunk 1870 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:06,271 - lightrag - INFO - Chunk 1875 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:06,273 - lightrag - INFO - Chunk 1876 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:06,274 - lightrag - INFO - Chunk 1877 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:06,275 - lightrag - INFO - Chunk 1871 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439313 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476770 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937824 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956172 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478376 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417466 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946947 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864505 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451376 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:07,896 - lightrag - INFO - Chunk 1878 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:07,896 - lightrag - INFO - Chunk 1872 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:07,897 - lightrag - INFO - Chunk 1873 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:07,899 - lightrag - INFO - Chunk 1874 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:07,900 - lightrag - INFO - Chunk 1879 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426200 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970970 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802970 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432431 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453024 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997260 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771679 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487242 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484408 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.849071 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945858 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:09,709 - lightrag - INFO - Chunk 1880 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:09,710 - lightrag - INFO - Chunk 1881 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:09,710 - lightrag - INFO - Chunk 1875 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:09,711 - lightrag - INFO - Chunk 1882 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:09,712 - lightrag - INFO - Chunk 1876 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437412 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440758 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.760876 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955567 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433754 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497714 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772190 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386312 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987041 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:11,236 - lightrag - INFO - Chunk 1877 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:11,236 - lightrag - INFO - Chunk 1878 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:11,237 - lightrag - INFO - Chunk 1883 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:11,238 - lightrag - INFO - Chunk 1884 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:11,238 - lightrag - INFO - Chunk 1885 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410706 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933715 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917127 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477466 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430467 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819853 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422225 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820626 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427633 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889328 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:12,975 - lightrag - INFO - Chunk 1879 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:12,976 - lightrag - INFO - Chunk 1886 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:12,977 - lightrag - INFO - Chunk 1880 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:12,979 - lightrag - INFO - Chunk 1881 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:12,980 - lightrag - INFO - Chunk 1882 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386360 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891299 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867606 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383404 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425133 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988905 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381455 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951425 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492304 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856741 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827073 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:14,765 - lightrag - INFO - Chunk 1887 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:14,766 - lightrag - INFO - Chunk 1888 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:14,766 - lightrag - INFO - Chunk 1889 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:14,767 - lightrag - INFO - Chunk 1883 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:14,768 - lightrag - INFO - Chunk 1890 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452253 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472922 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474412 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873656 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802902 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446073 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828631 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975568 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380789 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:16,266 - lightrag - INFO - Chunk 1884 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:16,267 - lightrag - INFO - Chunk 1885 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:16,268 - lightrag - INFO - Chunk 1886 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:16,270 - lightrag - INFO - Chunk 1891 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:16,271 - lightrag - INFO - Chunk 1892 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384575 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401052 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855367 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777820 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997010 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440925 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384059 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469819 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950102 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862708 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:17,882 - lightrag - INFO - Chunk 1893 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:17,883 - lightrag - INFO - Chunk 1887 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:17,884 - lightrag - INFO - Chunk 1894 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:17,885 - lightrag - INFO - Chunk 1888 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:17,886 - lightrag - INFO - Chunk 1889 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479333 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834750 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778231 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389016 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449483 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399172 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767008 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852337 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417275 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895374 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:19,584 - lightrag - INFO - Chunk 1890 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:19,585 - lightrag - INFO - Chunk 1895 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:19,586 - lightrag - INFO - Chunk 1896 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:19,587 - lightrag - INFO - Chunk 1897 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:19,589 - lightrag - INFO - Chunk 1891 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495351 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871732 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473409 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384548 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.927124 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973057 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788423 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389472 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949149 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379794 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:21,295 - lightrag - INFO - Chunk 1898 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:21,297 - lightrag - INFO - Chunk 1892 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:21,308 - lightrag - INFO - Chunk 1893 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:21,310 - lightrag - INFO - Chunk 1894 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:21,311 - lightrag - INFO - Chunk 1899 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456327 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423053 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949022 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922366 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943045 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400293 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928963 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444463 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490335 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:22,773 - lightrag - INFO - Chunk 1900 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:22,774 - lightrag - INFO - Chunk 1901 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:22,774 - lightrag - INFO - Chunk 1895 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:22,775 - lightrag - INFO - Chunk 1902 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:22,775 - lightrag - INFO - Chunk 1896 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434281 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902654 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442981 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893102 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883753 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414316 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457498 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410829 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876840 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798953 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:24,516 - lightrag - INFO - Chunk 1897 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:24,518 - lightrag - INFO - Chunk 1898 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:24,519 - lightrag - INFO - Chunk 1903 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:24,520 - lightrag - INFO - Chunk 1904 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:24,521 - lightrag - INFO - Chunk 1905 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452044 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937271 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454679 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450041 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460373 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776183 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914117 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984814 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396569 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:26,292 - lightrag - INFO - Chunk 1899 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:26,293 - lightrag - INFO - Chunk 1900 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:26,295 - lightrag - INFO - Chunk 1906 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:26,296 - lightrag - INFO - Chunk 1901 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:26,297 - lightrag - INFO - Chunk 1902 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414532 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815053 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409139 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865669 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403047 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977320 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456205 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806472 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415901 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858298 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938595 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:28,083 - lightrag - INFO - Chunk 1907 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:28,084 - lightrag - INFO - Chunk 1908 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:28,084 - lightrag - INFO - Chunk 1909 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:28,089 - lightrag - INFO - Chunk 1903 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:28,091 - lightrag - INFO - Chunk 1904 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:28,091 - lightrag - INFO - Chunk 1910 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427337 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382942 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398628 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943792 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994646 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954257 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469367 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389031 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921923 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433094 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870571 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:29,831 - lightrag - INFO - Chunk 1905 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:29,831 - lightrag - INFO - Chunk 1906 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:29,832 - lightrag - INFO - Chunk 1911 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:29,833 - lightrag - INFO - Chunk 1912 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:29,833 - lightrag - INFO - Chunk 1913 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438305 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902467 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836911 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438311 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462839 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894384 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494031 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377948 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944032 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796103 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947045 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:31,712 - lightrag - INFO - Chunk 1907 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:31,714 - lightrag - INFO - Chunk 1908 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:31,716 - lightrag - INFO - Chunk 1914 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:31,717 - lightrag - INFO - Chunk 1909 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:31,719 - lightrag - INFO - Chunk 1910 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496245 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465983 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448419 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959666 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416611 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946262 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851876 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999764 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378672 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:33,473 - lightrag - INFO - Chunk 1915 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:33,474 - lightrag - INFO - Chunk 1916 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:33,475 - lightrag - INFO - Chunk 1917 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:33,476 - lightrag - INFO - Chunk 1911 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:33,476 - lightrag - INFO - Chunk 1918 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484730 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386810 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932350 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384081 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844151 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884750 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427170 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422194 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:34,937 - lightrag - INFO - Chunk 1912 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:34,938 - lightrag - INFO - Chunk 1913 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:34,938 - lightrag - INFO - Chunk 1914 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:34,939 - lightrag - INFO - Chunk 1919 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:34,939 - lightrag - INFO - Chunk 1920 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932077 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420733 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453198 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985863 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901237 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922795 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399163 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413483 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398974 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758289 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:36,551 - lightrag - INFO - Chunk 1921 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:36,551 - lightrag - INFO - Chunk 1915 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:36,552 - lightrag - INFO - Chunk 1922 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:36,553 - lightrag - INFO - Chunk 1916 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:36,553 - lightrag - INFO - Chunk 1917 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484701 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820694 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826452 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758963 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391794 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.802325 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411918 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463136 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383075 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941639 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961920 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935540 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:38,270 - lightrag - INFO - Chunk 1918 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:38,271 - lightrag - INFO - Chunk 1923 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:38,271 - lightrag - INFO - Chunk 1924 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:38,272 - lightrag - INFO - Chunk 1925 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:38,272 - lightrag - INFO - Chunk 1919 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477220 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856018 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441389 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459659 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441924 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.878761 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851887 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910206 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484697 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909745 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:40,165 - lightrag - INFO - Chunk 1926 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:40,165 - lightrag - INFO - Chunk 1920 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:40,166 - lightrag - INFO - Chunk 1921 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:40,166 - lightrag - INFO - Chunk 1922 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:40,167 - lightrag - INFO - Chunk 1927 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490914 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437089 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407707 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943543 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919467 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883173 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409732 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904145 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400732 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:41,628 - lightrag - INFO - Chunk 1928 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:41,629 - lightrag - INFO - Chunk 1929 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:41,630 - lightrag - INFO - Chunk 1923 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:41,632 - lightrag - INFO - Chunk 1930 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:41,633 - lightrag - INFO - Chunk 1924 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421609 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385993 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785617 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.881664 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933915 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464616 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428154 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959364 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410654 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:43,132 - lightrag - INFO - Chunk 1925 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:43,132 - lightrag - INFO - Chunk 1926 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:43,134 - lightrag - INFO - Chunk 1931 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:43,135 - lightrag - INFO - Chunk 1932 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:43,135 - lightrag - INFO - Chunk 1933 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407576 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.913751 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.914703 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841936 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382668 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458526 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883820 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426334 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391671 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918939 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784340 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895075 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:45,066 - lightrag - INFO - Chunk 1927 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:45,067 - lightrag - INFO - Chunk 1934 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:45,067 - lightrag - INFO - Chunk 1928 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:45,070 - lightrag - INFO - Chunk 1929 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:45,071 - lightrag - INFO - Chunk 1930 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411320 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982010 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403276 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446712 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376374 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941441 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899413 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768975 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478894 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:46,864 - lightrag - INFO - Chunk 1935 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:46,866 - lightrag - INFO - Chunk 1936 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:46,867 - lightrag - INFO - Chunk 1937 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:46,869 - lightrag - INFO - Chunk 1931 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:46,870 - lightrag - INFO - Chunk 1932 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444335 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496637 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404521 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987421 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.953123 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.800907 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950575 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453607 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456397 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:48,268 - lightrag - INFO - Chunk 1938 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:48,269 - lightrag - INFO - Chunk 1933 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:48,270 - lightrag - INFO - Chunk 1934 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:48,271 - lightrag - INFO - Chunk 1939 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:48,272 - lightrag - INFO - Chunk 1940 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456609 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456499 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754364 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907432 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947016 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782790 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429582 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454612 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381319 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950080 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:49,685 - lightrag - INFO - Chunk 1941 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:49,686 - lightrag - INFO - Chunk 1935 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:49,686 - lightrag - INFO - Chunk 1936 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:49,687 - lightrag - INFO - Chunk 1937 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:49,688 - lightrag - INFO - Chunk 1942 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396925 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782844 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838759 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957627 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435336 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402825 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495064 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825550 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414341 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965612 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790569 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:51,852 - lightrag - INFO - Chunk 1938 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:51,853 - lightrag - INFO - Chunk 1943 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:51,854 - lightrag - INFO - Chunk 1944 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:51,855 - lightrag - INFO - Chunk 1945 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:51,856 - lightrag - INFO - Chunk 1939 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393289 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441127 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469736 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872022 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499329 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759004 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982663 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963475 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423529 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:53,338 - lightrag - INFO - Chunk 1940 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:53,338 - lightrag - INFO - Chunk 1941 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:53,339 - lightrag - INFO - Chunk 1946 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:53,340 - lightrag - INFO - Chunk 1942 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:53,341 - lightrag - INFO - Chunk 1947 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404508 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945131 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434770 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439039 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952752 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955695 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.833018 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485268 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428818 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909455 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:55,017 - lightrag - INFO - Chunk 1948 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:55,018 - lightrag - INFO - Chunk 1949 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:55,019 - lightrag - INFO - Chunk 1943 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:55,020 - lightrag - INFO - Chunk 1944 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: Connection error.\n",
      "2025-07-07 16:35:55,021 - lightrag - INFO - Chunk 1945 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378964 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413985 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911336 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787033 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969295 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491071 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471307 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:56,202 - lightrag - INFO - Chunk 1950 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432591 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:56,415 - lightrag - INFO - Chunk 1946 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:56,415 - lightrag - INFO - Chunk 1951 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:56,417 - lightrag - INFO - Chunk 1952 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380687 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850152 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858795 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823352 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936353 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:57,279 - lightrag - INFO - Chunk 1953 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408273 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430067 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431724 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891243 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:57,745 - lightrag - INFO - Chunk 1947 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421592 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836056 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845601 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958358 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:58,593 - lightrag - INFO - Chunk 1948 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:58,594 - lightrag - INFO - Chunk 1949 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:58,595 - lightrag - INFO - Chunk 1954 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454062 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:58,686 - lightrag - INFO - Chunk 1950 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458338 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388116 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852749 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473326 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809182 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928956 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783665 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:59,919 - lightrag - INFO - Chunk 1955 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405468 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:59,982 - lightrag - INFO - Chunk 1956 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:59,983 - lightrag - INFO - Chunk 1957 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:35:59,984 - lightrag - INFO - Chunk 1951 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475931 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:00,088 - lightrag - INFO - Chunk 1952 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405448 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868060 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458333 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958668 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775078 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801361 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458116 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:01,293 - lightrag - INFO - Chunk 1953 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474464 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:01,433 - lightrag - INFO - Chunk 1958 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:01,434 - lightrag - INFO - Chunk 1954 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:01,434 - lightrag - INFO - Chunk 1959 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484314 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980941 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:01,675 - lightrag - INFO - Chunk 1960 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450259 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973592 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996242 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929244 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382151 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456227 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:02,924 - lightrag - INFO - Chunk 1961 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411595 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932983 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:03,069 - lightrag - INFO - Chunk 1955 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:03,070 - lightrag - INFO - Chunk 1956 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:03,070 - lightrag - INFO - Chunk 1957 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422977 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867853 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889951 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977439 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:03,983 - lightrag - INFO - Chunk 1962 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436757 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375485 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442978 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893107 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930510 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:04,513 - lightrag - INFO - Chunk 1958 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460210 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901142 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962166 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:05,321 - lightrag - INFO - Chunk 1963 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:05,323 - lightrag - INFO - Chunk 1964 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:05,324 - lightrag - INFO - Chunk 1965 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428321 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:05,409 - lightrag - INFO - Chunk 1959 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491373 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479633 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770234 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796249 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418357 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932519 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910166 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:06,534 - lightrag - INFO - Chunk 1960 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439775 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:06,714 - lightrag - INFO - Chunk 1961 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:06,715 - lightrag - INFO - Chunk 1966 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:06,716 - lightrag - INFO - Chunk 1962 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493427 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836447 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:07,008 - lightrag - INFO - Chunk 1967 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495023 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966586 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824086 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916510 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440500 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:08,184 - lightrag - INFO - Chunk 1968 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423298 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902286 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:08,336 - lightrag - INFO - Chunk 1969 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:08,336 - lightrag - INFO - Chunk 1963 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:08,337 - lightrag - INFO - Chunk 1964 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410887 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789471 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:08,682 - lightrag - INFO - Chunk 1965 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423424 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.992921 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858253 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437414 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471304 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871538 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:09,769 - lightrag - INFO - Chunk 1970 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422852 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.780198 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:09,972 - lightrag - INFO - Chunk 1966 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:09,972 - lightrag - INFO - Chunk 1971 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:09,973 - lightrag - INFO - Chunk 1972 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416572 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880462 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950072 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:10,487 - lightrag - INFO - Chunk 1973 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430950 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388731 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945184 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941412 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440296 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:11,349 - lightrag - INFO - Chunk 1967 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438937 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928778 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754777 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:11,873 - lightrag - INFO - Chunk 1968 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:11,873 - lightrag - INFO - Chunk 1969 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:11,874 - lightrag - INFO - Chunk 1974 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457463 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:12,004 - lightrag - INFO - Chunk 1970 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427652 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838461 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945226 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478961 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491266 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918841 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.876736 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:13,184 - lightrag - INFO - Chunk 1975 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415881 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:13,385 - lightrag - INFO - Chunk 1976 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:13,386 - lightrag - INFO - Chunk 1977 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:13,387 - lightrag - INFO - Chunk 1971 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432239 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907077 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915436 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:13,868 - lightrag - INFO - Chunk 1972 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386913 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461378 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817947 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816875 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377206 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:14,749 - lightrag - INFO - Chunk 1973 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436857 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805517 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:15,085 - lightrag - INFO - Chunk 1978 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:15,086 - lightrag - INFO - Chunk 1974 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:15,088 - lightrag - INFO - Chunk 1979 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476674 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935639 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:15,265 - lightrag - INFO - Chunk 1980 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456569 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779237 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498718 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866766 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425293 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965094 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:16,353 - lightrag - INFO - Chunk 1981 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430466 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946584 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:16,598 - lightrag - INFO - Chunk 1975 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:16,599 - lightrag - INFO - Chunk 1976 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:16,599 - lightrag - INFO - Chunk 1977 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382447 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879598 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858367 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:17,189 - lightrag - INFO - Chunk 1982 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463802 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464270 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936870 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465369 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:17,852 - lightrag - INFO - Chunk 1978 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399063 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897524 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985086 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766472 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:18,608 - lightrag - INFO - Chunk 1983 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:18,610 - lightrag - INFO - Chunk 1984 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:18,611 - lightrag - INFO - Chunk 1985 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413734 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:18,882 - lightrag - INFO - Chunk 1979 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482455 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382070 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971369 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489229 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794256 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999574 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983360 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:20,013 - lightrag - INFO - Chunk 1980 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441421 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:20,168 - lightrag - INFO - Chunk 1986 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:20,168 - lightrag - INFO - Chunk 1981 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:20,169 - lightrag - INFO - Chunk 1982 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376136 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:20,426 - lightrag - INFO - Chunk 1987 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462007 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.961849 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896289 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478301 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860340 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981892 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482050 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:21,449 - lightrag - INFO - Chunk 1988 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413447 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:21,759 - lightrag - INFO - Chunk 1989 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:21,759 - lightrag - INFO - Chunk 1983 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:21,760 - lightrag - INFO - Chunk 1984 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422533 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848988 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944767 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:22,079 - lightrag - INFO - Chunk 1990 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497342 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893140 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922689 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395437 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468501 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:23,087 - lightrag - INFO - Chunk 1985 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390535 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769136 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832680 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924504 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:23,532 - lightrag - INFO - Chunk 1991 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:23,533 - lightrag - INFO - Chunk 1986 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:23,533 - lightrag - INFO - Chunk 1992 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482450 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:23,898 - lightrag - INFO - Chunk 1993 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435310 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430871 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795166 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497236 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892633 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796222 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:24,980 - lightrag - INFO - Chunk 1987 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409676 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:25,138 - lightrag - INFO - Chunk 1988 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:25,139 - lightrag - INFO - Chunk 1994 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:25,140 - lightrag - INFO - Chunk 1989 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482182 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944487 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:25,508 - lightrag - INFO - Chunk 1995 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429828 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887708 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421919 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868391 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983538 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390731 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:26,517 - lightrag - INFO - Chunk 1990 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453973 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.815160 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:26,817 - lightrag - INFO - Chunk 1996 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:26,818 - lightrag - INFO - Chunk 1997 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:26,819 - lightrag - INFO - Chunk 1991 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472165 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806300 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:27,127 - lightrag - INFO - Chunk 1992 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455362 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978496 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483767 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.853462 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489943 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974251 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:28,279 - lightrag - INFO - Chunk 1998 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487992 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818416 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:28,447 - lightrag - INFO - Chunk 1993 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:28,448 - lightrag - INFO - Chunk 1999 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:28,448 - lightrag - INFO - Chunk 1994 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479041 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.887030 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959102 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:29,035 - lightrag - INFO - Chunk 2000 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413097 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451684 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791110 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870513 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461164 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:29,896 - lightrag - INFO - Chunk 2001 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468199 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.834509 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:30,254 - lightrag - INFO - Chunk 1995 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:30,255 - lightrag - INFO - Chunk 1996 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:30,256 - lightrag - INFO - Chunk 2002 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386238 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803456 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:30,447 - lightrag - INFO - Chunk 1997 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427666 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816230 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804212 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389982 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412866 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904781 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:31,466 - lightrag - INFO - Chunk 2003 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434319 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829835 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:31,688 - lightrag - INFO - Chunk 1998 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:31,688 - lightrag - INFO - Chunk 2004 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:31,689 - lightrag - INFO - Chunk 2005 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445771 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865916 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838430 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:32,280 - lightrag - INFO - Chunk 1999 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428529 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431973 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867904 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424566 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996584 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:32,981 - lightrag - INFO - Chunk 2000 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406980 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938627 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767360 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:33,591 - lightrag - INFO - Chunk 2006 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:33,592 - lightrag - INFO - Chunk 2001 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:33,593 - lightrag - INFO - Chunk 2007 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392749 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:33,863 - lightrag - INFO - Chunk 2002 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402785 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906288 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395018 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412453 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793190 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835078 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945948 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:34,905 - lightrag - INFO - Chunk 2008 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385267 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:35,067 - lightrag - INFO - Chunk 2009 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:35,068 - lightrag - INFO - Chunk 2003 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:35,068 - lightrag - INFO - Chunk 2004 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435212 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.758665 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:35,386 - lightrag - INFO - Chunk 2010 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.451064 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911662 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383322 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813621 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964525 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496843 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:36,424 - lightrag - INFO - Chunk 2005 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399577 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980017 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:36,661 - lightrag - INFO - Chunk 2011 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:36,661 - lightrag - INFO - Chunk 2006 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:36,662 - lightrag - INFO - Chunk 2012 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437845 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.967520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:36,885 - lightrag - INFO - Chunk 2013 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476930 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979465 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941816 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408928 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392752 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969242 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:38,088 - lightrag - INFO - Chunk 2007 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431215 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752647 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:38,316 - lightrag - INFO - Chunk 2008 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:38,317 - lightrag - INFO - Chunk 2014 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:38,317 - lightrag - INFO - Chunk 2009 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474023 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772801 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846324 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:38,941 - lightrag - INFO - Chunk 2015 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422862 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425283 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412753 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996396 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801355 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:39,652 - lightrag - INFO - Chunk 2010 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391023 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819519 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883049 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:40,234 - lightrag - INFO - Chunk 2016 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:40,235 - lightrag - INFO - Chunk 2017 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:40,236 - lightrag - INFO - Chunk 2011 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489146 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:40,426 - lightrag - INFO - Chunk 2018 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417994 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459820 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990813 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793503 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432273 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930277 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.765501 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:41,648 - lightrag - INFO - Chunk 2012 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447399 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:41,740 - lightrag - INFO - Chunk 2013 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:41,740 - lightrag - INFO - Chunk 2019 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:41,741 - lightrag - INFO - Chunk 2020 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412327 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:41,949 - lightrag - INFO - Chunk 2014 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413186 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788003 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383223 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832017 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854058 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960880 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413593 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:43,010 - lightrag - INFO - Chunk 2021 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377393 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:43,227 - lightrag - INFO - Chunk 2015 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:43,228 - lightrag - INFO - Chunk 2022 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:43,229 - lightrag - INFO - Chunk 2016 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385617 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989517 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982398 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:43,501 - lightrag - INFO - Chunk 2017 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428116 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.855848 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966974 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483016 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486607 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:44,484 - lightrag - INFO - Chunk 2023 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465487 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.968114 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944893 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:44,909 - lightrag - INFO - Chunk 2024 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:44,910 - lightrag - INFO - Chunk 2018 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:44,911 - lightrag - INFO - Chunk 2025 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444056 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951935 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994509 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:45,775 - lightrag - INFO - Chunk 2019 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489805 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488051 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402798 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874834 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.852584 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903887 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:46,373 - lightrag - INFO - Chunk 2026 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804985 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:47,156 - lightrag - INFO - Chunk 2020 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:47,157 - lightrag - INFO - Chunk 2021 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:47,158 - lightrag - INFO - Chunk 2027 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491504 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:47,170 - lightrag - INFO - Chunk 2028 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430916 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442250 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784243 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921132 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436037 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791574 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894073 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:48,397 - lightrag - INFO - Chunk 2022 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411981 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:48,490 - lightrag - INFO - Chunk 2029 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:48,490 - lightrag - INFO - Chunk 2023 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:48,491 - lightrag - INFO - Chunk 2024 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394595 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:48,591 - lightrag - INFO - Chunk 2025 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387007 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965095 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952665 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985542 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430001 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.783378 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458080 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:49,849 - lightrag - INFO - Chunk 2030 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434354 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:49,972 - lightrag - INFO - Chunk 2031 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:49,973 - lightrag - INFO - Chunk 2032 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:49,973 - lightrag - INFO - Chunk 2026 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459534 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:50,231 - lightrag - INFO - Chunk 2033 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438145 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.890421 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.807967 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886409 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854949 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444628 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446439 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:51,326 - lightrag - INFO - Chunk 2027 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446024 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:51,534 - lightrag - INFO - Chunk 2028 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:51,535 - lightrag - INFO - Chunk 2029 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:51,536 - lightrag - INFO - Chunk 2034 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478296 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858707 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840059 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955946 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858273 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:52,443 - lightrag - INFO - Chunk 2035 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378404 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381846 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412434 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916632 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823256 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:52,882 - lightrag - INFO - Chunk 2030 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449197 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939636 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865271 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:53,676 - lightrag - INFO - Chunk 2036 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:53,677 - lightrag - INFO - Chunk 2037 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:53,678 - lightrag - INFO - Chunk 2031 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468920 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:53,753 - lightrag - INFO - Chunk 2032 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411968 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458854 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847298 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864762 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380943 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924223 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884885 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:55,010 - lightrag - INFO - Chunk 2033 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426571 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:55,038 - lightrag - INFO - Chunk 2038 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:55,038 - lightrag - INFO - Chunk 2039 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:55,039 - lightrag - INFO - Chunk 2034 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433203 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965216 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790730 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:55,481 - lightrag - INFO - Chunk 2040 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434209 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449846 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941906 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937881 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395587 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:56,423 - lightrag - INFO - Chunk 2035 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457212 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986939 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:56,871 - lightrag - INFO - Chunk 2041 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:56,873 - lightrag - INFO - Chunk 2036 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:56,875 - lightrag - INFO - Chunk 2037 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456507 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986623 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:56,888 - lightrag - INFO - Chunk 2042 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474926 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935597 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938993 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431697 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484287 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777271 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:58,286 - lightrag - INFO - Chunk 2043 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415479 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:58,312 - lightrag - INFO - Chunk 2038 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:58,313 - lightrag - INFO - Chunk 2044 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:58,314 - lightrag - INFO - Chunk 2039 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465958 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751146 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928314 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936275 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:58,892 - lightrag - INFO - Chunk 2045 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440186 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416576 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918495 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976474 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429079 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:36:59,727 - lightrag - INFO - Chunk 2040 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415740 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951325 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901705 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:00,266 - lightrag - INFO - Chunk 2041 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:00,267 - lightrag - INFO - Chunk 2046 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:00,268 - lightrag - INFO - Chunk 2047 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445991 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:00,522 - lightrag - INFO - Chunk 2042 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471272 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988223 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865402 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455210 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407196 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.865732 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949269 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:01,713 - lightrag - INFO - Chunk 2048 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435191 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:01,868 - lightrag - INFO - Chunk 2043 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:01,869 - lightrag - INFO - Chunk 2049 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:01,869 - lightrag - INFO - Chunk 2044 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394896 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977380 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851688 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:02,335 - lightrag - INFO - Chunk 2045 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379544 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455073 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.849226 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769733 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396776 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:03,137 - lightrag - INFO - Chunk 2050 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470642 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906251 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:03,575 - lightrag - INFO - Chunk 2051 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:03,576 - lightrag - INFO - Chunk 2052 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:03,578 - lightrag - INFO - Chunk 2046 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462006 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.830050 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:03,688 - lightrag - INFO - Chunk 2047 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383026 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916455 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787025 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483035 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424029 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:04,872 - lightrag - INFO - Chunk 2053 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482104 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.940365 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:04,970 - lightrag - INFO - Chunk 2048 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:04,971 - lightrag - INFO - Chunk 2049 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:04,971 - lightrag - INFO - Chunk 2054 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418328 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904872 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924424 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:05,828 - lightrag - INFO - Chunk 2055 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479920 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375519 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409563 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893926 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.911534 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:06,324 - lightrag - INFO - Chunk 2050 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469291 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809942 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931829 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:07,179 - lightrag - INFO - Chunk 2056 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:07,180 - lightrag - INFO - Chunk 2051 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:07,181 - lightrag - INFO - Chunk 2057 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432156 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:07,260 - lightrag - INFO - Chunk 2052 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481877 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431281 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933568 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.388497 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.886579 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965437 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919268 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:08,561 - lightrag - INFO - Chunk 2053 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387120 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:08,650 - lightrag - INFO - Chunk 2058 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:08,652 - lightrag - INFO - Chunk 2059 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:08,653 - lightrag - INFO - Chunk 2054 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438354 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:08,912 - lightrag - INFO - Chunk 2060 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432590 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870643 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474436 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.929174 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969246 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844503 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387373 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:10,030 - lightrag - INFO - Chunk 2055 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485026 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872366 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:10,324 - lightrag - INFO - Chunk 2061 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:10,325 - lightrag - INFO - Chunk 2056 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:10,326 - lightrag - INFO - Chunk 2057 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395370 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:10,394 - lightrag - INFO - Chunk 2062 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404642 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.993623 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877690 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856742 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449609 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466186 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994599 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:11,610 - lightrag - INFO - Chunk 2063 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386671 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:11,669 - lightrag - INFO - Chunk 2058 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:11,670 - lightrag - INFO - Chunk 2064 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:11,670 - lightrag - INFO - Chunk 2059 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498093 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897002 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808444 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.764192 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:12,566 - lightrag - INFO - Chunk 2065 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.486953 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375315 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454613 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:12,943 - lightrag - INFO - Chunk 2060 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474326 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.936919 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784396 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.907721 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.987396 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:13,983 - lightrag - INFO - Chunk 2066 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:13,984 - lightrag - INFO - Chunk 2061 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:13,986 - lightrag - INFO - Chunk 2067 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402246 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:14,003 - lightrag - INFO - Chunk 2068 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429524 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429995 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926055 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398643 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899203 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.988557 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755077 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:15,327 - lightrag - INFO - Chunk 2062 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392567 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:15,359 - lightrag - INFO - Chunk 2063 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:15,360 - lightrag - INFO - Chunk 2069 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:15,361 - lightrag - INFO - Chunk 2064 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474136 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:15,575 - lightrag - INFO - Chunk 2070 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410886 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463376 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.757874 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892925 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904306 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868991 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383691 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:16,738 - lightrag - INFO - Chunk 2071 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458002 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812404 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:16,899 - lightrag - INFO - Chunk 2065 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:16,900 - lightrag - INFO - Chunk 2072 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:16,902 - lightrag - INFO - Chunk 2066 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464254 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:17,035 - lightrag - INFO - Chunk 2067 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481720 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791963 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.968867 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.919465 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404871 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445066 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915544 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:18,346 - lightrag - INFO - Chunk 2073 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401184 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:18,446 - lightrag - INFO - Chunk 2068 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:18,447 - lightrag - INFO - Chunk 2074 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:18,447 - lightrag - INFO - Chunk 2075 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.389307 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962573 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959441 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934643 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:19,037 - lightrag - INFO - Chunk 2069 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466488 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387434 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.803238 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395882 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:19,780 - lightrag - INFO - Chunk 2076 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410740 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879097 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869944 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.934466 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:20,324 - lightrag - INFO - Chunk 2070 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:20,325 - lightrag - INFO - Chunk 2071 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:20,327 - lightrag - INFO - Chunk 2077 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400338 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:20,711 - lightrag - INFO - Chunk 2072 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444628 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836793 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463518 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495254 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952837 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978977 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:21,575 - lightrag - INFO - Chunk 2078 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889721 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979523 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:22,124 - lightrag - INFO - Chunk 2079 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:22,125 - lightrag - INFO - Chunk 2073 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:22,128 - lightrag - INFO - Chunk 2080 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434793 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:22,441 - lightrag - INFO - Chunk 2074 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381583 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421078 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994841 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.898043 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489202 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847485 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861197 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:23,567 - lightrag - INFO - Chunk 2075 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406795 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:23,730 - lightrag - INFO - Chunk 2081 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:23,730 - lightrag - INFO - Chunk 2076 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:23,731 - lightrag - INFO - Chunk 2082 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385834 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:23,808 - lightrag - INFO - Chunk 2083 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770138 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784377 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977552 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411905 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915547 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479407 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:24,911 - lightrag - INFO - Chunk 2077 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421006 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:25,182 - lightrag - INFO - Chunk 2084 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:25,184 - lightrag - INFO - Chunk 2078 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:25,185 - lightrag - INFO - Chunk 2079 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493867 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.773804 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767834 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:25,650 - lightrag - INFO - Chunk 2085 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492643 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933698 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416341 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478584 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751580 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818588 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844469 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:26,623 - lightrag - INFO - Chunk 2080 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483546 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:26,934 - lightrag - INFO - Chunk 2086 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:26,935 - lightrag - INFO - Chunk 2087 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:26,936 - lightrag - INFO - Chunk 2081 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393363 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805176 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:27,258 - lightrag - INFO - Chunk 2088 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386277 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785552 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475011 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836285 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847271 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425781 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:28,129 - lightrag - INFO - Chunk 2082 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421349 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906947 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:28,491 - lightrag - INFO - Chunk 2083 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:28,492 - lightrag - INFO - Chunk 2089 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:28,493 - lightrag - INFO - Chunk 2084 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463818 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.970975 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:28,767 - lightrag - INFO - Chunk 2090 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376492 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965450 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.915549 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495267 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452417 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937671 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:29,933 - lightrag - INFO - Chunk 2091 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424159 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892878 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:30,070 - lightrag - INFO - Chunk 2085 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:30,070 - lightrag - INFO - Chunk 2092 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:30,071 - lightrag - INFO - Chunk 2086 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405456 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.849537 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937770 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:30,707 - lightrag - INFO - Chunk 2087 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452026 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481094 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794719 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497606 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848952 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:31,440 - lightrag - INFO - Chunk 2093 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454146 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786792 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867252 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:31,965 - lightrag - INFO - Chunk 2088 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:31,966 - lightrag - INFO - Chunk 2094 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:31,967 - lightrag - INFO - Chunk 2095 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476552 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:32,247 - lightrag - INFO - Chunk 2089 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398481 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857016 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463030 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858952 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465855 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786794 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819295 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:33,311 - lightrag - INFO - Chunk 2096 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381209 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:33,516 - lightrag - INFO - Chunk 2090 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:33,516 - lightrag - INFO - Chunk 2091 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:33,517 - lightrag - INFO - Chunk 2097 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433816 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772389 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:33,766 - lightrag - INFO - Chunk 2092 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376687 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869867 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382447 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805829 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806856 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375466 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:34,831 - lightrag - INFO - Chunk 2098 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415581 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.974581 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:34,957 - lightrag - INFO - Chunk 2099 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:34,958 - lightrag - INFO - Chunk 2093 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:34,959 - lightrag - INFO - Chunk 2100 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398057 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935691 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:35,268 - lightrag - INFO - Chunk 2094 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485927 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.788976 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960673 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400186 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460246 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:36,196 - lightrag - INFO - Chunk 2095 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425187 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916566 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.894925 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.918433 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:36,728 - lightrag - INFO - Chunk 2101 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:36,729 - lightrag - INFO - Chunk 2102 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:36,730 - lightrag - INFO - Chunk 2096 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386591 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897541 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:37,208 - lightrag - INFO - Chunk 2103 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423567 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399044 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382565 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869633 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944878 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897807 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:38,027 - lightrag - INFO - Chunk 2097 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489707 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:38,516 - lightrag - INFO - Chunk 2098 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:38,518 - lightrag - INFO - Chunk 2104 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:38,519 - lightrag - INFO - Chunk 2099 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493137 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801952 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:38,857 - lightrag - INFO - Chunk 2105 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378902 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491933 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899987 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861942 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441681 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782621 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796469 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:39,928 - lightrag - INFO - Chunk 2100 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485951 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:40,108 - lightrag - INFO - Chunk 2106 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:40,109 - lightrag - INFO - Chunk 2107 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:40,110 - lightrag - INFO - Chunk 2101 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418193 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:40,169 - lightrag - INFO - Chunk 2102 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412006 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861317 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.921399 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378436 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916727 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778417 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404472 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:41,459 - lightrag - INFO - Chunk 2108 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406357 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:41,513 - lightrag - INFO - Chunk 2103 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:41,514 - lightrag - INFO - Chunk 2109 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:41,514 - lightrag - INFO - Chunk 2104 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459282 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.771050 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:41,742 - lightrag - INFO - Chunk 2110 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468438 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763618 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797010 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809647 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438725 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448237 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:42,778 - lightrag - INFO - Chunk 2111 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469468 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832186 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:43,029 - lightrag - INFO - Chunk 2105 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:43,030 - lightrag - INFO - Chunk 2106 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:43,031 - lightrag - INFO - Chunk 2112 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391113 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756379 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893820 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819308 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:43,759 - lightrag - INFO - Chunk 2107 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382767 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477422 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.963033 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442625 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:44,252 - lightrag - INFO - Chunk 2113 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468547 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.924005 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767947 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819147 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:45,118 - lightrag - INFO - Chunk 2108 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:45,120 - lightrag - INFO - Chunk 2114 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:45,121 - lightrag - INFO - Chunk 2115 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377897 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:45,272 - lightrag - INFO - Chunk 2109 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475545 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439486 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804629 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.437727 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864094 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.759130 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903597 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:46,315 - lightrag - INFO - Chunk 2110 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454153 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:46,590 - lightrag - INFO - Chunk 2116 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:46,591 - lightrag - INFO - Chunk 2111 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:46,592 - lightrag - INFO - Chunk 2117 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438837 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:46,624 - lightrag - INFO - Chunk 2118 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412361 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.766031 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409899 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941920 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.850332 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.991245 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400504 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:47,899 - lightrag - INFO - Chunk 2112 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444290 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863093 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:47,986 - lightrag - INFO - Chunk 2119 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:47,987 - lightrag - INFO - Chunk 2113 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:47,987 - lightrag - INFO - Chunk 2120 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378799 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:48,337 - lightrag - INFO - Chunk 2114 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376773 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952821 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982349 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959587 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460127 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813681 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400777 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:49,358 - lightrag - INFO - Chunk 2115 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.428502 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:49,687 - lightrag - INFO - Chunk 2121 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:49,689 - lightrag - INFO - Chunk 2122 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:49,690 - lightrag - INFO - Chunk 2116 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419470 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819258 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829175 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:50,109 - lightrag - INFO - Chunk 2123 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454251 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750473 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404683 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836035 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397123 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:50,872 - lightrag - INFO - Chunk 2117 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465906 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.916254 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923264 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.885988 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:51,410 - lightrag - INFO - Chunk 2124 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:51,411 - lightrag - INFO - Chunk 2118 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:51,412 - lightrag - INFO - Chunk 2119 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471225 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:51,873 - lightrag - INFO - Chunk 2125 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491515 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896212 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.433408 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.393916 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.867076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976234 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:52,789 - lightrag - INFO - Chunk 2126 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.442107 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980709 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:53,261 - lightrag - INFO - Chunk 2120 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:53,262 - lightrag - INFO - Chunk 2127 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:53,263 - lightrag - INFO - Chunk 2121 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479439 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:53,283 - lightrag - INFO - Chunk 2128 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463766 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415586 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846337 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.804537 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843011 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391448 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:54,562 - lightrag - INFO - Chunk 2122 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472851 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:54,600 - lightrag - INFO - Chunk 2123 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:54,600 - lightrag - INFO - Chunk 2129 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:54,601 - lightrag - INFO - Chunk 2124 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.422219 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753404 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:54,886 - lightrag - INFO - Chunk 2130 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414087 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952134 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.831579 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986239 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444172 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964270 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.459970 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:55,983 - lightrag - INFO - Chunk 2131 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413284 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:56,298 - lightrag - INFO - Chunk 2125 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:56,299 - lightrag - INFO - Chunk 2132 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:56,301 - lightrag - INFO - Chunk 2126 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498012 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943751 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930923 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:56,802 - lightrag - INFO - Chunk 2127 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455311 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776317 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377217 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:57,587 - lightrag - INFO - Chunk 2133 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436624 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.762836 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.845061 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997653 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:58,210 - lightrag - INFO - Chunk 2128 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:58,211 - lightrag - INFO - Chunk 2134 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:58,212 - lightrag - INFO - Chunk 2135 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399615 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:58,482 - lightrag - INFO - Chunk 2129 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402752 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400890 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.917042 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781214 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954779 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394605 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.996712 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:59,539 - lightrag - INFO - Chunk 2136 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482445 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:59,674 - lightrag - INFO - Chunk 2130 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:59,674 - lightrag - INFO - Chunk 2131 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:59,675 - lightrag - INFO - Chunk 2137 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425313 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:37:59,941 - lightrag - INFO - Chunk 2132 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478375 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811458 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.938431 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877709 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384247 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956824 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448565 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:01,046 - lightrag - INFO - Chunk 2138 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417704 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.869656 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:01,313 - lightrag - INFO - Chunk 2139 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:01,314 - lightrag - INFO - Chunk 2133 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:01,314 - lightrag - INFO - Chunk 2140 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408313 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932506 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982034 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:01,787 - lightrag - INFO - Chunk 2134 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399698 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468203 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990750 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.496090 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.905659 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:02,714 - lightrag - INFO - Chunk 2135 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430527 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824865 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957610 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:03,189 - lightrag - INFO - Chunk 2141 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:03,190 - lightrag - INFO - Chunk 2136 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:03,191 - lightrag - INFO - Chunk 2142 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461682 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:03,555 - lightrag - INFO - Chunk 2143 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414453 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806533 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448228 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958230 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436727 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839384 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:04,484 - lightrag - INFO - Chunk 2137 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499914 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982504 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:04,945 - lightrag - INFO - Chunk 2144 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:04,951 - lightrag - INFO - Chunk 2138 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:04,953 - lightrag - INFO - Chunk 2139 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380751 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.976913 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:05,033 - lightrag - INFO - Chunk 2145 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417562 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923304 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.810196 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423269 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950096 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396804 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:06,267 - lightrag - INFO - Chunk 2140 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489664 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:06,272 - lightrag - INFO - Chunk 2146 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:06,273 - lightrag - INFO - Chunk 2147 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:06,274 - lightrag - INFO - Chunk 2141 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477128 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.872669 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823876 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.931674 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:06,929 - lightrag - INFO - Chunk 2148 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461161 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.411464 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.770210 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380235 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767096 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:07,698 - lightrag - INFO - Chunk 2142 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408857 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.899620 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812338 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:08,174 - lightrag - INFO - Chunk 2143 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:08,174 - lightrag - INFO - Chunk 2144 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:08,175 - lightrag - INFO - Chunk 2149 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465920 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:08,469 - lightrag - INFO - Chunk 2150 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439643 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.896456 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474841 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930597 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394868 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.986645 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904344 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:09,547 - lightrag - INFO - Chunk 2151 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.436159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:09,849 - lightrag - INFO - Chunk 2145 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:09,850 - lightrag - INFO - Chunk 2152 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:09,850 - lightrag - INFO - Chunk 2146 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483111 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.751543 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:10,266 - lightrag - INFO - Chunk 2147 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438302 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.920272 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457239 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787430 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397633 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.819494 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.794480 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:11,262 - lightrag - INFO - Chunk 2148 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384240 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:11,504 - lightrag - INFO - Chunk 2153 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:11,504 - lightrag - INFO - Chunk 2154 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:11,506 - lightrag - INFO - Chunk 2155 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384103 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:11,623 - lightrag - INFO - Chunk 2149 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410825 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805334 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975752 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444426 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.908933 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754858 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397486 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:12,879 - lightrag - INFO - Chunk 2156 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498670 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.868808 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:12,963 - lightrag - INFO - Chunk 2150 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:12,967 - lightrag - INFO - Chunk 2151 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:12,968 - lightrag - INFO - Chunk 2152 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400211 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:13,153 - lightrag - INFO - Chunk 2157 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446459 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949118 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971879 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.808780 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484238 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.995089 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480254 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:14,362 - lightrag - INFO - Chunk 2158 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.380276 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:14,422 - lightrag - INFO - Chunk 2159 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:14,422 - lightrag - INFO - Chunk 2160 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:14,423 - lightrag - INFO - Chunk 2153 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386112 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.864197 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752996 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775692 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:15,257 - lightrag - INFO - Chunk 2154 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460712 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402259 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415938 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:15,618 - lightrag - INFO - Chunk 2155 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465864 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791764 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880488 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787665 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:16,526 - lightrag - INFO - Chunk 2156 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:16,527 - lightrag - INFO - Chunk 2161 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:16,528 - lightrag - INFO - Chunk 2162 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497411 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:16,806 - lightrag - INFO - Chunk 2163 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395737 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456625 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432695 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892190 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966678 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951770 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772475 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:17,930 - lightrag - INFO - Chunk 2157 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394590 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:18,179 - lightrag - INFO - Chunk 2164 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:18,180 - lightrag - INFO - Chunk 2158 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:18,181 - lightrag - INFO - Chunk 2159 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464708 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:18,235 - lightrag - INFO - Chunk 2160 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.385644 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491190 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943580 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966745 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994189 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990031 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487997 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:19,598 - lightrag - INFO - Chunk 2165 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495757 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:19,677 - lightrag - INFO - Chunk 2166 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:19,678 - lightrag - INFO - Chunk 2167 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:19,679 - lightrag - INFO - Chunk 2168 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.482396 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:19,774 - lightrag - INFO - Chunk 2161 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452330 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973347 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891544 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939870 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.928083 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382934 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457293 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:21,114 - lightrag - INFO - Chunk 2162 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468728 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:21,169 - lightrag - INFO - Chunk 2163 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923661 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:21,170 - lightrag - INFO - Chunk 2164 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:21,171 - lightrag - INFO - Chunk 2169 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425241 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.989082 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.785290 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.780048 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:22,100 - lightrag - INFO - Chunk 2170 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.427598 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397362 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480095 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:22,457 - lightrag - INFO - Chunk 2171 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418499 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826728 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791362 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.825113 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.990924 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:23,372 - lightrag - INFO - Chunk 2165 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:23,373 - lightrag - INFO - Chunk 2166 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:23,374 - lightrag - INFO - Chunk 2172 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453480 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:23,575 - lightrag - INFO - Chunk 2167 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400803 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435555 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816673 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420889 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.873922 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939201 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.787364 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:24,656 - lightrag - INFO - Chunk 2168 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467425 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:24,861 - lightrag - INFO - Chunk 2173 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:24,862 - lightrag - INFO - Chunk 2174 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:24,862 - lightrag - INFO - Chunk 2175 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413957 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:25,087 - lightrag - INFO - Chunk 2169 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419211 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416431 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.768492 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910144 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983363 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973035 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409471 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:26,195 - lightrag - INFO - Chunk 2170 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413321 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814544 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:26,500 - lightrag - INFO - Chunk 2176 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:26,501 - lightrag - INFO - Chunk 2171 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:26,502 - lightrag - INFO - Chunk 2172 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379874 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:26,512 - lightrag - INFO - Chunk 2177 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.426971 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.952428 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954151 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977830 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376609 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793853 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461075 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:27,847 - lightrag - INFO - Chunk 2178 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498178 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:27,926 - lightrag - INFO - Chunk 2179 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:27,927 - lightrag - INFO - Chunk 2173 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:27,928 - lightrag - INFO - Chunk 2174 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390600 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846513 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.797238 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:28,329 - lightrag - INFO - Chunk 2180 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457505 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.969240 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820920 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450067 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.419369 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:29,323 - lightrag - INFO - Chunk 2175 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465329 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793734 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789397 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:29,622 - lightrag - INFO - Chunk 2176 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:29,623 - lightrag - INFO - Chunk 2181 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:29,624 - lightrag - INFO - Chunk 2182 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450451 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944608 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.829348 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:30,138 - lightrag - INFO - Chunk 2183 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377501 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391393 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.994386 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497598 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955681 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:30,917 - lightrag - INFO - Chunk 2177 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445760 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769113 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922672 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:31,527 - lightrag - INFO - Chunk 2178 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:31,528 - lightrag - INFO - Chunk 2184 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:31,529 - lightrag - INFO - Chunk 2179 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468827 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:31,703 - lightrag - INFO - Chunk 2180 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447589 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.841514 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439891 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997786 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435414 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897393 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769579 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:32,852 - lightrag - INFO - Chunk 2185 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457747 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:33,158 - lightrag - INFO - Chunk 2186 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:33,159 - lightrag - INFO - Chunk 2187 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:33,159 - lightrag - INFO - Chunk 2181 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407988 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.764897 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:33,362 - lightrag - INFO - Chunk 2182 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497611 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396899 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.942492 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973108 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.826147 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394668 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862019 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:34,517 - lightrag - INFO - Chunk 2188 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463701 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:34,745 - lightrag - INFO - Chunk 2183 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:34,746 - lightrag - INFO - Chunk 2184 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:34,746 - lightrag - INFO - Chunk 2189 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468603 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:34,844 - lightrag - INFO - Chunk 2190 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490030 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944674 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.756890 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874437 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432683 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.843506 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392113 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:35,983 - lightrag - INFO - Chunk 2191 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477057 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:36,219 - lightrag - INFO - Chunk 2185 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:36,220 - lightrag - INFO - Chunk 2186 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:36,221 - lightrag - INFO - Chunk 2192 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480319 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977210 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847291 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:36,641 - lightrag - INFO - Chunk 2187 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.449266 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.793070 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.930758 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.375133 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463694 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:37,526 - lightrag - INFO - Chunk 2188 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409580 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944993 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.964383 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840688 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:38,047 - lightrag - INFO - Chunk 2193 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:38,049 - lightrag - INFO - Chunk 2194 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:38,050 - lightrag - INFO - Chunk 2195 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460169 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.879054 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:38,652 - lightrag - INFO - Chunk 2189 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487817 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421564 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383068 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985623 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.956628 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895300 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:39,402 - lightrag - INFO - Chunk 2190 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406754 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.789064 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:40,086 - lightrag - INFO - Chunk 2196 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:40,087 - lightrag - INFO - Chunk 2191 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:40,088 - lightrag - INFO - Chunk 2192 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497801 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:40,136 - lightrag - INFO - Chunk 2197 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382153 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401110 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957454 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.832874 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951563 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.493959 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.983639 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:41,420 - lightrag - INFO - Chunk 2198 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478600 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:41,510 - lightrag - INFO - Chunk 2199 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:41,515 - lightrag - INFO - Chunk 2193 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:41,519 - lightrag - INFO - Chunk 2194 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484186 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:41,575 - lightrag - INFO - Chunk 2200 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495730 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.755346 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858358 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.893296 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418078 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.948028 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387932 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:42,877 - lightrag - INFO - Chunk 2195 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397038 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:42,974 - lightrag - INFO - Chunk 2196 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:42,975 - lightrag - INFO - Chunk 2201 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:42,975 - lightrag - INFO - Chunk 2202 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467829 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.950577 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902408 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816308 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:43,477 - lightrag - INFO - Chunk 2203 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383232 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.955804 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399426 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376006 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:44,271 - lightrag - INFO - Chunk 2197 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413601 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.817022 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.860214 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958582 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:44,827 - lightrag - INFO - Chunk 2198 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:44,828 - lightrag - INFO - Chunk 2204 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:44,829 - lightrag - INFO - Chunk 2199 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474178 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:45,252 - lightrag - INFO - Chunk 2200 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413112 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912341 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469884 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494940 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906070 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.902310 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.904210 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:46,224 - lightrag - INFO - Chunk 2205 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457961 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:46,583 - lightrag - INFO - Chunk 2206 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:46,584 - lightrag - INFO - Chunk 2207 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:46,585 - lightrag - INFO - Chunk 2201 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499224 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.805195 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:46,812 - lightrag - INFO - Chunk 2202 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470651 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.382433 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.870252 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959246 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.839542 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476072 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:47,968 - lightrag - INFO - Chunk 2208 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481567 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.812100 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:48,252 - lightrag - INFO - Chunk 2203 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:48,253 - lightrag - INFO - Chunk 2204 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:48,254 - lightrag - INFO - Chunk 2209 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489189 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:48,323 - lightrag - INFO - Chunk 2210 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.457715 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.922200 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.871668 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827924 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492777 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753221 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413333 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:49,623 - lightrag - INFO - Chunk 2211 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.445179 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:49,628 - lightrag - INFO - Chunk 2205 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:49,629 - lightrag - INFO - Chunk 2206 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:49,629 - lightrag - INFO - Chunk 2207 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.391109 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965294 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999311 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:50,048 - lightrag - INFO - Chunk 2212 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.492109 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926482 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.959100 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402113 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429731 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:51,026 - lightrag - INFO - Chunk 2208 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.425795 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778750 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.982013 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943657 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:51,510 - lightrag - INFO - Chunk 2213 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:51,511 - lightrag - INFO - Chunk 2214 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:51,511 - lightrag - INFO - Chunk 2215 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440625 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:51,960 - lightrag - INFO - Chunk 2209 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.943893 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.443195 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.477973 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.859013 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434834 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.966459 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880621 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:52,907 - lightrag - INFO - Chunk 2210 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.417295 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:53,277 - lightrag - INFO - Chunk 2216 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:53,278 - lightrag - INFO - Chunk 2211 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:53,280 - lightrag - INFO - Chunk 2212 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414250 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979922 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939717 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:53,777 - lightrag - INFO - Chunk 2217 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.497068 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.384917 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.993149 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.985998 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479988 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:54,648 - lightrag - INFO - Chunk 2218 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.429608 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909836 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854083 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:55,252 - lightrag - INFO - Chunk 2219 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:55,254 - lightrag - INFO - Chunk 2213 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:55,256 - lightrag - INFO - Chunk 2214 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465535 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:55,270 - lightrag - INFO - Chunk 2215 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452442 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398029 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.945008 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.978953 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.460615 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.761964 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.818605 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:56,677 - lightrag - INFO - Chunk 2220 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473304 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:56,744 - lightrag - INFO - Chunk 2216 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:56,744 - lightrag - INFO - Chunk 2221 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:56,745 - lightrag - INFO - Chunk 2222 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.480058 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:56,879 - lightrag - INFO - Chunk 2223 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.494639 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.854843 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.441963 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820080 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998064 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.753311 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476507 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:58,061 - lightrag - INFO - Chunk 2217 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452462 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:58,382 - lightrag - INFO - Chunk 2218 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:58,383 - lightrag - INFO - Chunk 2219 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:58,384 - lightrag - INFO - Chunk 2224 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458177 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:58,467 - lightrag - INFO - Chunk 2220 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456179 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791601 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998808 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.786413 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.767798 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414848 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.402352 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:59,642 - lightrag - INFO - Chunk 2225 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.450094 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946979 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:59,736 - lightrag - INFO - Chunk 2226 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:59,738 - lightrag - INFO - Chunk 2227 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:38:59,739 - lightrag - INFO - Chunk 2221 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398770 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.752130 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.814464 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.837544 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "Error during LM Studio generation: Connection error.\n",
      "2025-07-07 16:39:00,686 - lightrag - INFO - Chunk 2222 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.475242 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.495826 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395957 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:00,985 - lightrag - INFO - Chunk 2228 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:00,986 - lightrag - INFO - Chunk 2223 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.481175 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975979 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856428 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.801217 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847143 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:02,052 - lightrag - INFO - Chunk 2224 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:02,053 - lightrag - INFO - Chunk 2229 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.471866 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395157 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:02,150 - lightrag - INFO - Chunk 2230 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397722 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.452184 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.883121 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875794 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.775039 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957758 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:03,335 - lightrag - INFO - Chunk 2225 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:03,335 - lightrag - INFO - Chunk 2231 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403475 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:03,414 - lightrag - INFO - Chunk 2226 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:03,416 - lightrag - INFO - Chunk 2227 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.412621 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491232 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.778422 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:03,745 - lightrag - INFO - Chunk 2232 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392762 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.973698 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.981197 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.998426 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410661 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:04,811 - lightrag - INFO - Chunk 2228 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:04,812 - lightrag - INFO - Chunk 2233 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.472496 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:04,898 - lightrag - INFO - Chunk 2234 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:04,899 - lightrag - INFO - Chunk 2229 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.473780 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.993076 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398519 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.900523 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874234 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947698 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:05,949 - lightrag - INFO - Chunk 2235 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399182 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.455878 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:06,255 - lightrag - INFO - Chunk 2230 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:06,255 - lightrag - INFO - Chunk 2231 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.474655 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.777100 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:06,501 - lightrag - INFO - Chunk 2236 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:06,501 - lightrag - INFO - Chunk 2232 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395083 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.779575 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.780208 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.888485 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416271 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:07,433 - lightrag - INFO - Chunk 2237 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439828 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476138 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.957444 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:07,796 - lightrag - INFO - Chunk 2238 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:07,797 - lightrag - INFO - Chunk 2233 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485519 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811005 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910183 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.848069 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:08,519 - lightrag - INFO - Chunk 2239 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:08,520 - lightrag - INFO - Chunk 2234 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.469602 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468636 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:08,913 - lightrag - INFO - Chunk 2235 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.387430 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.901339 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406059 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.844497 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798167 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827542 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:09,903 - lightrag - INFO - Chunk 2240 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:09,904 - lightrag - INFO - Chunk 2236 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487546 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:10,011 - lightrag - INFO - Chunk 2241 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:10,011 - lightrag - INFO - Chunk 2242 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439468 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.430612 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:10,384 - lightrag - INFO - Chunk 2237 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.483185 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863661 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977407 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.861500 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.968570 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463964 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:11,415 - lightrag - INFO - Chunk 2243 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:11,416 - lightrag - INFO - Chunk 2238 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.431747 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:11,439 - lightrag - INFO - Chunk 2239 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:11,440 - lightrag - INFO - Chunk 2240 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.420642 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939718 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.377952 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.909962 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977349 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.769628 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:12,687 - lightrag - INFO - Chunk 2244 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405438 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423339 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:12,846 - lightrag - INFO - Chunk 2245 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:12,847 - lightrag - INFO - Chunk 2246 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.414501 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:13,004 - lightrag - INFO - Chunk 2241 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:13,005 - lightrag - INFO - Chunk 2247 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464034 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.857282 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791105 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891513 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.791855 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418574 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:13,993 - lightrag - INFO - Chunk 2242 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440883 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401395 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:14,270 - lightrag - INFO - Chunk 2243 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:14,270 - lightrag - INFO - Chunk 2244 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395728 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.912168 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776393 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.824083 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.968380 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:15,221 - lightrag - INFO - Chunk 2248 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:15,222 - lightrag - INFO - Chunk 2249 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.456369 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466344 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:15,403 - lightrag - INFO - Chunk 2245 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390940 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464301 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.910746 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.933516 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.889963 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.935568 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:16,605 - lightrag - INFO - Chunk 2250 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:16,606 - lightrag - INFO - Chunk 2251 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.390769 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:16,698 - lightrag - INFO - Chunk 2246 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:16,698 - lightrag - INFO - Chunk 2247 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.404440 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.432619 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.823708 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:17,074 - lightrag - INFO - Chunk 2252 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397510 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.925491 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.997379 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.947056 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.479400 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:18,073 - lightrag - INFO - Chunk 2248 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:18,081 - lightrag - INFO - Chunk 2253 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.399954 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:18,157 - lightrag - INFO - Chunk 2249 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:18,158 - lightrag - INFO - Chunk 2254 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383325 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862409 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.407284 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.835280 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926132 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.828417 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:19,191 - lightrag - INFO - Chunk 2255 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.446835 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487853 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:19,482 - lightrag - INFO - Chunk 2250 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:19,483 - lightrag - INFO - Chunk 2251 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487716 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846851 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:19,674 - lightrag - INFO - Chunk 2256 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:19,675 - lightrag - INFO - Chunk 2252 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397988 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.951728 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.999368 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.816365 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.383785 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:20,774 - lightrag - INFO - Chunk 2257 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.448528 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.975232 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.491798 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:21,021 - lightrag - INFO - Chunk 2253 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:21,022 - lightrag - INFO - Chunk 2258 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465511 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.836623 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.944394 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.851671 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:21,867 - lightrag - INFO - Chunk 2254 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:21,868 - lightrag - INFO - Chunk 2259 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.418094 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444061 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.891065 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:22,343 - lightrag - INFO - Chunk 2255 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401329 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.466318 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.906708 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.750286 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862845 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:23,191 - lightrag - INFO - Chunk 2260 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:23,192 - lightrag - INFO - Chunk 2256 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.394937 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:23,427 - lightrag - INFO - Chunk 2261 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:23,428 - lightrag - INFO - Chunk 2257 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490328 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.478123 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.820984 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:23,684 - lightrag - INFO - Chunk 2262 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.462276 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.954158 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923509 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.946339 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.401783 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754389 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:24,883 - lightrag - INFO - Chunk 2258 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:24,884 - lightrag - INFO - Chunk 2263 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.444183 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:24,960 - lightrag - INFO - Chunk 2259 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:24,961 - lightrag - INFO - Chunk 2264 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.465578 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376730 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.863220 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.784493 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.866431 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:25,590 - lightrag - INFO - Chunk 2260 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.434589 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960478 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.403397 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:26,226 - lightrag - INFO - Chunk 2265 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:26,227 - lightrag - INFO - Chunk 2261 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476382 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:26,354 - lightrag - INFO - Chunk 2266 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:26,355 - lightrag - INFO - Chunk 2262 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.461090 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.772293 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.780158 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.939055 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.405543 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:27,388 - lightrag - INFO - Chunk 2267 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396299 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980131 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.464170 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:27,767 - lightrag - INFO - Chunk 2263 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:27,768 - lightrag - INFO - Chunk 2268 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.439753 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.796608 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958071 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.862353 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:28,392 - lightrag - INFO - Chunk 2264 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:28,393 - lightrag - INFO - Chunk 2269 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485647 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376951 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.941521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:28,924 - lightrag - INFO - Chunk 2265 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398275 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.892638 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.440146 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754966 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.971021 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:29,834 - lightrag - INFO - Chunk 2270 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:29,836 - lightrag - INFO - Chunk 2266 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395759 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:29,887 - lightrag - INFO - Chunk 2271 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:29,888 - lightrag - INFO - Chunk 2267 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.378470 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499271 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.809159 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.897022 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:30,501 - lightrag - INFO - Chunk 2272 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.487043 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813752 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.984222 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.485066 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:31,170 - lightrag - INFO - Chunk 2268 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:31,171 - lightrag - INFO - Chunk 2273 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.416712 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:31,409 - lightrag - INFO - Chunk 2269 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:31,410 - lightrag - INFO - Chunk 2274 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.498538 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.980083 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.827470 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846429 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423983 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.884077 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:32,424 - lightrag - INFO - Chunk 2270 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.376231 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424944 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:32,764 - lightrag - INFO - Chunk 2275 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:32,764 - lightrag - INFO - Chunk 2276 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.406642 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.960000 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965953 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:33,306 - lightrag - INFO - Chunk 2271 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:33,308 - lightrag - INFO - Chunk 2272 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421242 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.806540 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.467633 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:33,924 - lightrag - INFO - Chunk 2277 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476532 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.476322 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.979060 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926717 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.895240 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:34,552 - lightrag - INFO - Chunk 2273 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:34,553 - lightrag - INFO - Chunk 2278 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.438861 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.937097 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:35,241 - lightrag - INFO - Chunk 2274 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:35,242 - lightrag - INFO - Chunk 2279 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.453910 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395859 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:35,359 - lightrag - INFO - Chunk 2280 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.379853 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.840547 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.795805 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.856625 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.415022 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846474 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:36,534 - lightrag - INFO - Chunk 2275 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:36,534 - lightrag - INFO - Chunk 2276 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.435815 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:36,548 - lightrag - INFO - Chunk 2281 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:36,549 - lightrag - INFO - Chunk 2282 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.424623 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.392385 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.790822 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.754001 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.923259 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:37,211 - lightrag - INFO - Chunk 2277 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386877 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.949543 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.423696 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:37,767 - lightrag - INFO - Chunk 2278 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:37,768 - lightrag - INFO - Chunk 2283 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.454218 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:37,930 - lightrag - INFO - Chunk 2279 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:37,931 - lightrag - INFO - Chunk 2284 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489971 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.813872 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.763568 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.838244 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.458030 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:38,977 - lightrag - INFO - Chunk 2280 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.409351 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.470103 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.890570 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:39,268 - lightrag - INFO - Chunk 2285 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:39,268 - lightrag - INFO - Chunk 2286 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.398350 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.781378 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.847806 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.942338 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:39,914 - lightrag - INFO - Chunk 2281 of 3990 extracted 0 Ent + 0 Rel\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:39,915 - lightrag - INFO - Chunk 2282 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447489 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.381349 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: Connection error.\n",
      "Error during LM Studio generation: AsyncCompletions.create() got an unexpected keyword argument 'history_messages'\n",
      "2025-07-07 16:39:40,320 - lightrag - INFO - Chunk 2287 of 3990 extracted 0 Ent + 0 Rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.490692 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.926267 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.764571 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.447424 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LM Studio generation: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.962528 seconds\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.877867 seconds\n"
     ]
    }
   ],
   "source": [
    "# --- Helper function to read PDFs ---\n",
    "def get_text_from_pdfs(folder_path):\n",
    "    all_text = \"\"\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            print(f\"Reading PDF: {filename}\")\n",
    "            with open(os.path.join(folder_path, filename), 'rb') as f:\n",
    "                reader = PdfReader(f)\n",
    "                for page in reader.pages:\n",
    "                    all_text += page.extract_text() + \"\\n\"\n",
    "    return all_text\n",
    "\n",
    "async def lm_studio_generator(prompt: str, **kwargs) -> str:\n",
    "    \"\"\"An async wrapper for the LM Studio OpenAI-compatible API.\"\"\"\n",
    "    try:\n",
    "        # --- THIS IS THE FIX ---\n",
    "        # The lightrag library passes internal arguments like 'hashing_kv'.\n",
    "        # The OpenAI client doesn't recognize this, so we safely remove it\n",
    "        # from the kwargs dictionary before making the API call.\n",
    "        kwargs.pop('hashing_kv', None)\n",
    "\n",
    "        response = await lm_studio_client.chat.completions.create(\n",
    "            model=LM_STUDIO_MODEL_NAME,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.1,\n",
    "            # Now, **kwargs only contains arguments the client understands\n",
    "            **kwargs\n",
    "        )\n",
    "        return response.choices[0].message.content or \"\"\n",
    "    except Exception as e:\n",
    "        # This will now also catch timeout errors if you add them\n",
    "        print(f\"Error during LM Studio generation: {e}\")\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "async def run_lightrag_ingestion():\n",
    "    embedding_function_wrapper = EmbeddingFunc(\n",
    "        embedding_dim=OLLAMA_EMBEDDING_DIM,\n",
    "        max_token_size=4096,\n",
    "        func=lambda texts: ollama_embed(texts, embed_model=OLLAMA_EMBEDDING_MODEL)\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "    rag_instance = LightRAG(\n",
    "        working_dir=WORKING_DIR,\n",
    "        llm_model_func=lm_studio_generator,\n",
    "        #llm_model_max_async=1,\n",
    "        embedding_func=embedding_function_wrapper,\n",
    "        graph_storage=\"Neo4JStorage\",\n",
    "        chunk_token_size=512,  \n",
    "        chunk_overlap_token_size=50,\n",
    "        addon_params={\n",
    "        \"language\": PROMPTS_IT[\"DEFAULT_LANGUAGE\"],\n",
    "        \"entity_types\": PROMPTS_IT[\"DEFAULT_ENTITY_TYPES\"],\n",
    "        \"entity_extraction_prompt\": PROMPTS_IT[\"entity_extraction\"],\n",
    "        \"entity_extraction_examples\": PROMPTS_IT[\"entity_extraction_examples\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"--- Initializing LightRAG Storages (connecting to Neo4j...) ---\")\n",
    "    await rag_instance.initialize_storages()\n",
    "    await initialize_pipeline_status()\n",
    "\n",
    "    print(\"--- Reading PA Regulation PDFs ---\")\n",
    "    document_text = get_text_from_pdfs(PDF_FOLDER)\n",
    "    if not document_text:\n",
    "        print(\"No text found. Halting.\")\n",
    "        return\n",
    "\n",
    "    documents_to_insert = [document_text]\n",
    "    document_ids = [\"pa_regulations_corpus_lmstudio\"]\n",
    "    \n",
    "    print(f\"\\n--- Ingesting document with ID '{document_ids[0]}' into LightRAG... ---\")\n",
    "    await rag_instance.ainsert(documents_to_insert, ids=document_ids)\n",
    "    \n",
    "    print(\"\\n--- Ingestion Complete! ---\")\n",
    "    print(\"Your knowledge graph has been generated and loaded directly into Neo4j.\")\n",
    "\n",
    "# Run the asynchronous ingestion process\n",
    "await run_lightrag_ingestion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
